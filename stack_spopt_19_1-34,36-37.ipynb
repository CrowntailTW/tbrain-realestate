{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '19'\n",
    "models = '1-34,36-37'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = False\n",
    "add_intercept = True\n",
    "is_cv_on_opt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n",
      "32 model-32-lgb-remove_outlier_01-cv.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-kfold.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-one.csv\n",
      "33 model-33-lgb-remove_outlier_03-cv.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-kfold.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-one.csv\n",
      "34 model-34-lgb-remove_outlier_01-cv.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-kfold.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-one.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-kfold.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "37 model-37-lgb-remove_outlier_05-cv.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-kfold.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "36\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n",
      "model-32-lgb-remove_outlier_01-cv.csv\n",
      "model-33-lgb-remove_outlier_03-cv.csv\n",
      "model-34-lgb-remove_outlier_01-cv.csv\n",
      "model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "model-37-lgb-remove_outlier_05-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n",
      "No. 31 file: model-32-lgb-remove_outlier_01-test-one.csv\n",
      "No. 32 file: model-33-lgb-remove_outlier_03-test-one.csv\n",
      "No. 33 file: model-34-lgb-remove_outlier_01-test-one.csv\n",
      "No. 34 file: model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "No. 35 file: model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360546</td>\n",
       "      <td>12.131443</td>\n",
       "      <td>6.245441e+05</td>\n",
       "      <td>13.344779</td>\n",
       "      <td>12.115676</td>\n",
       "      <td>6.319899e+05</td>\n",
       "      <td>13.356630</td>\n",
       "      <td>12.127527</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.934792</td>\n",
       "      <td>13.538225</td>\n",
       "      <td>3.042045e+06</td>\n",
       "      <td>14.928041</td>\n",
       "      <td>13.531473</td>\n",
       "      <td>3.142342e+06</td>\n",
       "      <td>14.960479</td>\n",
       "      <td>13.563912</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.111430</td>\n",
       "      <td>14.391475</td>\n",
       "      <td>9.818275e+06</td>\n",
       "      <td>16.099756</td>\n",
       "      <td>14.379801</td>\n",
       "      <td>9.946933e+06</td>\n",
       "      <td>16.112775</td>\n",
       "      <td>14.392820</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.360720</td>\n",
       "      <td>13.753373</td>\n",
       "      <td>1.264691e+07</td>\n",
       "      <td>16.352924</td>\n",
       "      <td>13.745577</td>\n",
       "      <td>1.295773e+07</td>\n",
       "      <td>16.377203</td>\n",
       "      <td>13.769857</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833961</td>\n",
       "      <td>12.288935</td>\n",
       "      <td>9.305770e+05</td>\n",
       "      <td>13.743561</td>\n",
       "      <td>12.198536</td>\n",
       "      <td>9.859947e+05</td>\n",
       "      <td>13.801407</td>\n",
       "      <td>12.256382</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "           ...            log_pred_34  log_parea_pred_34       pred_36  \\\n",
       "0          ...              13.360546          12.131443  6.245441e+05   \n",
       "1          ...              14.934792          13.538225  3.042045e+06   \n",
       "2          ...              16.111430          14.391475  9.818275e+06   \n",
       "3          ...              16.360720          13.753373  1.264691e+07   \n",
       "4          ...              13.833961          12.288935  9.305770e+05   \n",
       "\n",
       "   log_pred_36  log_parea_pred_36       pred_37  log_pred_37  \\\n",
       "0    13.344779          12.115676  6.319899e+05    13.356630   \n",
       "1    14.928041          13.531473  3.142342e+06    14.960479   \n",
       "2    16.099756          14.379801  9.946933e+06    16.112775   \n",
       "3    16.352924          13.745577  1.295773e+07    16.377203   \n",
       "4    13.743561          12.198536  9.859947e+05    13.801407   \n",
       "\n",
       "   log_parea_pred_37  log_total_price  log_parea_total_price  \n",
       "0          12.127527        13.381036              12.151933  \n",
       "1          13.563912        15.015913              13.619345  \n",
       "2          14.392820        16.074236              14.354282  \n",
       "3          13.769857        16.469809              13.862462  \n",
       "4          12.256382        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_33</th>\n",
       "      <th>pred_34</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.177853</td>\n",
       "      <td>1.265085e+07</td>\n",
       "      <td>16.353235</td>\n",
       "      <td>15.124128</td>\n",
       "      <td>1.298618e+07</td>\n",
       "      <td>16.379396</td>\n",
       "      <td>15.150290</td>\n",
       "      <td>1.304845e+07</td>\n",
       "      <td>16.384180</td>\n",
       "      <td>15.155073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.129452</td>\n",
       "      <td>3.890897e+06</td>\n",
       "      <td>15.174151</td>\n",
       "      <td>13.129532</td>\n",
       "      <td>3.897411e+06</td>\n",
       "      <td>15.175823</td>\n",
       "      <td>13.131204</td>\n",
       "      <td>3.897545e+06</td>\n",
       "      <td>15.175858</td>\n",
       "      <td>13.131239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.676769</td>\n",
       "      <td>1.078313e+07</td>\n",
       "      <td>16.193493</td>\n",
       "      <td>13.694473</td>\n",
       "      <td>1.049745e+07</td>\n",
       "      <td>16.166643</td>\n",
       "      <td>13.667623</td>\n",
       "      <td>1.035078e+07</td>\n",
       "      <td>16.152573</td>\n",
       "      <td>13.653552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.815015</td>\n",
       "      <td>6.080412e+06</td>\n",
       "      <td>15.620583</td>\n",
       "      <td>14.808651</td>\n",
       "      <td>6.139949e+06</td>\n",
       "      <td>15.630327</td>\n",
       "      <td>14.818395</td>\n",
       "      <td>6.120593e+06</td>\n",
       "      <td>15.627170</td>\n",
       "      <td>14.815237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.159895</td>\n",
       "      <td>1.092040e+06</td>\n",
       "      <td>13.903559</td>\n",
       "      <td>12.143297</td>\n",
       "      <td>1.106728e+06</td>\n",
       "      <td>13.916919</td>\n",
       "      <td>12.156657</td>\n",
       "      <td>1.098338e+06</td>\n",
       "      <td>13.909310</td>\n",
       "      <td>12.149048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3        ...          log_parea_pred_33       pred_34  \\\n",
       "0   16.544464        ...                  15.177853  1.265085e+07   \n",
       "1   15.196062        ...                  13.129452  3.890897e+06   \n",
       "2   16.199646        ...                  13.676769  1.078313e+07   \n",
       "3   15.609807        ...                  14.815015  6.080412e+06   \n",
       "4   13.842395        ...                  12.159895  1.092040e+06   \n",
       "\n",
       "   log_pred_34  log_parea_pred_34       pred_36  log_pred_36  \\\n",
       "0    16.353235          15.124128  1.298618e+07    16.379396   \n",
       "1    15.174151          13.129532  3.897411e+06    15.175823   \n",
       "2    16.193493          13.694473  1.049745e+07    16.166643   \n",
       "3    15.620583          14.808651  6.139949e+06    15.630327   \n",
       "4    13.903559          12.143297  1.106728e+06    13.916919   \n",
       "\n",
       "   log_parea_pred_36       pred_37  log_pred_37  log_parea_pred_37  \n",
       "0          15.150290  1.304845e+07    16.384180          15.155073  \n",
       "1          13.131204  3.897545e+06    15.175858          13.131239  \n",
       "2          13.667623  1.035078e+07    16.152573          13.653552  \n",
       "3          14.818395  6.120593e+06    15.627170          14.815237  \n",
       "4          12.156657  1.098338e+06    13.909310          12.149048  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n",
      "31 model-32 5930.875106\n",
      "32 model-33 5976.875715\n",
      "33 model-34 5942.875172\n",
      "34 model-36 5989.876236\n",
      "35 model-37 5980.875836\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, cv, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv[cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "      ]\n",
    "#bounds = tuple([(0, 1) for i in range(len_x-1)] + [(-2, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV\n",
    "not run yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "if is_cv_on_opt:\n",
    "    cv = cv.reset_index(drop=True)\n",
    "    #cv = cv.head(100)\n",
    "\n",
    "    score_list = []\n",
    "\n",
    "    kf = KFold(shuffle= True)\n",
    "    for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "        best_score = {}\n",
    "        best_coeffs = {}\n",
    "\n",
    "        cv_fold_train = cv.loc[idx_train].reset_index(drop=True)\n",
    "        cv_fold_val = cv.loc[idx_train].reset_index(drop=True)\n",
    "\n",
    "        for metric in ['mape']:\n",
    "        #for metric in ['mape', 'mae', 'mse']:\n",
    "            best_score[metric] = 0\n",
    "            best_coeffs[metric] = []\n",
    "            for x0 in x0s:\n",
    "                print('Optimizing with init x0: {}'.format(x0))\n",
    "                print()\n",
    "                minimize(objective, x0, args=(cv_fold_train, metric, best_score, best_coeffs, \n",
    "                                              True), \n",
    "                         tol=1e-4) #, bounds=bounds\n",
    "\n",
    "        val_pred_final = cv_fold_val[cols_opt].dot(best_coeffs['mape'])\n",
    "        if is_per_area:\n",
    "            val_pred_final = np.expm1(val_pred_final) * cv_fold_val['building_area']\n",
    "        else:\n",
    "            val_pred_final = np.expm1(val_pred_final)\n",
    "        score = cal_score(cv_fold_val['total_price'], val_pred_final)\n",
    "\n",
    "        score_list.append(score)\n",
    "\n",
    "    print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387541056735\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.6738755546903\n",
      "coeffs:  [0.02702704 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469065\n",
      "coeffs:  [0.02702703 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469264\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702704 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469867\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555470145\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.673875554738\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  5798.868333469345\n",
      "coeffs:  [0.02778131 0.02778118 0.02778131 0.02778132 0.02778136 0.02778131\n",
      " 0.02778108 0.02778137 0.02778131 0.02778131 0.02778156 0.02778134\n",
      " 0.0277813  0.02778132 0.02778132 0.02778132 0.02778132 0.02778132\n",
      " 0.02778132 0.02778132 0.02778136 0.02778136 0.02778132 0.02778133\n",
      " 0.02778132 0.02778131 0.02778131 0.02778132 0.02778132 0.0277813\n",
      " 0.02778129 0.02778138 0.02778139 0.02778138 0.02778139 0.02778139\n",
      " 0.02707569]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055568649\n",
      "coeffs:  [0.02754046 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.02831829 0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055574206\n",
      "coeffs:  [0.02754047 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.02831829 0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055574231\n",
      "coeffs:  [0.02754046 0.02773639 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.02831829 0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.87605557424\n",
      "coeffs:  [0.02754046 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.02785252 0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.02831829 0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055574261\n",
      "coeffs:  [0.02754046 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824427 0.02797503 0.02831829 0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055574268\n",
      "coeffs:  [0.02754046 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.0283183  0.02840824\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5936.876055574275\n",
      "coeffs:  [0.02754046 0.02773637 0.02761102 0.02754779 0.02789021 0.02757481\n",
      " 0.02762945 0.0278525  0.02756143 0.02759184 0.02616626 0.02768875\n",
      " 0.02765326 0.0276059  0.02759697 0.02762001 0.02762122 0.027642\n",
      " 0.02762348 0.02762014 0.02788045 0.0278858  0.02775475 0.02788042\n",
      " 0.02765886 0.02759199 0.02765937 0.02763829 0.02765496 0.0277894\n",
      " 0.02775357 0.02797004 0.02824426 0.02797503 0.02831829 0.02840825\n",
      " 0.02687568]\n",
      "\n",
      "find better score:\n",
      "score:  5950.8762821093615\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.876282110494\n",
      "coeffs:  [0.02668116 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5950.876282110517\n",
      "coeffs:  [0.02668114 0.02860768 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.876282110519\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872572 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.8762821105265\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927678 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.876282110549\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.03110462 0.02933944 0.03162825 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.876282110556\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162827 0.03217575\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5950.876282110563\n",
      "coeffs:  [0.02668114 0.02860766 0.02711308 0.02662825 0.02872571 0.0268901\n",
      " 0.02842958 0.02927677 0.02677258 0.02691746 0.01572108 0.02843707\n",
      " 0.02823904 0.02699177 0.0269104  0.02708366 0.0271192  0.0272846\n",
      " 0.02707963 0.02702514 0.02860409 0.02863733 0.0280279  0.02874453\n",
      " 0.02730543 0.02687984 0.02727893 0.02720682 0.02730874 0.02831881\n",
      " 0.02817933 0.02929414 0.0311046  0.02933944 0.03162825 0.03217576\n",
      " 0.02109371]\n",
      "\n",
      "find better score:\n",
      "score:  5966.876681971396\n",
      "coeffs:  [ 0.02455948  0.0305032   0.0259184   0.02451373  0.03078917  0.02522537\n",
      "  0.03004347  0.03258788  0.02484316  0.02524967 -0.00895752  0.03013531\n",
      "  0.02952297  0.0254848   0.02521655  0.0257513   0.02587799  0.02639774\n",
      "  0.02572402  0.02552272  0.03041547  0.03051232  0.02866271  0.03078186\n",
      "  0.02639898  0.02512918  0.02636807  0.02612142  0.02646994  0.02961473\n",
      "  0.0292258   0.03250649  0.03810996  0.03265174  0.03973547  0.04142369\n",
      "  0.00709638]\n",
      "\n",
      "find better score:\n",
      "score:  5983.877282709066\n",
      "coeffs:  [ 0.01965039  0.03439498  0.02317305  0.02008474  0.03559936  0.02137552\n",
      "  0.03296327  0.03980243  0.0203682   0.02133438 -0.06328201  0.03340978\n",
      "  0.03207786  0.02194699  0.02126525  0.0226466   0.0229683   0.02430745\n",
      "  0.0225215   0.02195182  0.03468296  0.03493283  0.03001127  0.03535758\n",
      "  0.02418408  0.02104154  0.02438046  0.02351892  0.02447806  0.03252374\n",
      "  0.03167315  0.03990494  0.05428722  0.04028164  0.05849216  0.06288367\n",
      " -0.02384044]\n",
      "\n",
      "find better score:\n",
      "score:  6000.877684211513\n",
      "coeffs:  [ 0.01372928  0.03781944  0.01990708  0.01546795  0.04112494  0.0167208\n",
      "  0.03508288  0.04765226  0.01492003  0.01657309 -0.12101801  0.03614315\n",
      "  0.03439335  0.01764383  0.01645425  0.01883951  0.01937378  0.02168827\n",
      "  0.01857498  0.01750818  0.03950972  0.0399518   0.0315387   0.04053581\n",
      "  0.02133682  0.01611351  0.02227307  0.0202257   0.02199515  0.03593586\n",
      "  0.03427996  0.04861616  0.07356108  0.04929749  0.08084698  0.08861238\n",
      " -0.05665364]\n",
      "\n",
      "find better score:\n",
      "score:  6004.878663389447\n",
      "coeffs:  [-0.03200972  0.00934763 -0.00283674  0.02227862  0.06269887 -0.01819491\n",
      "  0.0053591   0.06629559 -0.02695303 -0.02288442 -0.12152745  0.01090311\n",
      "  0.02316761 -0.01818008 -0.023329   -0.01549759 -0.01411999 -0.00601093\n",
      " -0.01927842 -0.0271249   0.05627355  0.05807494  0.03238723  0.06058028\n",
      " -0.01377596 -0.02480422  0.02470034 -0.01589211 -0.00201563  0.05081699\n",
      "  0.04401773  0.09329391  0.19562597  0.09732787  0.22487527  0.27066747\n",
      " -0.07849341]\n",
      "\n",
      "find better score:\n",
      "score:  6004.878663390571\n",
      "coeffs:  [-0.0320097   0.00934763 -0.00283674  0.02227862  0.06269887 -0.01819491\n",
      "  0.0053591   0.06629559 -0.02695303 -0.02288442 -0.12152745  0.01090311\n",
      "  0.02316761 -0.01818008 -0.023329   -0.01549759 -0.01411999 -0.00601093\n",
      " -0.01927842 -0.0271249   0.05627355  0.05807494  0.03238723  0.06058028\n",
      " -0.01377596 -0.02480422  0.02470034 -0.01589211 -0.00201563  0.05081699\n",
      "  0.04401773  0.09329391  0.19562597  0.09732787  0.22487527  0.27066747\n",
      " -0.07849341]\n",
      "\n",
      "find better score:\n",
      "score:  6004.878663390598\n",
      "coeffs:  [-0.03200972  0.00934764 -0.00283674  0.02227862  0.06269887 -0.01819491\n",
      "  0.0053591   0.06629559 -0.02695303 -0.02288442 -0.12152745  0.01090311\n",
      "  0.02316761 -0.01818008 -0.023329   -0.01549759 -0.01411999 -0.00601093\n",
      " -0.01927842 -0.0271249   0.05627355  0.05807494  0.03238723  0.06058028\n",
      " -0.01377596 -0.02480422  0.02470034 -0.01589211 -0.00201563  0.05081699\n",
      "  0.04401773  0.09329391  0.19562597  0.09732787  0.22487527  0.27066747\n",
      " -0.07849341]\n",
      "\n",
      "find better score:\n",
      "score:  6004.8786633906075\n",
      "coeffs:  [-0.03200972  0.00934763 -0.00283674  0.02227862  0.06269887 -0.01819491\n",
      "  0.00535912  0.06629559 -0.02695303 -0.02288442 -0.12152745  0.01090311\n",
      "  0.02316761 -0.01818008 -0.023329   -0.01549759 -0.01411999 -0.00601093\n",
      " -0.01927842 -0.0271249   0.05627355  0.05807494  0.03238723  0.06058028\n",
      " -0.01377596 -0.02480422  0.02470034 -0.01589211 -0.00201563  0.05081699\n",
      "  0.04401773  0.09329391  0.19562597  0.09732787  0.22487527  0.27066747\n",
      " -0.07849341]\n",
      "\n",
      "find better score:\n",
      "score:  6014.878694490978\n",
      "coeffs:  [-0.03125937  0.01295933 -0.0019578   0.02255813  0.06154226 -0.01743441\n",
      "  0.01040212  0.06836319 -0.02620394 -0.02248172 -0.11644409  0.0144329\n",
      "  0.02604173 -0.01775287 -0.02291217 -0.01526849 -0.0139046  -0.00599413\n",
      " -0.01970997 -0.0273363   0.05513567  0.05694379  0.03269803  0.06006382\n",
      " -0.01416398 -0.02527424  0.02475611 -0.01597744 -0.00187259  0.05044176\n",
      "  0.04408189  0.09000092  0.19039672  0.09407998  0.21972355  0.26537977\n",
      " -0.0736581 ]\n",
      "\n",
      "find better score:\n",
      "score:  6014.878732380072\n",
      "coeffs:  [-0.03307596  0.01903457 -0.00111082  0.02217759  0.06136085 -0.01814332\n",
      "  0.01960518  0.07467202 -0.02774526 -0.02451522 -0.11942901  0.02078661\n",
      "  0.03107319 -0.01929751 -0.02491295 -0.01717254 -0.01573674 -0.00776093\n",
      " -0.0240441  -0.0315666   0.05458381  0.05658445  0.03462844  0.06204663\n",
      " -0.01780597 -0.0302604   0.02522724 -0.01883564 -0.003023    0.0518157\n",
      "  0.04611429  0.08640715  0.1893939   0.09095618  0.22141763  0.27036146\n",
      " -0.07056942]\n",
      "\n",
      "find better score:\n",
      "score:  6014.878737554245\n",
      "coeffs:  [-0.03395002  0.01936321 -0.00066475  0.02231949  0.06150741 -0.01845391\n",
      "  0.0210326   0.07582591 -0.02846695 -0.02536781 -0.11913711  0.02146723\n",
      "  0.03137513 -0.01991419 -0.02574163 -0.0179317  -0.0164754  -0.00843152\n",
      " -0.02584058 -0.03339051  0.05456576  0.05665694  0.03559058  0.06322464\n",
      " -0.01931209 -0.03234382  0.02584514 -0.02002007 -0.00339189  0.05267774\n",
      "  0.04706938  0.08554756  0.19028233  0.09032354  0.22358052  0.27426525\n",
      " -0.06897801]\n",
      "\n",
      "find better score:\n",
      "score:  6014.878737554374\n",
      "coeffs:  [-0.03395     0.01936321 -0.00066475  0.02231949  0.06150741 -0.01845391\n",
      "  0.0210326   0.07582591 -0.02846695 -0.02536781 -0.11913711  0.02146723\n",
      "  0.03137513 -0.01991419 -0.02574163 -0.0179317  -0.0164754  -0.00843152\n",
      " -0.02584058 -0.03339051  0.05456576  0.05665694  0.03559058  0.06322464\n",
      " -0.01931209 -0.03234382  0.02584514 -0.02002007 -0.00339189  0.05267774\n",
      "  0.04706938  0.08554756  0.19028233  0.09032354  0.22358052  0.27426525\n",
      " -0.06897801]\n",
      "\n",
      "find better score:\n",
      "score:  6014.87873755438\n",
      "coeffs:  [-0.03395002  0.01936321 -0.00066474  0.02231949  0.06150741 -0.01845391\n",
      "  0.0210326   0.07582591 -0.02846695 -0.02536781 -0.11913711  0.02146723\n",
      "  0.03137513 -0.01991419 -0.02574163 -0.0179317  -0.0164754  -0.00843152\n",
      " -0.02584058 -0.03339051  0.05456576  0.05665694  0.03559058  0.06322464\n",
      " -0.01931209 -0.03234382  0.02584514 -0.02002007 -0.00339189  0.05267774\n",
      "  0.04706938  0.08554756  0.19028233  0.09032354  0.22358052  0.27426525\n",
      " -0.06897801]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6014.878972110459\n",
      "coeffs:  [-3.90674459e-02  1.15832455e-02  9.26012621e-02  1.55502884e-02\n",
      "  5.54729832e-02  1.91920049e-02  2.10117823e-02  7.77696643e-02\n",
      " -1.93130829e-02 -1.97981765e-02 -1.21730425e-01  2.96436813e-02\n",
      "  9.88145370e-04  4.34967621e-03 -1.70994602e-02 -9.14052092e-03\n",
      " -7.98449051e-03 -4.62394961e-03 -1.17361662e-01 -1.16377702e-01\n",
      "  3.95579251e-02  4.97081670e-02  8.92937602e-02  1.56564735e-01\n",
      " -8.39256864e-02 -1.50048593e-01  1.06253101e-01 -5.05557799e-02\n",
      "  2.43544555e-02  8.46133668e-02  9.00353619e-02 -2.29742128e-02\n",
      "  1.33829609e-01 -2.50127328e-04  2.58090256e-01  4.23743508e-01\n",
      " -7.27685741e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6014.879053603396\n",
      "coeffs:  [-0.06871153  0.01915265  0.13765119 -0.00855681  0.05555041  0.02772462\n",
      "  0.02621046  0.07050973 -0.03622683 -0.00133238 -0.13108354  0.01398704\n",
      "  0.01802424  0.0397114   0.00156389  0.01568766  0.01644495  0.01261818\n",
      " -0.16220192 -0.15396663  0.03253605  0.05016389  0.04813914  0.19430288\n",
      " -0.10610109 -0.21921792  0.16910945 -0.04369746  0.05846559  0.05008588\n",
      "  0.06906391 -0.04661435  0.07737013 -0.00953117  0.27491869  0.5114762\n",
      " -0.0615144 ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879055947083\n",
      "coeffs:  [-0.07297104  0.01784825  0.13752572 -0.00942427  0.05397441  0.0260028\n",
      "  0.02835957  0.07010471 -0.03981499 -0.00090146 -0.13045363  0.01176779\n",
      "  0.01929577  0.04135099  0.00187487  0.01683929  0.01764777  0.01338446\n",
      " -0.16372202 -0.15530526  0.03059763  0.04875176  0.04733493  0.19492558\n",
      " -0.10640004 -0.22221876  0.17211719 -0.04225726  0.06037129  0.05102142\n",
      "  0.07129876 -0.04438133  0.07366283 -0.00646972  0.27606327  0.51523128\n",
      " -0.05853231]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879055947084\n",
      "coeffs:  [-0.07297102  0.01784825  0.13752572 -0.00942427  0.05397441  0.0260028\n",
      "  0.02835957  0.07010471 -0.03981499 -0.00090146 -0.13045363  0.01176779\n",
      "  0.01929577  0.04135099  0.00187487  0.01683929  0.01764777  0.01338446\n",
      " -0.16372202 -0.15530526  0.03059763  0.04875176  0.04733493  0.19492558\n",
      " -0.10640004 -0.22221876  0.17211719 -0.04225726  0.06037129  0.05102142\n",
      "  0.07129876 -0.04438133  0.07366283 -0.00646972  0.27606327  0.51523128\n",
      " -0.05853231]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879055947086\n",
      "coeffs:  [-0.07297104  0.01784827  0.13752572 -0.00942427  0.05397441  0.0260028\n",
      "  0.02835957  0.07010471 -0.03981499 -0.00090146 -0.13045363  0.01176779\n",
      "  0.01929577  0.04135099  0.00187487  0.01683929  0.01764777  0.01338446\n",
      " -0.16372202 -0.15530526  0.03059763  0.04875176  0.04733493  0.19492558\n",
      " -0.10640004 -0.22221876  0.17211719 -0.04225726  0.06037129  0.05102142\n",
      "  0.07129876 -0.04438133  0.07366283 -0.00646972  0.27606327  0.51523128\n",
      " -0.05853231]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879055947089\n",
      "coeffs:  [-0.07297104  0.01784825  0.13752572 -0.00942426  0.05397441  0.0260028\n",
      "  0.02835957  0.07010471 -0.03981499 -0.00090146 -0.13045363  0.01176779\n",
      "  0.01929577  0.04135099  0.00187487  0.01683929  0.01764777  0.01338446\n",
      " -0.16372202 -0.15530526  0.03059763  0.04875176  0.04733493  0.19492558\n",
      " -0.10640004 -0.22221876  0.17211719 -0.04225726  0.06037129  0.05102142\n",
      "  0.07129876 -0.04438133  0.07366283 -0.00646972  0.27606327  0.51523128\n",
      " -0.05853231]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879055947092\n",
      "coeffs:  [-0.07297104  0.01784825  0.13752572 -0.00942427  0.05397443  0.0260028\n",
      "  0.02835957  0.07010471 -0.03981499 -0.00090146 -0.13045363  0.01176779\n",
      "  0.01929577  0.04135099  0.00187487  0.01683929  0.01764777  0.01338446\n",
      " -0.16372202 -0.15530526  0.03059763  0.04875176  0.04733493  0.19492558\n",
      " -0.10640004 -0.22221876  0.17211719 -0.04225726  0.06037129  0.05102142\n",
      "  0.07129876 -0.04438133  0.07366283 -0.00646972  0.27606327  0.51523128\n",
      " -0.05853231]\n",
      "\n",
      "find better score:\n",
      "score:  6015.87910830543\n",
      "coeffs:  [-1.54930449e-01  1.40576814e-02  1.53998893e-01 -5.53416781e-04\n",
      "  7.19420205e-02  2.29044594e-03  3.09765646e-02  6.98154909e-02\n",
      " -1.07218863e-01  8.72690871e-03 -1.33136063e-01 -1.63691136e-04\n",
      "  2.93621748e-02  8.27198176e-02  7.38036616e-03  4.60520139e-02\n",
      "  4.99357962e-02  3.31071257e-02 -2.10481966e-01 -1.94699720e-01\n",
      "  3.18562888e-02  6.67233086e-02  2.76378867e-02  2.00226577e-01\n",
      " -1.19331807e-01 -3.07300304e-01  2.27239753e-01 -6.45384299e-03\n",
      "  9.71134682e-02  7.85305597e-02  7.62910451e-02 -1.56400937e-02\n",
      " -5.08415324e-02  4.42816886e-02  2.82868536e-01  5.70847641e-01\n",
      " -6.15946672e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114535395\n",
      "coeffs:  [-0.15692854  0.01797696  0.16267674  0.00625542  0.07429199  0.00566548\n",
      "  0.02186313  0.07353258 -0.10822428  0.00837183 -0.12933423  0.00849587\n",
      "  0.02363185  0.08702469  0.00621502  0.04853821  0.05332818  0.03429833\n",
      " -0.21913256 -0.20199825  0.03154118  0.06923818  0.02713215  0.20039464\n",
      " -0.12283638 -0.32106621  0.22886974 -0.00262586  0.09772169  0.08523412\n",
      "  0.07095298 -0.01799785 -0.06734331  0.0452558   0.28598251  0.57629231\n",
      " -0.06265343]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114535431\n",
      "coeffs:  [-0.15692852  0.01797696  0.16267674  0.00625542  0.07429199  0.00566548\n",
      "  0.02186313  0.07353258 -0.10822428  0.00837183 -0.12933423  0.00849587\n",
      "  0.02363185  0.08702469  0.00621502  0.04853821  0.05332818  0.03429833\n",
      " -0.21913256 -0.20199825  0.03154118  0.06923818  0.02713215  0.20039464\n",
      " -0.12283638 -0.32106621  0.22886974 -0.00262586  0.09772169  0.08523412\n",
      "  0.07095298 -0.01799785 -0.06734331  0.0452558   0.28598251  0.57629231\n",
      " -0.06265343]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114535432\n",
      "coeffs:  [-0.15692854  0.01797696  0.16267674  0.00625542  0.07429199  0.00566548\n",
      "  0.02186313  0.07353258 -0.10822428  0.00837183 -0.12933423  0.00849587\n",
      "  0.02363185  0.08702469  0.00621502  0.04853821  0.05332818  0.03429833\n",
      " -0.21913256 -0.20199825  0.03154118  0.06923818  0.02713215  0.20039464\n",
      " -0.12283638 -0.32106621  0.22886974 -0.00262586  0.09772169  0.08523412\n",
      "  0.07095298 -0.01799785 -0.06734331  0.0452558   0.28598253  0.57629231\n",
      " -0.06265343]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879117422227\n",
      "coeffs:  [-0.15644796  0.01871265  0.16530596  0.0104983   0.07166476  0.00742888\n",
      "  0.02033016  0.07416098 -0.10792935  0.00836348 -0.12962088  0.01251543\n",
      "  0.01878681  0.08929348  0.00554577  0.05025105  0.05569783  0.03529369\n",
      " -0.21997225 -0.20230798  0.02804973  0.06717441  0.02530847  0.19720743\n",
      " -0.12137692 -0.32412161  0.2263611   0.00202107  0.09725498  0.089013\n",
      "  0.06691272 -0.01454438 -0.07468364  0.05010769  0.28738178  0.57356475\n",
      " -0.0612777 ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879117422333\n",
      "coeffs:  [-0.15644795  0.01871265  0.16530596  0.0104983   0.07166476  0.00742888\n",
      "  0.02033016  0.07416098 -0.10792935  0.00836348 -0.12962088  0.01251543\n",
      "  0.01878681  0.08929348  0.00554577  0.05025105  0.05569783  0.03529369\n",
      " -0.21997225 -0.20230798  0.02804973  0.06717441  0.02530847  0.19720743\n",
      " -0.12137692 -0.32412161  0.2263611   0.00202107  0.09725498  0.089013\n",
      "  0.06691272 -0.01454438 -0.07468364  0.05010769  0.28738178  0.57356475\n",
      " -0.0612777 ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879117422334\n",
      "coeffs:  [-0.15644796  0.01871265  0.16530596  0.0104983   0.07166476  0.00742888\n",
      "  0.02033016  0.07416098 -0.10792935  0.00836348 -0.12962088  0.01251543\n",
      "  0.01878681  0.08929348  0.00554577  0.05025105  0.05569783  0.03529369\n",
      " -0.21997225 -0.20230798  0.02804973  0.06717441  0.02530847  0.19720743\n",
      " -0.12137692 -0.32412161  0.2263611   0.00202108  0.09725498  0.089013\n",
      "  0.06691272 -0.01454438 -0.07468364  0.05010769  0.28738178  0.57356475\n",
      " -0.0612777 ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879117422335\n",
      "coeffs:  [-0.15644796  0.01871265  0.16530596  0.0104983   0.07166476  0.00742888\n",
      "  0.02033016  0.07416098 -0.10792935  0.00836348 -0.12962088  0.01251543\n",
      "  0.01878681  0.08929348  0.00554577  0.05025105  0.05569783  0.03529369\n",
      " -0.21997225 -0.20230798  0.02804973  0.06717441  0.02530847  0.19720743\n",
      " -0.12137692 -0.32412161  0.2263611   0.00202107  0.09725498  0.089013\n",
      "  0.06691274 -0.01454438 -0.07468364  0.05010769  0.28738178  0.57356475\n",
      " -0.0612777 ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879117422336\n",
      "coeffs:  [-0.15644796  0.01871265  0.16530596  0.0104983   0.07166476  0.00742888\n",
      "  0.02033016  0.07416098 -0.10792935  0.00836348 -0.12962088  0.01251543\n",
      "  0.01878681  0.08929348  0.00554577  0.05025105  0.05569783  0.03529369\n",
      " -0.21997225 -0.20230798  0.02804973  0.06717441  0.02530847  0.19720743\n",
      " -0.12137692 -0.32412161  0.2263611   0.00202107  0.09725498  0.089013\n",
      "  0.06691272 -0.01454438 -0.07468364  0.05010769  0.2873818   0.57356475\n",
      " -0.0612777 ]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6018.879119498371\n",
      "coeffs:  [-0.15827206  0.01843728  0.16918686  0.0150289   0.06922087  0.00877316\n",
      "  0.02070151  0.07479956 -0.10952165  0.00799699 -0.13180757  0.01595542\n",
      "  0.01300893  0.09230041  0.00439602  0.05226592  0.05850549  0.03641104\n",
      " -0.22333203 -0.20495022  0.02422379  0.06531889  0.02361614  0.19540611\n",
      " -0.12118439 -0.33102176  0.22563887  0.00697644  0.09745401  0.09433566\n",
      "  0.0635053  -0.01067145 -0.08383731  0.05619099  0.29169824  0.57621758\n",
      " -0.05776586]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87911949874\n",
      "coeffs:  [-0.15827204  0.01843728  0.16918686  0.0150289   0.06922087  0.00877316\n",
      "  0.02070151  0.07479956 -0.10952165  0.00799699 -0.13180757  0.01595542\n",
      "  0.01300893  0.09230041  0.00439602  0.05226592  0.05850549  0.03641104\n",
      " -0.22333203 -0.20495022  0.02422379  0.06531889  0.02361614  0.19540611\n",
      " -0.12118439 -0.33102176  0.22563887  0.00697644  0.09745401  0.09433566\n",
      "  0.0635053  -0.01067145 -0.08383731  0.05619099  0.29169824  0.57621758\n",
      " -0.05776586]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879119498741\n",
      "coeffs:  [-0.15827206  0.01843729  0.16918686  0.0150289   0.06922087  0.00877316\n",
      "  0.02070151  0.07479956 -0.10952165  0.00799699 -0.13180757  0.01595542\n",
      "  0.01300893  0.09230041  0.00439602  0.05226592  0.05850549  0.03641104\n",
      " -0.22333203 -0.20495022  0.02422379  0.06531889  0.02361614  0.19540611\n",
      " -0.12118439 -0.33102176  0.22563887  0.00697644  0.09745401  0.09433566\n",
      "  0.0635053  -0.01067145 -0.08383731  0.05619099  0.29169824  0.57621758\n",
      " -0.05776586]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879119498742\n",
      "coeffs:  [-0.15827206  0.01843728  0.16918686  0.0150289   0.06922087  0.00877316\n",
      "  0.02070152  0.07479956 -0.10952165  0.00799699 -0.13180757  0.01595542\n",
      "  0.01300893  0.09230041  0.00439602  0.05226592  0.05850549  0.03641104\n",
      " -0.22333203 -0.20495022  0.02422379  0.06531889  0.02361614  0.19540611\n",
      " -0.12118439 -0.33102176  0.22563887  0.00697644  0.09745401  0.09433566\n",
      "  0.0635053  -0.01067145 -0.08383731  0.05619099  0.29169824  0.57621758\n",
      " -0.05776586]\n",
      "\n",
      "find better score:\n",
      "score:  6018.8791194987425\n",
      "coeffs:  [-0.15827206  0.01843728  0.16918686  0.0150289   0.06922087  0.00877316\n",
      "  0.02070151  0.07479956 -0.10952165  0.00799699 -0.13180757  0.01595542\n",
      "  0.01300893  0.09230041  0.00439602  0.05226592  0.05850549  0.03641104\n",
      " -0.22333203 -0.20495022  0.02422379  0.06531889  0.02361614  0.19540611\n",
      " -0.12118439 -0.33102176  0.22563887  0.00697644  0.09745401  0.09433566\n",
      "  0.06350531 -0.01067145 -0.08383731  0.05619099  0.29169824  0.57621758\n",
      " -0.05776586]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879120590963\n",
      "coeffs:  [-0.16173292  0.01807996  0.17057515  0.01544793  0.0688203   0.00809527\n",
      "  0.02196465  0.07501531 -0.11238609  0.00811582 -0.13405848  0.01579731\n",
      "  0.01252329  0.09423041  0.00423615  0.05355311  0.06004971  0.03721427\n",
      " -0.22589766 -0.20713205  0.02305011  0.06509807  0.02273739  0.19584224\n",
      " -0.12179982 -0.33570183  0.22770404  0.00900527  0.09882209  0.09639632\n",
      "  0.06396999 -0.00888122 -0.08913127  0.05923232  0.29381694  0.58025547\n",
      " -0.05699853]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87912059119\n",
      "coeffs:  [-0.16173291  0.01807996  0.17057515  0.01544793  0.0688203   0.00809527\n",
      "  0.02196465  0.07501531 -0.11238609  0.00811582 -0.13405848  0.01579731\n",
      "  0.01252329  0.09423041  0.00423615  0.05355311  0.06004971  0.03721427\n",
      " -0.22589766 -0.20713205  0.02305011  0.06509807  0.02273739  0.19584224\n",
      " -0.12179982 -0.33570183  0.22770404  0.00900527  0.09882209  0.09639632\n",
      "  0.06396999 -0.00888122 -0.08913127  0.05923232  0.29381694  0.58025547\n",
      " -0.05699853]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879120591191\n",
      "coeffs:  [-0.16173292  0.01807996  0.17057515  0.01544793  0.0688203   0.00809527\n",
      "  0.02196467  0.07501531 -0.11238609  0.00811582 -0.13405848  0.01579731\n",
      "  0.01252329  0.09423041  0.00423615  0.05355311  0.06004971  0.03721427\n",
      " -0.22589766 -0.20713205  0.02305011  0.06509807  0.02273739  0.19584224\n",
      " -0.12179982 -0.33570183  0.22770404  0.00900527  0.09882209  0.09639632\n",
      "  0.06396999 -0.00888122 -0.08913127  0.05923232  0.29381694  0.58025547\n",
      " -0.05699853]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879120591192\n",
      "coeffs:  [-0.16173292  0.01807996  0.17057515  0.01544793  0.0688203   0.00809527\n",
      "  0.02196465  0.07501531 -0.11238609  0.00811582 -0.13405848  0.01579731\n",
      "  0.01252329  0.09423041  0.00423615  0.05355311  0.06004971  0.03721427\n",
      " -0.22589766 -0.20713205  0.02305011  0.06509807  0.02273739  0.19584224\n",
      " -0.12179982 -0.33570183  0.22770404  0.00900527  0.09882209  0.09639632\n",
      "  0.06397    -0.00888122 -0.08913127  0.05923232  0.29381694  0.58025547\n",
      " -0.05699853]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879159850337\n",
      "coeffs:  [-0.18032212  0.01667898  0.18910433  0.00504852  0.07135022  0.03066375\n",
      "  0.02382059  0.06977829 -0.10198082 -0.05334397 -0.12672534  0.0111427\n",
      "  0.01598504  0.15524284 -0.08811545  0.06605765  0.10929851  0.00487361\n",
      " -0.27290404 -0.22901234 -0.0132592   0.10057556 -0.05484532  0.17867885\n",
      " -0.05623783 -0.48898141  0.20945737  0.21687639  0.08809034  0.16604341\n",
      "  0.07174697 -0.03928444 -0.28580808  0.11618413  0.47792072  0.59910879\n",
      " -0.05668072]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879159850757\n",
      "coeffs:  [-0.1803221   0.01667898  0.18910433  0.00504852  0.07135022  0.03066375\n",
      "  0.02382059  0.06977829 -0.10198082 -0.05334397 -0.12672534  0.0111427\n",
      "  0.01598504  0.15524284 -0.08811545  0.06605765  0.10929851  0.00487361\n",
      " -0.27290404 -0.22901234 -0.0132592   0.10057556 -0.05484532  0.17867885\n",
      " -0.05623783 -0.48898141  0.20945737  0.21687639  0.08809034  0.16604341\n",
      "  0.07174697 -0.03928444 -0.28580808  0.11618413  0.47792072  0.59910879\n",
      " -0.05668072]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879159850759\n",
      "coeffs:  [-0.18032212  0.01667899  0.18910433  0.00504852  0.07135022  0.03066375\n",
      "  0.02382059  0.06977829 -0.10198082 -0.05334397 -0.12672534  0.0111427\n",
      "  0.01598504  0.15524284 -0.08811545  0.06605765  0.10929851  0.00487361\n",
      " -0.27290404 -0.22901234 -0.0132592   0.10057556 -0.05484532  0.17867885\n",
      " -0.05623783 -0.48898141  0.20945737  0.21687639  0.08809034  0.16604341\n",
      "  0.07174697 -0.03928444 -0.28580808  0.11618413  0.47792072  0.59910879\n",
      " -0.05668072]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87915985076\n",
      "coeffs:  [-0.18032212  0.01667898  0.18910433  0.00504852  0.07135022  0.03066375\n",
      "  0.02382059  0.06977831 -0.10198082 -0.05334397 -0.12672534  0.0111427\n",
      "  0.01598504  0.15524284 -0.08811545  0.06605765  0.10929851  0.00487361\n",
      " -0.27290404 -0.22901234 -0.0132592   0.10057556 -0.05484532  0.17867885\n",
      " -0.05623783 -0.48898141  0.20945737  0.21687639  0.08809034  0.16604341\n",
      "  0.07174697 -0.03928444 -0.28580808  0.11618413  0.47792072  0.59910879\n",
      " -0.05668072]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879164973399\n",
      "coeffs:  [-0.16959335  0.01451854  0.16592488  0.00626044  0.07475501  0.02318154\n",
      "  0.0253738   0.07850122 -0.08393012 -0.06473897 -0.1254871   0.0114829\n",
      "  0.01510756  0.17227388 -0.11073847  0.0622838   0.11944952 -0.02048626\n",
      " -0.26122057 -0.22620912 -0.01725539  0.1059588  -0.03398727  0.15185334\n",
      " -0.03720028 -0.48703896  0.21764747  0.24749044  0.06500497  0.14748374\n",
      "  0.0756841  -0.05331121 -0.27382767  0.12731477  0.4772852   0.58311063\n",
      " -0.05670169]\n",
      "\n",
      "find better score:\n",
      "score:  6018.8791651990905\n",
      "coeffs:  [-0.169951    0.01334777  0.16463808  0.00683335  0.07455368  0.02275296\n",
      "  0.02548371  0.07783316 -0.08333618 -0.06638212 -0.12618894  0.01291366\n",
      "  0.01523144  0.17443022 -0.11351679  0.06231629  0.12085407 -0.02243356\n",
      " -0.26123689 -0.22648018 -0.01864069  0.10628445 -0.03414536  0.15200521\n",
      " -0.03492396 -0.48941294  0.21872361  0.25267979  0.06416145  0.14701615\n",
      "  0.07615067 -0.05511788 -0.27582407  0.12848609  0.48035093  0.58347438\n",
      " -0.05683014]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165616146\n",
      "coeffs:  [-0.17178372  0.01204926  0.16508866  0.00841033  0.0748727   0.02209395\n",
      "  0.02558138  0.07652335 -0.08328186 -0.06752584 -0.12763677  0.01474401\n",
      "  0.01528761  0.18079989 -0.11693459  0.06402683  0.12524149 -0.0250438\n",
      " -0.26372117 -0.23011645 -0.02096068  0.1068217  -0.0330481   0.15176104\n",
      " -0.03334383 -0.49660257  0.22373923  0.2599652   0.06256972  0.14464391\n",
      "  0.07562025 -0.05777011 -0.28127863  0.13204552  0.48230433  0.58777849\n",
      " -0.05671766]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165853847\n",
      "coeffs:  [-0.17252147  0.01236817  0.16710898  0.00913118  0.07562742  0.021986\n",
      "  0.02488222  0.07578518 -0.08294805 -0.06711317 -0.12852474  0.01582702\n",
      "  0.01536115  0.18667912 -0.11836989  0.06606613  0.12939697 -0.02664155\n",
      " -0.26647695 -0.23455727 -0.02221261  0.10711392 -0.03110146  0.15015319\n",
      " -0.0339715  -0.50237911  0.22825209  0.26288505  0.06005407  0.14090973\n",
      "  0.07478495 -0.05890354 -0.28423902  0.1357475   0.48033495  0.59236234\n",
      " -0.05577033]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165853857\n",
      "coeffs:  [-0.17252145  0.01236817  0.16710898  0.00913118  0.07562742  0.021986\n",
      "  0.02488222  0.07578518 -0.08294805 -0.06711317 -0.12852474  0.01582702\n",
      "  0.01536115  0.18667912 -0.11836989  0.06606613  0.12939697 -0.02664155\n",
      " -0.26647695 -0.23455727 -0.02221261  0.10711392 -0.03110146  0.15015319\n",
      " -0.0339715  -0.50237911  0.22825209  0.26288505  0.06005407  0.14090973\n",
      "  0.07478495 -0.05890354 -0.28423902  0.1357475   0.48033495  0.59236234\n",
      " -0.05577033]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165853858\n",
      "coeffs:  [-0.17252147  0.01236818  0.16710898  0.00913118  0.07562742  0.021986\n",
      "  0.02488222  0.07578518 -0.08294805 -0.06711317 -0.12852474  0.01582702\n",
      "  0.01536115  0.18667912 -0.11836989  0.06606613  0.12939697 -0.02664155\n",
      " -0.26647695 -0.23455727 -0.02221261  0.10711392 -0.03110146  0.15015319\n",
      " -0.0339715  -0.50237911  0.22825209  0.26288505  0.06005407  0.14090973\n",
      "  0.07478495 -0.05890354 -0.28423902  0.1357475   0.48033495  0.59236234\n",
      " -0.05577033]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6018.8791659379685\n",
      "coeffs:  [-0.17236789  0.0135204   0.16833189  0.00843149  0.07558446  0.02247766\n",
      "  0.02431265  0.07638445 -0.08365093 -0.06588483 -0.1283573   0.01555342\n",
      "  0.01458035  0.18483358 -0.11617959  0.06609202  0.12821968 -0.02483848\n",
      " -0.26652556 -0.23421629 -0.0212928   0.10676036 -0.03187097  0.15066919\n",
      " -0.03562553 -0.50069416  0.22705056  0.25910419  0.0610599   0.14156044\n",
      "  0.07450122 -0.05728014 -0.2831021   0.13486945  0.47858777  0.59224194\n",
      " -0.05552443]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165938033\n",
      "coeffs:  [-0.17236787  0.0135204   0.16833189  0.00843149  0.07558446  0.02247766\n",
      "  0.02431265  0.07638445 -0.08365093 -0.06588483 -0.1283573   0.01555342\n",
      "  0.01458035  0.18483358 -0.11617959  0.06609202  0.12821968 -0.02483848\n",
      " -0.26652556 -0.23421629 -0.0212928   0.10676036 -0.03187097  0.15066919\n",
      " -0.03562553 -0.50069416  0.22705056  0.25910419  0.0610599   0.14156044\n",
      "  0.07450122 -0.05728014 -0.2831021   0.13486945  0.47858777  0.59224194\n",
      " -0.05552443]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165938034\n",
      "coeffs:  [-0.17236789  0.0135204   0.16833189  0.00843149  0.07558446  0.02247766\n",
      "  0.02431265  0.07638445 -0.08365093 -0.06588483 -0.12835728  0.01555342\n",
      "  0.01458035  0.18483358 -0.11617959  0.06609202  0.12821968 -0.02483848\n",
      " -0.26652556 -0.23421629 -0.0212928   0.10676036 -0.03187097  0.15066919\n",
      " -0.03562553 -0.50069416  0.22705056  0.25910419  0.0610599   0.14156044\n",
      "  0.07450122 -0.05728014 -0.2831021   0.13486945  0.47858777  0.59224194\n",
      " -0.05552443]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87916597161\n",
      "coeffs:  [-0.17217905  0.01413092  0.16850751  0.00821597  0.07566566  0.02257621\n",
      "  0.02420819  0.07691928 -0.08388719 -0.06538389 -0.127734    0.01510973\n",
      "  0.01391815  0.18367856 -0.11519418  0.06592483  0.12745633 -0.02410069\n",
      " -0.266246   -0.23376599 -0.02068807  0.1066915  -0.03195496  0.15056135\n",
      " -0.0362931  -0.49937439  0.22626654  0.25717282  0.06142645  0.14201029\n",
      "  0.07414464 -0.05641652 -0.28215028  0.1343988   0.47761398  0.59164177\n",
      " -0.05600181]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879165971629\n",
      "coeffs:  [-0.17217904  0.01413092  0.16850751  0.00821597  0.07566566  0.02257621\n",
      "  0.02420819  0.07691928 -0.08388719 -0.06538389 -0.127734    0.01510973\n",
      "  0.01391815  0.18367856 -0.11519418  0.06592483  0.12745633 -0.02410069\n",
      " -0.266246   -0.23376599 -0.02068807  0.1066915  -0.03195496  0.15056135\n",
      " -0.0362931  -0.49937439  0.22626654  0.25717282  0.06142645  0.14201029\n",
      "  0.07414464 -0.05641652 -0.28215028  0.1343988   0.47761398  0.59164177\n",
      " -0.05600181]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87916597163\n",
      "coeffs:  [-0.17217905  0.01413092  0.16850751  0.00821597  0.07566566  0.02257621\n",
      "  0.02420819  0.07691928 -0.08388719 -0.06538389 -0.127734    0.01510975\n",
      "  0.01391815  0.18367856 -0.11519418  0.06592483  0.12745633 -0.02410069\n",
      " -0.266246   -0.23376599 -0.02068807  0.1066915  -0.03195496  0.15056135\n",
      " -0.0362931  -0.49937439  0.22626654  0.25717282  0.06142645  0.14201029\n",
      "  0.07414464 -0.05641652 -0.28215028  0.1343988   0.47761398  0.59164177\n",
      " -0.05600181]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166022518\n",
      "coeffs:  [-0.17217134  0.01392426  0.16831305  0.00834114  0.07573872  0.02242545\n",
      "  0.02420827  0.07666106 -0.0837568  -0.06553517 -0.12777503  0.01553847\n",
      "  0.01396886  0.18430586 -0.11562672  0.06600335  0.12786109 -0.02453444\n",
      " -0.26625839 -0.23406972 -0.02088653  0.1067137  -0.03158665  0.15055701\n",
      " -0.0360812  -0.49971175  0.2267057   0.25773863  0.06098439  0.14142804\n",
      "  0.07426716 -0.05676744 -0.28205293  0.13472451  0.47742803  0.59186042\n",
      " -0.05619336]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166022609\n",
      "coeffs:  [-0.17217132  0.01392426  0.16831305  0.00834114  0.07573872  0.02242545\n",
      "  0.02420827  0.07666106 -0.0837568  -0.06553517 -0.12777503  0.01553847\n",
      "  0.01396886  0.18430586 -0.11562672  0.06600335  0.12786109 -0.02453444\n",
      " -0.26625839 -0.23406972 -0.02088653  0.1067137  -0.03158665  0.15055701\n",
      " -0.0360812  -0.49971175  0.2267057   0.25773863  0.06098439  0.14142804\n",
      "  0.07426716 -0.05676744 -0.28205293  0.13472451  0.47742803  0.59186042\n",
      " -0.05619336]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87916602261\n",
      "coeffs:  [-0.17217134  0.01392427  0.16831305  0.00834114  0.07573872  0.02242545\n",
      "  0.02420827  0.07666106 -0.0837568  -0.06553517 -0.12777503  0.01553847\n",
      "  0.01396886  0.18430586 -0.11562672  0.06600335  0.12786109 -0.02453444\n",
      " -0.26625839 -0.23406972 -0.02088653  0.1067137  -0.03158665  0.15055701\n",
      " -0.0360812  -0.49971175  0.2267057   0.25773863  0.06098439  0.14142804\n",
      "  0.07426716 -0.05676744 -0.28205293  0.13472451  0.47742803  0.59186042\n",
      " -0.05619336]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166022611\n",
      "coeffs:  [-0.17217134  0.01392426  0.16831305  0.00834114  0.07573872  0.02242545\n",
      "  0.02420827  0.07666106 -0.0837568  -0.06553517 -0.12777503  0.01553847\n",
      "  0.01396886  0.18430586 -0.11562672  0.06600335  0.12786109 -0.02453444\n",
      " -0.26625839 -0.23406972 -0.02088653  0.1067137  -0.03158665  0.15055703\n",
      " -0.0360812  -0.49971175  0.2267057   0.25773863  0.06098439  0.14142804\n",
      "  0.07426716 -0.05676744 -0.28205293  0.13472451  0.47742803  0.59186042\n",
      " -0.05619336]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166120663\n",
      "coeffs:  [-0.17220843  0.0137206   0.16765115  0.00863894  0.0760415   0.02194066\n",
      "  0.02420448  0.07593111 -0.08353778 -0.06619173 -0.12764642  0.0168429\n",
      "  0.01364922  0.18610412 -0.11718805  0.06619525  0.12907072 -0.02584922\n",
      " -0.26627883 -0.23495227 -0.02146081  0.10690446 -0.03051336  0.15034064\n",
      " -0.03531131 -0.5008062   0.22746017  0.25972696  0.05941706  0.14031685\n",
      "  0.07488468 -0.05740424 -0.28214024  0.13616184  0.47706337  0.59214198\n",
      " -0.05675856]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166120696\n",
      "coeffs:  [-0.17220841  0.0137206   0.16765115  0.00863894  0.0760415   0.02194066\n",
      "  0.02420448  0.07593111 -0.08353778 -0.06619173 -0.12764642  0.0168429\n",
      "  0.01364922  0.18610412 -0.11718805  0.06619525  0.12907072 -0.02584922\n",
      " -0.26627883 -0.23495227 -0.02146081  0.10690446 -0.03051336  0.15034064\n",
      " -0.03531131 -0.5008062   0.22746017  0.25972696  0.05941706  0.14031685\n",
      "  0.07488468 -0.05740424 -0.28214024  0.13616184  0.47706337  0.59214198\n",
      " -0.05675856]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166120697\n",
      "coeffs:  [-0.17220843  0.0137206   0.16765115  0.00863894  0.0760415   0.02194066\n",
      "  0.02420449  0.07593111 -0.08353778 -0.06619173 -0.12764642  0.0168429\n",
      "  0.01364922  0.18610412 -0.11718805  0.06619525  0.12907072 -0.02584922\n",
      " -0.26627883 -0.23495227 -0.02146081  0.10690446 -0.03051336  0.15034064\n",
      " -0.03531131 -0.5008062   0.22746017  0.25972696  0.05941706  0.14031685\n",
      "  0.07488468 -0.05740424 -0.28214024  0.13616184  0.47706337  0.59214198\n",
      " -0.05675856]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166120698\n",
      "coeffs:  [-0.17220843  0.0137206   0.16765115  0.00863894  0.0760415   0.02194066\n",
      "  0.02420448  0.07593111 -0.08353778 -0.06619173 -0.12764642  0.0168429\n",
      "  0.01364922  0.18610412 -0.11718805  0.06619525  0.12907072 -0.02584922\n",
      " -0.26627883 -0.23495227 -0.02146081  0.10690446 -0.03051336  0.15034065\n",
      " -0.03531131 -0.5008062   0.22746017  0.25972696  0.05941706  0.14031685\n",
      "  0.07488468 -0.05740424 -0.28214024  0.13616184  0.47706337  0.59214198\n",
      " -0.05675856]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166195103\n",
      "coeffs:  [-0.17241262  0.01375048  0.16670937  0.00887771  0.07627724  0.02127499\n",
      "  0.02413985  0.07546026 -0.08322288 -0.06696813 -0.12744971  0.01741136\n",
      "  0.01341081  0.18835071 -0.11905333  0.06647361  0.13058278 -0.02746182\n",
      " -0.26629405 -0.23584963 -0.02227248  0.10712848 -0.02914538  0.14991993\n",
      " -0.03418438 -0.50224939  0.22872895  0.26251957  0.05784173  0.139209\n",
      "  0.07518459 -0.0583514  -0.28265418  0.13777743  0.47699873  0.59248468\n",
      " -0.05710089]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879166495657\n",
      "coeffs:  [-0.17273152  0.0144445   0.16546342  0.00779769  0.07729244  0.01980896\n",
      "  0.02374816  0.07411737 -0.08278208 -0.06805523 -0.12673155  0.0195503\n",
      "  0.01222892  0.19475185 -0.12300746  0.06776778  0.13496309 -0.03100419\n",
      " -0.26672274 -0.23917357 -0.02400677  0.10758464 -0.02564959  0.1502412\n",
      " -0.03235452 -0.50587757  0.23237461  0.26787976  0.05337774  0.13478162\n",
      "  0.07611926 -0.0607332  -0.28301669  0.14193102  0.47419746  0.59442452\n",
      " -0.05798857]\n",
      "\n",
      "find better score:\n",
      "score:  6018.8791678205325\n",
      "coeffs:  [-0.1684429   0.01612145  0.1640957   0.0026363   0.07903905  0.01965314\n",
      "  0.0240938   0.0702332  -0.07897494 -0.0728412  -0.12664894  0.01976109\n",
      "  0.01314793  0.20502022 -0.1342047   0.06875434  0.14247895 -0.03865092\n",
      " -0.26574765 -0.24412564 -0.02811446  0.10851871 -0.01880833  0.15669474\n",
      " -0.02630751 -0.51101917  0.23107746  0.28070828  0.04126125  0.13095873\n",
      "  0.07501855 -0.0677317  -0.2806151   0.14803058  0.47304767  0.59467247\n",
      " -0.05472873]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879167820715\n",
      "coeffs:  [-0.16844289  0.01612145  0.1640957   0.0026363   0.07903905  0.01965314\n",
      "  0.0240938   0.0702332  -0.07897494 -0.0728412  -0.12664894  0.01976109\n",
      "  0.01314793  0.20502022 -0.1342047   0.06875434  0.14247895 -0.03865092\n",
      " -0.26574765 -0.24412564 -0.02811446  0.10851871 -0.01880833  0.15669474\n",
      " -0.02630751 -0.51101917  0.23107746  0.28070828  0.04126125  0.13095873\n",
      "  0.07501855 -0.0677317  -0.2806151   0.14803058  0.47304767  0.59467247\n",
      " -0.05472873]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879167820716\n",
      "coeffs:  [-0.1684429   0.01612145  0.1640957   0.00263632  0.07903905  0.01965314\n",
      "  0.0240938   0.0702332  -0.07897494 -0.0728412  -0.12664894  0.01976109\n",
      "  0.01314793  0.20502022 -0.1342047   0.06875434  0.14247895 -0.03865092\n",
      " -0.26574765 -0.24412564 -0.02811446  0.10851871 -0.01880833  0.15669474\n",
      " -0.02630751 -0.51101917  0.23107746  0.28070828  0.04126125  0.13095873\n",
      "  0.07501855 -0.0677317  -0.2806151   0.14803058  0.47304767  0.59467247\n",
      " -0.05472873]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6018.879167820717\n",
      "coeffs:  [-0.1684429   0.01612145  0.1640957   0.0026363   0.07903905  0.01965314\n",
      "  0.0240938   0.07023322 -0.07897494 -0.0728412  -0.12664894  0.01976109\n",
      "  0.01314793  0.20502022 -0.1342047   0.06875434  0.14247895 -0.03865092\n",
      " -0.26574765 -0.24412564 -0.02811446  0.10851871 -0.01880833  0.15669474\n",
      " -0.02630751 -0.51101917  0.23107746  0.28070828  0.04126125  0.13095873\n",
      "  0.07501855 -0.0677317  -0.2806151   0.14803058  0.47304767  0.59467247\n",
      " -0.05472873]\n",
      "\n",
      "find better score:\n",
      "score:  6018.87916804891\n",
      "coeffs:  [-0.16801001  0.01564947  0.16387242  0.00195216  0.07943821  0.01973481\n",
      "  0.02476647  0.06970451 -0.07878256 -0.07415365 -0.12641146  0.01977185\n",
      "  0.01332362  0.20620037 -0.13656151  0.06871055  0.14341039 -0.03972347\n",
      " -0.26554797 -0.24465784 -0.02885513  0.10887789 -0.01828755  0.16002587\n",
      " -0.02483853 -0.51200836  0.23011606  0.28356033  0.03985384  0.131591\n",
      "  0.0736839  -0.06963785 -0.28085398  0.14819334  0.47412708  0.59456653\n",
      " -0.0548509 ]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879168048944\n",
      "coeffs:  [-0.16800999  0.01564947  0.16387242  0.00195216  0.07943821  0.01973481\n",
      "  0.02476647  0.06970451 -0.07878256 -0.07415365 -0.12641146  0.01977185\n",
      "  0.01332362  0.20620037 -0.13656151  0.06871055  0.14341039 -0.03972347\n",
      " -0.26554797 -0.24465784 -0.02885513  0.10887789 -0.01828755  0.16002587\n",
      " -0.02483853 -0.51200836  0.23011606  0.28356033  0.03985384  0.131591\n",
      "  0.0736839  -0.06963785 -0.28085398  0.14819334  0.47412708  0.59456653\n",
      " -0.0548509 ]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879168048945\n",
      "coeffs:  [-0.16801001  0.01564947  0.16387242  0.00195217  0.07943821  0.01973481\n",
      "  0.02476647  0.06970451 -0.07878256 -0.07415365 -0.12641146  0.01977185\n",
      "  0.01332362  0.20620037 -0.13656151  0.06871055  0.14341039 -0.03972347\n",
      " -0.26554797 -0.24465784 -0.02885513  0.10887789 -0.01828755  0.16002587\n",
      " -0.02483853 -0.51200836  0.23011606  0.28356033  0.03985384  0.131591\n",
      "  0.0736839  -0.06963785 -0.28085398  0.14819334  0.47412708  0.59456653\n",
      " -0.0548509 ]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879168192726\n",
      "coeffs:  [-0.16752841  0.01523915  0.16338442  0.00116958  0.08000885  0.01931032\n",
      "  0.02487282  0.07001465 -0.0785045  -0.07475795 -0.12631208  0.0202904\n",
      "  0.01286197  0.20823427 -0.13837698  0.0689867   0.14487456 -0.04107528\n",
      " -0.26524832 -0.24577419 -0.02938498  0.10906964 -0.01644224  0.16136574\n",
      " -0.0240116  -0.51251934  0.23031694  0.28519737  0.03759723  0.13040084\n",
      "  0.07303934 -0.07069759 -0.27972637  0.14953357  0.47265039  0.59476999\n",
      " -0.05527457]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879168236225\n",
      "coeffs:  [-1.66762446e-01  1.43543180e-02  1.63821800e-01  6.40605384e-05\n",
      "  8.10227821e-02  1.92247080e-02  2.52121874e-02  7.13392571e-02\n",
      " -7.82055636e-02 -7.53824852e-02 -1.26395953e-01  2.04469817e-02\n",
      "  1.22543654e-02  2.11157409e-01 -1.40663879e-01  6.96594078e-02\n",
      "  1.47126918e-01 -4.24636006e-02 -2.65493757e-01 -2.47881460e-01\n",
      " -2.99291901e-02  1.09535302e-01 -1.41421944e-02  1.63141922e-01\n",
      " -2.33886801e-02 -5.14006361e-01  2.30112498e-01  2.87178450e-01\n",
      "  3.44357572e-02  1.29397373e-01  7.12326507e-02 -7.18218960e-02\n",
      " -2.79096382e-01  1.51668831e-01  4.70617401e-01  5.95494836e-01\n",
      " -5.58253816e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879168310711\n",
      "coeffs:  [-1.66950032e-01  1.43596958e-02  1.63762676e-01  3.03382603e-04\n",
      "  8.11453773e-02  1.90608287e-02  2.50232414e-02  7.16506472e-02\n",
      " -7.81621434e-02 -7.53399591e-02 -1.26386089e-01  2.04672846e-02\n",
      "  1.22929751e-02  2.11783547e-01 -1.40797399e-01  6.98488433e-02\n",
      "  1.47554681e-01 -4.27273462e-02 -2.65726533e-01 -2.48244460e-01\n",
      " -2.99468151e-02  1.09679325e-01 -1.39643323e-02  1.62090579e-01\n",
      " -2.34201622e-02 -5.14563885e-01  2.30711402e-01  2.87567143e-01\n",
      "  3.41535901e-02  1.28862265e-01  7.14545932e-02 -7.16684924e-02\n",
      " -2.79509996e-01  1.52334124e-01  4.70406564e-01  5.95772894e-01\n",
      " -5.60384922e-02]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.05840281  0.08428003  0.02357447  0.01365567  0.03361005  0.03320353\n",
      "  0.01773818  0.01807664  0.01459417  0.00711973  0.01200565  0.02741301\n",
      "  0.05721401  0.00778706  0.00301909  0.12150663 -0.00295693  0.03942252\n",
      "  0.07507196  0.05511988  0.04673891  0.02217088  0.0560146   0.06709724\n",
      "  0.03566316 -0.00680731  0.03300838  0.0356874   0.01432522  0.05825308\n",
      "  0.0585763   0.00281447  0.04185215  0.06461555  0.01864164 -0.00618301\n",
      "  0.04011788]\n",
      "\n",
      "Optimizing with init x0: [ 0.05318761  0.02460851  0.037807   -0.02384521  0.013462    0.03399896\n",
      "  0.09972168  0.06053027  0.00776531  0.02293739  0.04865512  0.00626001\n",
      "  0.05412571  0.0019105  -0.00934919 -0.00563557  0.08659433  0.03345008\n",
      "  0.05694164 -0.01181743 -0.01270818  0.08663032  0.05916189  0.0589663\n",
      "  0.00466912  0.0598388   0.03238766  0.02793622 -0.04191682 -0.03759943\n",
      "  0.0297142   0.03896917  0.02437655  0.00414082  0.02885035  0.00764113\n",
      "  0.08906679]\n",
      "\n",
      "Optimizing with init x0: [ 0.02997229  0.03490736  0.03284766  0.03935318  0.05602379  0.04019485\n",
      "  0.03482462  0.04543997  0.08128808  0.05317612  0.01902824 -0.01029074\n",
      "  0.01442584  0.04278272  0.01398506  0.06232565 -0.02224156  0.03727588\n",
      "  0.03823918  0.06147026  0.04049701  0.02285474  0.00077965  0.04554654\n",
      "  0.02477235  0.01079885  0.03795882  0.0464054  -0.00434438 -0.01887612\n",
      " -0.01410116  0.02334931  0.01749014  0.0249575   0.04830887  0.04956817\n",
      " -0.01334895]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 6018.879168310711}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-1.66950032e-01,  1.43596958e-02,  1.63762676e-01,  3.03382603e-04,\n",
       "         8.11453773e-02,  1.90608287e-02,  2.50232414e-02,  7.16506472e-02,\n",
       "        -7.81621434e-02, -7.53399591e-02, -1.26386089e-01,  2.04672846e-02,\n",
       "         1.22929751e-02,  2.11783547e-01, -1.40797399e-01,  6.98488433e-02,\n",
       "         1.47554681e-01, -4.27273462e-02, -2.65726533e-01, -2.48244460e-01,\n",
       "        -2.99468151e-02,  1.09679325e-01, -1.39643323e-02,  1.62090579e-01,\n",
       "        -2.34201622e-02, -5.14563885e-01,  2.30711402e-01,  2.87567143e-01,\n",
       "         3.41535901e-02,  1.28862265e-01,  7.14545932e-02, -7.16684924e-02,\n",
       "        -2.79509996e-01,  1.52334124e-01,  4.70406564e-01,  5.95772894e-01,\n",
       "        -5.60384922e-02])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prices = np.sort(df_train['total_price'].unique())\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return array[(np.fabs(array - value)).argmin()]\n",
    "\n",
    "def correct_prices(sq):\n",
    "    return [find_nearest(unique_prices, x) for x in sq]\n",
    "\n",
    "test_pred_final['total_price'] = correct_prices(test_pred_final['total_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
