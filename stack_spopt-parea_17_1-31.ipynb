{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '17'\n",
    "models = '1-31'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = True\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "31\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.349368</td>\n",
       "      <td>12.120265</td>\n",
       "      <td>6.687262e+05</td>\n",
       "      <td>13.413132</td>\n",
       "      <td>12.184028</td>\n",
       "      <td>6.789011e+05</td>\n",
       "      <td>13.428232</td>\n",
       "      <td>12.199129</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.961478</td>\n",
       "      <td>13.564910</td>\n",
       "      <td>3.180461e+06</td>\n",
       "      <td>14.972537</td>\n",
       "      <td>13.575969</td>\n",
       "      <td>2.996046e+06</td>\n",
       "      <td>14.912804</td>\n",
       "      <td>13.516237</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.094058</td>\n",
       "      <td>14.374103</td>\n",
       "      <td>9.739343e+06</td>\n",
       "      <td>16.091684</td>\n",
       "      <td>14.371729</td>\n",
       "      <td>9.840726e+06</td>\n",
       "      <td>16.102040</td>\n",
       "      <td>14.382085</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.351248</td>\n",
       "      <td>13.743901</td>\n",
       "      <td>1.242492e+07</td>\n",
       "      <td>16.335215</td>\n",
       "      <td>13.727868</td>\n",
       "      <td>1.246321e+07</td>\n",
       "      <td>16.338292</td>\n",
       "      <td>13.730945</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.936413</td>\n",
       "      <td>12.391388</td>\n",
       "      <td>1.227169e+06</td>\n",
       "      <td>14.020221</td>\n",
       "      <td>12.475195</td>\n",
       "      <td>1.159105e+06</td>\n",
       "      <td>13.963160</td>\n",
       "      <td>12.418134</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "   ...  log_pred_29  log_parea_pred_29       pred_30  log_pred_30  \\\n",
       "0  ...    13.349368          12.120265  6.687262e+05    13.413132   \n",
       "1  ...    14.961478          13.564910  3.180461e+06    14.972537   \n",
       "2  ...    16.094058          14.374103  9.739343e+06    16.091684   \n",
       "3  ...    16.351248          13.743901  1.242492e+07    16.335215   \n",
       "4  ...    13.936413          12.391388  1.227169e+06    14.020221   \n",
       "\n",
       "   log_parea_pred_30       pred_31  log_pred_31  log_parea_pred_31  \\\n",
       "0          12.184028  6.789011e+05    13.428232          12.199129   \n",
       "1          13.575969  2.996046e+06    14.912804          13.516237   \n",
       "2          14.371729  9.840726e+06    16.102040          14.382085   \n",
       "3          13.727868  1.246321e+07    16.338292          13.730945   \n",
       "4          12.475195  1.159105e+06    13.963160          12.418134   \n",
       "\n",
       "   log_total_price  log_parea_total_price  \n",
       "0        13.381036              12.151933  \n",
       "1        15.015913              13.619345  \n",
       "2        16.074236              14.354282  \n",
       "3        16.469809              13.862462  \n",
       "4        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_28</th>\n",
       "      <th>pred_29</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.284537</td>\n",
       "      <td>1.458851e+07</td>\n",
       "      <td>16.495745</td>\n",
       "      <td>15.266638</td>\n",
       "      <td>1.341823e+07</td>\n",
       "      <td>16.412125</td>\n",
       "      <td>15.183018</td>\n",
       "      <td>1.235658e+07</td>\n",
       "      <td>16.329699</td>\n",
       "      <td>15.100592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.138282</td>\n",
       "      <td>3.930381e+06</td>\n",
       "      <td>15.184247</td>\n",
       "      <td>13.139628</td>\n",
       "      <td>3.931973e+06</td>\n",
       "      <td>15.184652</td>\n",
       "      <td>13.140033</td>\n",
       "      <td>3.933268e+06</td>\n",
       "      <td>15.184982</td>\n",
       "      <td>13.140363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.683307</td>\n",
       "      <td>1.053625e+07</td>\n",
       "      <td>16.170332</td>\n",
       "      <td>13.671312</td>\n",
       "      <td>1.221239e+07</td>\n",
       "      <td>16.317962</td>\n",
       "      <td>13.818941</td>\n",
       "      <td>1.039900e+07</td>\n",
       "      <td>16.157220</td>\n",
       "      <td>13.658199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.799625</td>\n",
       "      <td>5.922934e+06</td>\n",
       "      <td>15.594343</td>\n",
       "      <td>14.782410</td>\n",
       "      <td>5.957837e+06</td>\n",
       "      <td>15.600218</td>\n",
       "      <td>14.788286</td>\n",
       "      <td>5.944207e+06</td>\n",
       "      <td>15.597928</td>\n",
       "      <td>14.785996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.131217</td>\n",
       "      <td>1.092658e+06</td>\n",
       "      <td>13.904125</td>\n",
       "      <td>12.143863</td>\n",
       "      <td>1.110080e+06</td>\n",
       "      <td>13.919943</td>\n",
       "      <td>12.159682</td>\n",
       "      <td>1.140621e+06</td>\n",
       "      <td>13.947084</td>\n",
       "      <td>12.186822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3  ...  log_parea_pred_28       pred_29  log_pred_29  \\\n",
       "0   16.544464  ...          15.284537  1.458851e+07    16.495745   \n",
       "1   15.196062  ...          13.138282  3.930381e+06    15.184247   \n",
       "2   16.199646  ...          13.683307  1.053625e+07    16.170332   \n",
       "3   15.609807  ...          14.799625  5.922934e+06    15.594343   \n",
       "4   13.842395  ...          12.131217  1.092658e+06    13.904125   \n",
       "\n",
       "   log_parea_pred_29       pred_30  log_pred_30  log_parea_pred_30  \\\n",
       "0          15.266638  1.341823e+07    16.412125          15.183018   \n",
       "1          13.139628  3.931973e+06    15.184652          13.140033   \n",
       "2          13.671312  1.221239e+07    16.317962          13.818941   \n",
       "3          14.782410  5.957837e+06    15.600218          14.788286   \n",
       "4          12.143863  1.110080e+06    13.919943          12.159682   \n",
       "\n",
       "        pred_31  log_pred_31  log_parea_pred_31  \n",
       "0  1.235658e+07    16.329699          15.100592  \n",
       "1  3.933268e+06    15.184982          13.140363  \n",
       "2  1.039900e+07    16.157220          13.658199  \n",
       "3  5.944207e+06    15.597928          14.785996  \n",
       "4  1.140621e+06    13.947084          12.186822  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, idx, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv.loc[idx,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv.loc[idx,'building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score ?: 5956.210229434066; [5932.875207888342, 5964.878090273449, 5970.877390140405]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = cv.reset_index(drop=True)\n",
    "#cv = cv.head(100)\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842,\n",
    "        0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "score_list = []\n",
    "\n",
    "kf = KFold(shuffle= True)\n",
    "for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "    best_score = {}\n",
    "    best_coeffs = {}\n",
    "\n",
    "    for metric in ['mape']:\n",
    "    #for metric in ['mape', 'mae', 'mse']:\n",
    "        best_score[metric] = 0\n",
    "        best_coeffs[metric] = []\n",
    "        for x0 in x0s:\n",
    "#            print('Optimizing with init x0: {}'.format(x0))\n",
    "#            print()\n",
    "            minimize(objective, x0, args=(idx_train, metric, best_score, best_coeffs, False), tol=1e-4)\n",
    "    \n",
    "    val_pred_final = cv.loc[idx_val, cols_opt].dot(best_coeffs['mape'])\n",
    "    if is_per_area:\n",
    "        val_pred_final = np.expm1(val_pred_final) * cv.loc[idx_val, 'building_area']\n",
    "    else:\n",
    "        val_pred_final = np.expm1(val_pred_final)\n",
    "    score = cal_score(cv.loc[idx_val, 'total_price'], val_pred_final)\n",
    "    \n",
    "    score_list.append(score)\n",
    "\n",
    "print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741209262715\n",
      "coeffs:  [0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105163646\n",
      "coeffs:  [0.03125001 0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741210516372\n",
      "coeffs:  [0.03125    0.03125    0.03125001 0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105163964\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125001 0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105164584\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105164595\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125001 0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741210516832\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  4559.855291629754\n",
      "coeffs:  [0.03196446 0.03196431 0.03196447 0.03196448 0.03196452 0.03196446\n",
      " 0.03196421 0.03196452 0.03196446 0.03196447 0.03196473 0.03196448\n",
      " 0.03196444 0.03196447 0.03196447 0.03196447 0.03196447 0.03196447\n",
      " 0.03196446 0.03196447 0.03196451 0.03196452 0.03196447 0.03196448\n",
      " 0.03196447 0.03196446 0.03196446 0.03196447 0.03196447 0.03196445\n",
      " 0.03196444 0.03130284]\n",
      "\n",
      "find better score:\n",
      "score:  4559.855291716448\n",
      "coeffs:  [0.03196448 0.03196431 0.03196447 0.03196448 0.03196452 0.03196446\n",
      " 0.03196421 0.03196452 0.03196446 0.03196447 0.03196473 0.03196448\n",
      " 0.03196444 0.03196447 0.03196447 0.03196447 0.03196447 0.03196447\n",
      " 0.03196446 0.03196447 0.03196451 0.03196452 0.03196447 0.03196448\n",
      " 0.03196447 0.03196446 0.03196446 0.03196447 0.03196447 0.03196445\n",
      " 0.03196444 0.03130284]\n",
      "\n",
      "find better score:\n",
      "score:  4559.8552917164525\n",
      "coeffs:  [0.03196446 0.03196431 0.03196448 0.03196448 0.03196452 0.03196446\n",
      " 0.03196421 0.03196452 0.03196446 0.03196447 0.03196473 0.03196448\n",
      " 0.03196444 0.03196447 0.03196447 0.03196447 0.03196447 0.03196447\n",
      " 0.03196446 0.03196447 0.03196451 0.03196452 0.03196447 0.03196448\n",
      " 0.03196447 0.03196446 0.03196446 0.03196447 0.03196447 0.03196445\n",
      " 0.03196444 0.03130284]\n",
      "\n",
      "find better score:\n",
      "score:  4559.855291716473\n",
      "coeffs:  [0.03196446 0.03196431 0.03196447 0.03196448 0.03196453 0.03196446\n",
      " 0.03196421 0.03196452 0.03196446 0.03196447 0.03196473 0.03196448\n",
      " 0.03196444 0.03196447 0.03196447 0.03196447 0.03196447 0.03196447\n",
      " 0.03196446 0.03196447 0.03196451 0.03196452 0.03196447 0.03196448\n",
      " 0.03196447 0.03196446 0.03196446 0.03196447 0.03196447 0.03196445\n",
      " 0.03196444 0.03130284]\n",
      "\n",
      "find better score:\n",
      "score:  5898.87528495697\n",
      "coeffs:  [0.03205231 0.03233159 0.03214651 0.03197707 0.03250737 0.03210452\n",
      " 0.03265274 0.03247944 0.03208904 0.0321241  0.0292309  0.03227943\n",
      " 0.03224796 0.03213772 0.03211455 0.03215269 0.03215002 0.03219297\n",
      " 0.03213773 0.03214621 0.03245194 0.03247749 0.03230326 0.03250128\n",
      " 0.03219968 0.03209062 0.0322255  0.03217176 0.03219961 0.03237279\n",
      " 0.03227879 0.02837163]\n",
      "\n",
      "find better score:\n",
      "score:  5898.875284970578\n",
      "coeffs:  [0.03205232 0.03233159 0.03214651 0.03197707 0.03250737 0.03210452\n",
      " 0.03265274 0.03247944 0.03208904 0.0321241  0.0292309  0.03227943\n",
      " 0.03224796 0.03213772 0.03211455 0.03215269 0.03215002 0.03219297\n",
      " 0.03213773 0.03214621 0.03245194 0.03247749 0.03230326 0.03250128\n",
      " 0.03219968 0.03209062 0.0322255  0.03217176 0.03219961 0.03237279\n",
      " 0.03227879 0.02837163]\n",
      "\n",
      "find better score:\n",
      "score:  5898.875284970588\n",
      "coeffs:  [0.03205231 0.0323316  0.03214651 0.03197707 0.03250737 0.03210452\n",
      " 0.03265274 0.03247944 0.03208904 0.0321241  0.0292309  0.03227943\n",
      " 0.03224796 0.03213772 0.03211455 0.03215269 0.03215002 0.03219297\n",
      " 0.03213773 0.03214621 0.03245194 0.03247749 0.03230326 0.03250128\n",
      " 0.03219968 0.03209062 0.0322255  0.03217176 0.03219961 0.03237279\n",
      " 0.03227879 0.02837163]\n",
      "\n",
      "find better score:\n",
      "score:  5898.8752849706025\n",
      "coeffs:  [0.03205231 0.03233159 0.03214651 0.03197707 0.03250738 0.03210452\n",
      " 0.03265274 0.03247944 0.03208904 0.0321241  0.0292309  0.03227943\n",
      " 0.03224796 0.03213772 0.03211455 0.03215269 0.03215002 0.03219297\n",
      " 0.03213773 0.03214621 0.03245194 0.03247749 0.03230326 0.03250128\n",
      " 0.03219968 0.03209062 0.0322255  0.03217176 0.03219961 0.03237279\n",
      " 0.03227879 0.02837163]\n",
      "\n",
      "find better score:\n",
      "score:  5898.875284970604\n",
      "coeffs:  [0.03205231 0.03233159 0.03214651 0.03197707 0.03250737 0.03210452\n",
      " 0.03265274 0.03247944 0.03208904 0.0321241  0.0292309  0.03227943\n",
      " 0.03224796 0.03213772 0.03211455 0.03215269 0.03215002 0.03219297\n",
      " 0.03213773 0.03214621 0.03245194 0.03247749 0.03230326 0.03250129\n",
      " 0.03219968 0.03209062 0.0322255  0.03217176 0.03219961 0.03237279\n",
      " 0.03227879 0.02837163]\n",
      "\n",
      "find better score:\n",
      "score:  5947.875670729985\n",
      "coeffs:  [0.03174355 0.03290974 0.03222074 0.03164344 0.03391219 0.03198816\n",
      " 0.0333194  0.03371101 0.03183381 0.03205068 0.01841521 0.03280929\n",
      " 0.03253009 0.03213829 0.03201776 0.03224858 0.03229258 0.03248528\n",
      " 0.03228342 0.03220835 0.03374017 0.03380931 0.03304355 0.03410303\n",
      " 0.03253505 0.03206858 0.03252871 0.03240154 0.03249357 0.03345112\n",
      " 0.03319706 0.02053054]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634286366\n",
      "coeffs:  [ 0.02810136  0.03612786  0.03265302  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634291521\n",
      "coeffs:  [ 0.02810137  0.03612786  0.03265302  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634291523\n",
      "coeffs:  [ 0.02810136  0.03612788  0.03265302  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634291527\n",
      "coeffs:  [ 0.02810136  0.03612786  0.03265304  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5954.876634291534\n",
      "coeffs:  [ 0.02810136  0.03612786  0.03265302  0.0298861   0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634291538\n",
      "coeffs:  [ 0.02810136  0.03612786  0.03265302  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466529  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859408\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876634291542\n",
      "coeffs:  [ 0.02810136  0.03612786  0.03265302  0.02988608  0.04679009  0.030354\n",
      "  0.03349348  0.04466527  0.02900619  0.03065032 -0.07404608  0.03587842\n",
      "  0.0344696   0.03147456  0.03054581  0.03259192  0.03305291  0.03489356\n",
      "  0.03326434  0.03211842  0.04593814  0.04637895  0.03910617  0.04859409\n",
      "  0.03517602  0.03159965  0.03557354  0.03402744  0.0349711   0.04326203\n",
      "  0.04192901 -0.04727026]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876736325821\n",
      "coeffs:  [ 0.02631565  0.03673828  0.03265617  0.02989883  0.05139484  0.02948404\n",
      "  0.03283911  0.04898534  0.02761176  0.02991704 -0.10560723  0.03657756\n",
      "  0.03501372  0.03106088  0.02976538  0.03260127  0.03321949  0.03579404\n",
      "  0.03359344  0.03188895  0.0502709   0.05086228  0.04134442  0.05451298\n",
      "  0.03610698  0.03141054  0.03727217  0.03448842  0.03594753  0.04717505\n",
      "  0.04535011 -0.07268262]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876736327855\n",
      "coeffs:  [ 0.02631567  0.03673828  0.03265617  0.02989883  0.05139484  0.02948404\n",
      "  0.03283911  0.04898534  0.02761176  0.02991704 -0.10560723  0.03657756\n",
      "  0.03501372  0.03106088  0.02976538  0.03260127  0.03321949  0.03579404\n",
      "  0.03359344  0.03188895  0.0502709   0.05086228  0.04134442  0.05451298\n",
      "  0.03610698  0.03141054  0.03727217  0.03448842  0.03594753  0.04717505\n",
      "  0.04535011 -0.07268262]\n",
      "\n",
      "find better score:\n",
      "score:  5956.87673632786\n",
      "coeffs:  [ 0.02631565  0.03673828  0.03265619  0.02989883  0.05139484  0.02948404\n",
      "  0.03283911  0.04898534  0.02761176  0.02991704 -0.10560723  0.03657756\n",
      "  0.03501372  0.03106088  0.02976538  0.03260127  0.03321949  0.03579404\n",
      "  0.03359344  0.03188895  0.0502709   0.05086228  0.04134442  0.05451298\n",
      "  0.03610698  0.03141054  0.03727217  0.03448842  0.03594753  0.04717505\n",
      "  0.04535011 -0.07268262]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876736327872\n",
      "coeffs:  [ 0.02631565  0.03673828  0.03265617  0.02989884  0.05139484  0.02948404\n",
      "  0.03283911  0.04898534  0.02761176  0.02991704 -0.10560723  0.03657756\n",
      "  0.03501372  0.03106088  0.02976538  0.03260127  0.03321949  0.03579404\n",
      "  0.03359344  0.03188895  0.0502709   0.05086228  0.04134442  0.05451298\n",
      "  0.03610698  0.03141054  0.03727217  0.03448842  0.03594753  0.04717505\n",
      "  0.04535011 -0.07268262]\n",
      "\n",
      "find better score:\n",
      "score:  5956.87673632788\n",
      "coeffs:  [ 0.02631565  0.03673828  0.03265617  0.02989883  0.05139484  0.02948404\n",
      "  0.03283911  0.04898534  0.02761176  0.02991704 -0.10560722  0.03657756\n",
      "  0.03501372  0.03106088  0.02976538  0.03260127  0.03321949  0.03579404\n",
      "  0.03359344  0.03188895  0.0502709   0.05086228  0.04134442  0.05451298\n",
      "  0.03610698  0.03141054  0.03727217  0.03448842  0.03594753  0.04717505\n",
      "  0.04535011 -0.07268262]\n",
      "\n",
      "find better score:\n",
      "score:  5957.876748868787\n",
      "coeffs:  [ 0.02557332  0.03616287  0.03246045  0.03057268  0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680767  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5957.87674886905\n",
      "coeffs:  [ 0.02557334  0.03616287  0.03246045  0.03057268  0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680767  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5957.876748869053\n",
      "coeffs:  [ 0.02557332  0.03616289  0.03246045  0.03057268  0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680767  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5957.876748869056\n",
      "coeffs:  [ 0.02557332  0.03616287  0.03246047  0.03057268  0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680767  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5957.876748869068\n",
      "coeffs:  [ 0.02557332  0.03616287  0.03246045  0.0305727   0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680767  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5957.876748869079\n",
      "coeffs:  [ 0.02557332  0.03616287  0.03246045  0.03057268  0.05187493  0.02905104\n",
      "  0.03195347  0.04983855  0.02698442  0.02956723 -0.10680766  0.0361372\n",
      "  0.03494677  0.03080343  0.02939931  0.0324582   0.03309591  0.03590418\n",
      "  0.03358578  0.03163003  0.05069002  0.05132604  0.04162879  0.05589067\n",
      "  0.03615322  0.03135701  0.03809478  0.03438107  0.03608625  0.04801597\n",
      "  0.0459778  -0.07595672]\n",
      "\n",
      "find better score:\n",
      "score:  5961.87678463528\n",
      "coeffs:  [ 0.02058547  0.0322051   0.03083569  0.03577147  0.05293976  0.0259639\n",
      "  0.02627037  0.05426685  0.0227447   0.02702465 -0.097382    0.03296096\n",
      "  0.03467668  0.02881577  0.02676496  0.0311478   0.03187179  0.03607496\n",
      "  0.03315764  0.0295497   0.05138254  0.05228785  0.0423437   0.06303196\n",
      "  0.03579715  0.03085461  0.0432991   0.03306852  0.0363815   0.0521399\n",
      "  0.04874126 -0.08497985]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876818629256\n",
      "coeffs:  [ 0.01439813  0.02787394  0.02887075  0.04186065  0.05449244  0.02213497\n",
      "  0.02004458  0.06003994  0.01751792  0.02386732 -0.08871155  0.02944532\n",
      "  0.03467548  0.02636882  0.0234984   0.02954057  0.03038244  0.03634012\n",
      "  0.03259563  0.02694874  0.05246623  0.05371849  0.04319174  0.07208368\n",
      "  0.03538161  0.0301484   0.04961807  0.03145395  0.03673751  0.05726468\n",
      "  0.05220557 -0.09682144]\n",
      "\n",
      "find better score:\n",
      "score:  5962.876952276393\n",
      "coeffs:  [-3.23092422e-02  1.41035556e-02  1.67944525e-02  7.36215127e-02\n",
      "  5.96745177e-02 -5.56780123e-03  2.72215305e-02  1.02520972e-01\n",
      " -2.21498022e-02  1.39848078e-03 -8.41524403e-02  1.66858562e-02\n",
      "  4.17486285e-02  1.03579615e-02 -6.15236123e-05  1.98154782e-02\n",
      "  2.21385224e-02  4.19897214e-02  2.86672649e-02  5.93565920e-03\n",
      "  5.34823300e-02  5.77508044e-02  3.70260225e-02  1.42524031e-01\n",
      "  3.35239719e-02  2.45189954e-02  1.01111603e-01  1.94766821e-02\n",
      "  4.05081481e-02  8.80515890e-02  7.18472036e-02 -1.23453978e-01]\n",
      "\n",
      "find better score:\n",
      "score:  5964.87697325296\n",
      "coeffs:  [-0.04226688  0.00804176  0.0157348   0.079345    0.06037172 -0.01075467\n",
      "  0.02964135  0.10679263 -0.03043307 -0.00236693 -0.08793659  0.0103385\n",
      "  0.03924292  0.00832753 -0.00411311  0.01924831  0.02199665  0.0452567\n",
      "  0.02905086  0.00184134  0.05310305  0.05819088  0.03375757  0.16004171\n",
      "  0.03450521  0.02443975  0.11572626  0.01781845  0.042783    0.09466626\n",
      "  0.07560153 -0.11898984]\n",
      "\n",
      "find better score:\n",
      "score:  5967.876992022352\n",
      "coeffs:  [-0.05370664  0.00029667  0.01473722  0.08609939  0.06108718 -0.01660292\n",
      "  0.03090118  0.11095059 -0.03991788 -0.00657474 -0.08990155  0.00220028\n",
      "  0.03561209  0.00615409 -0.00865928  0.01876289  0.02199467  0.04923286\n",
      "  0.02959445 -0.00289352  0.05256164  0.05862373  0.02979528  0.18039023\n",
      "  0.03571489  0.02447141  0.13307189  0.01594193  0.04552738  0.1023457\n",
      "  0.07978068 -0.11315415]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5967.877166045031\n",
      "coeffs:  [-0.15625784  0.01778226  0.14449381  0.05341404  0.09295079  0.0019135\n",
      "  0.02524757  0.09418727 -0.08209633 -0.09760331 -0.10245647  0.01324579\n",
      "  0.02622267  0.09972387 -0.13890907  0.042903    0.14016543  0.25505775\n",
      "  0.02409596 -0.34334855 -0.01843085  0.08280336 -0.17375977  0.21606895\n",
      "  0.05726476  0.01143893  0.3286502  -0.06694676  0.0968628   0.29917526\n",
      "  0.06297503 -0.10392216]\n",
      "\n",
      "find better score:\n",
      "score:  5967.877166259798\n",
      "coeffs:  [-0.15470403  0.01676224  0.14482236  0.05321699  0.09153166  0.00225057\n",
      "  0.02577132  0.09482049 -0.07970661 -0.09727083 -0.102025    0.01358615\n",
      "  0.02607182  0.0990794  -0.13836944  0.0414198   0.1378656   0.2511216\n",
      "  0.02361488 -0.34112544 -0.01837635  0.08211892 -0.17167182  0.21830667\n",
      "  0.05682871  0.01083252  0.3322831  -0.06669301  0.09787831  0.29360866\n",
      "  0.06304621 -0.10472648]\n",
      "\n",
      "find better score:\n",
      "score:  5967.877166409793\n",
      "coeffs:  [-0.15475356  0.01573304  0.14480683  0.05377385  0.09178574  0.00215664\n",
      "  0.02552951  0.09530529 -0.07857351 -0.09871358 -0.10162792  0.01369561\n",
      "  0.02613451  0.09996949 -0.14042402  0.04019997  0.13790825  0.25098975\n",
      "  0.02433841 -0.34359279 -0.01883631  0.08267683 -0.17195644  0.21947363\n",
      "  0.05809471  0.01130294  0.33258694 -0.06637679  0.10002304  0.29213432\n",
      "  0.06314103 -0.10486121]\n",
      "\n",
      "find better score:\n",
      "score:  5968.87716643152\n",
      "coeffs:  [-0.15419934  0.01472791  0.14364942  0.05489123  0.09223263  0.00183802\n",
      "  0.02507348  0.09554017 -0.07713147 -0.0998287  -0.101256    0.01336824\n",
      "  0.02620427  0.1005469  -0.14204446  0.03870605  0.13742393  0.24979749\n",
      "  0.02547519 -0.34428444 -0.01871257  0.08346403 -0.17124111  0.22054268\n",
      "  0.05971872  0.01217207  0.33081915 -0.06524925  0.10229183  0.28918752\n",
      "  0.0631839  -0.10490493]\n",
      "\n",
      "find better score:\n",
      "score:  5968.877166724571\n",
      "coeffs:  [-0.15483885  0.01610251  0.14281469  0.05596328  0.092931    0.00119278\n",
      "  0.02559849  0.09687127 -0.07793556 -0.09980858 -0.10199902  0.01132831\n",
      "  0.02531763  0.10152071 -0.14231017  0.03854869  0.13774805  0.24969866\n",
      "  0.02556493 -0.3452415  -0.0182038   0.0844034  -0.17083025  0.22057926\n",
      "  0.05989638  0.01224548  0.33117221 -0.06536252  0.1020254   0.28872695\n",
      "  0.06320032 -0.10512102]\n",
      "\n",
      "find better score:\n",
      "score:  5968.877166724572\n",
      "coeffs:  [-0.15483886  0.01610251  0.14281469  0.05596328  0.092931    0.00119278\n",
      "  0.02559849  0.09687127 -0.07793556 -0.09980856 -0.10199902  0.01132831\n",
      "  0.02531763  0.10152071 -0.14231017  0.03854869  0.13774805  0.24969866\n",
      "  0.02556493 -0.3452415  -0.0182038   0.0844034  -0.17083025  0.22057926\n",
      "  0.05989638  0.01224548  0.33117221 -0.06536252  0.1020254   0.28872695\n",
      "  0.06320032 -0.10512102]\n",
      "\n",
      "find better score:\n",
      "score:  5968.8771671749755\n",
      "coeffs:  [-1.56854176e-01  1.80351345e-02  1.42384037e-01  5.54755292e-02\n",
      "  9.42448869e-02  1.52640362e-04  2.74612888e-02  9.53815060e-02\n",
      " -7.81374166e-02 -1.02682377e-01 -1.02601882e-01  8.08625009e-03\n",
      "  2.66291327e-02  1.09182536e-01 -1.47839605e-01  3.74962994e-02\n",
      "  1.42310880e-01  2.53706023e-01  2.77545747e-02 -3.58002891e-01\n",
      " -2.04438498e-02  8.70800592e-02 -1.72450470e-01  2.19587581e-01\n",
      "  6.35963739e-02  1.38978399e-02  3.31209129e-01 -6.56902228e-02\n",
      "  1.04891970e-01  2.89414709e-01  6.36786325e-02 -1.05596193e-01]\n",
      "\n",
      "find better score:\n",
      "score:  5968.877167175064\n",
      "coeffs:  [-1.56854161e-01  1.80351345e-02  1.42384037e-01  5.54755292e-02\n",
      "  9.42448869e-02  1.52640362e-04  2.74612888e-02  9.53815060e-02\n",
      " -7.81374166e-02 -1.02682377e-01 -1.02601882e-01  8.08625009e-03\n",
      "  2.66291327e-02  1.09182536e-01 -1.47839605e-01  3.74962994e-02\n",
      "  1.42310880e-01  2.53706023e-01  2.77545747e-02 -3.58002891e-01\n",
      " -2.04438498e-02  8.70800592e-02 -1.72450470e-01  2.19587581e-01\n",
      "  6.35963739e-02  1.38978399e-02  3.31209129e-01 -6.56902228e-02\n",
      "  1.04891970e-01  2.89414709e-01  6.36786325e-02 -1.05596193e-01]\n",
      "\n",
      "find better score:\n",
      "score:  5968.877167175065\n",
      "coeffs:  [-1.56854176e-01  1.80351345e-02  1.42384037e-01  5.54755292e-02\n",
      "  9.42448869e-02  1.52640362e-04  2.74612888e-02  9.53815060e-02\n",
      " -7.81374166e-02 -1.02682377e-01 -1.02601882e-01  8.08625009e-03\n",
      "  2.66291327e-02  1.09182551e-01 -1.47839605e-01  3.74962994e-02\n",
      "  1.42310880e-01  2.53706023e-01  2.77545747e-02 -3.58002891e-01\n",
      " -2.04438498e-02  8.70800592e-02 -1.72450470e-01  2.19587581e-01\n",
      "  6.35963739e-02  1.38978399e-02  3.31209129e-01 -6.56902228e-02\n",
      "  1.04891970e-01  2.89414709e-01  6.36786325e-02 -1.05596193e-01]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0]\n",
      "\n",
      "find better score:\n",
      "score:  5969.877031790558\n",
      "coeffs:  [-0.07633914  0.01908046  0.04715564  0.09626171  0.07163536 -0.03531958\n",
      "  0.02398886  0.1087664  -0.05732052 -0.04163452 -0.09156344 -0.00331682\n",
      "  0.02616816 -0.02545347  0.00539145  0.03669926  0.04110954  0.07321346\n",
      " -0.01387079 -0.00637282  0.01974991  0.07909496  0.02987207  0.20586191\n",
      "  0.04363977  0.03359134  0.17086198  0.01896291  0.04929472  0.08801076\n",
      "  0.06971908 -0.10491713]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-0.6100338113350916, -0.2030458414128532, 0.27365025265424203, 0.48790835909289215, -1.1892823479734076, -0.13325877664137703, -0.2017701901319427, 1.2781823480027414, -0.6336413988834858, -1.461682496181627, 1.9698389631485427, 0.5734119169593367, -1.608280641130845, -1.6981306340962743, 1.7410384115545297, 0.2788707237836989, 0.6214269714024983, 0.06859300519397646, 1.2089318056047726, 0.382089815384848, 0.889493593034382, -1.8771655390251467, 0.8688167396283558, 1.1988507203655918, -0.9738489199893658, -0.2417013411181837, 1.501309417977364, 1.5971740723736572, 0.3330964847184318, 0.7790449475517037, -1.0968514346171434, 1.261943552584088]\n",
      "\n",
      "Optimizing with init x0: [-0.5467550038568518, -0.4605198050273249, -0.08507176770400192, -0.2553311027593755, -1.1042073380350663, 0.9371018083899806, -0.33746103077940387, 0.1190814775403279, 0.07883820719979433, 0.5383576990129886, -0.9751166720426614, 0.8496151533967968, 0.17271637830962397, -0.08463314054404064, -0.39841272966982005, 1.4792690254661838, 0.12044021427022862, -0.8139857626967089, -0.09569496842782524, -1.2872340290564774, -0.5317459370597915, -0.31531018205133693, -0.017749435081047336, -0.8760328070215446, -2.089879608082457, -0.06225854476975293, 1.1631827642636894, -0.13563828856840413, 0.07122611067837742, -0.9236735709179731, -1.3797356291849285, 1.3891627236625184]\n",
      "\n",
      "Optimizing with init x0: [0.70431443358993, 1.4001076888829604, 0.884320327010969, 0.45427085219357666, -0.975695166239759, 0.9404850042333904, -3.4081648323673024, 0.04279054339349111, 3.0197567117456674, 1.163647059700144, 0.06167247587586712, -1.0845749534336793, 2.0401723133446494, -0.4814759924157046, -1.7745052568184512, -1.0377056758714556, -0.23521814590875312, -1.2975485365313633, 0.9810593935774693, 1.0929615614413883, -1.2944530959816334, 0.6477980868234815, 0.3374341454568045, 1.558299629900087, 0.4905431680568741, -0.12065253095011697, 0.5021531328702701, 1.4850613845357823, -0.02969956784452865, -1.6654726007306742, 0.25856978917046447, 0.34264527175242454]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv.index, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 5969.877031790558}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-0.07633914,  0.01908046,  0.04715564,  0.09626171,  0.07163536,\n",
       "        -0.03531958,  0.02398886,  0.1087664 , -0.05732052, -0.04163452,\n",
       "        -0.09156344, -0.00331682,  0.02616816, -0.02545347,  0.00539145,\n",
       "         0.03669926,  0.04110954,  0.07321346, -0.01387079, -0.00637282,\n",
       "         0.01974991,  0.07909496,  0.02987207,  0.20586191,  0.04363977,\n",
       "         0.03359134,  0.17086198,  0.01896291,  0.04929472,  0.08801076,\n",
       "         0.06971908, -0.10491713])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:, cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
