{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape, cal_score_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '17'\n",
    "models = '1-31'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = True\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "31\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.349368</td>\n",
       "      <td>12.120265</td>\n",
       "      <td>6.687262e+05</td>\n",
       "      <td>13.413132</td>\n",
       "      <td>12.184028</td>\n",
       "      <td>6.789011e+05</td>\n",
       "      <td>13.428232</td>\n",
       "      <td>12.199129</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.961478</td>\n",
       "      <td>13.564910</td>\n",
       "      <td>3.180461e+06</td>\n",
       "      <td>14.972537</td>\n",
       "      <td>13.575969</td>\n",
       "      <td>2.996046e+06</td>\n",
       "      <td>14.912804</td>\n",
       "      <td>13.516237</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.094058</td>\n",
       "      <td>14.374103</td>\n",
       "      <td>9.739343e+06</td>\n",
       "      <td>16.091684</td>\n",
       "      <td>14.371729</td>\n",
       "      <td>9.840726e+06</td>\n",
       "      <td>16.102040</td>\n",
       "      <td>14.382085</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.351248</td>\n",
       "      <td>13.743901</td>\n",
       "      <td>1.242492e+07</td>\n",
       "      <td>16.335215</td>\n",
       "      <td>13.727868</td>\n",
       "      <td>1.246321e+07</td>\n",
       "      <td>16.338292</td>\n",
       "      <td>13.730945</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.936413</td>\n",
       "      <td>12.391388</td>\n",
       "      <td>1.227169e+06</td>\n",
       "      <td>14.020221</td>\n",
       "      <td>12.475195</td>\n",
       "      <td>1.159105e+06</td>\n",
       "      <td>13.963160</td>\n",
       "      <td>12.418134</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "   ...  log_pred_29  log_parea_pred_29       pred_30  log_pred_30  \\\n",
       "0  ...    13.349368          12.120265  6.687262e+05    13.413132   \n",
       "1  ...    14.961478          13.564910  3.180461e+06    14.972537   \n",
       "2  ...    16.094058          14.374103  9.739343e+06    16.091684   \n",
       "3  ...    16.351248          13.743901  1.242492e+07    16.335215   \n",
       "4  ...    13.936413          12.391388  1.227169e+06    14.020221   \n",
       "\n",
       "   log_parea_pred_30       pred_31  log_pred_31  log_parea_pred_31  \\\n",
       "0          12.184028  6.789011e+05    13.428232          12.199129   \n",
       "1          13.575969  2.996046e+06    14.912804          13.516237   \n",
       "2          14.371729  9.840726e+06    16.102040          14.382085   \n",
       "3          13.727868  1.246321e+07    16.338292          13.730945   \n",
       "4          12.475195  1.159105e+06    13.963160          12.418134   \n",
       "\n",
       "   log_total_price  log_parea_total_price  \n",
       "0        13.381036              12.151933  \n",
       "1        15.015913              13.619345  \n",
       "2        16.074236              14.354282  \n",
       "3        16.469809              13.862462  \n",
       "4        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_28</th>\n",
       "      <th>pred_29</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.284537</td>\n",
       "      <td>1.458851e+07</td>\n",
       "      <td>16.495745</td>\n",
       "      <td>15.266638</td>\n",
       "      <td>1.341823e+07</td>\n",
       "      <td>16.412125</td>\n",
       "      <td>15.183018</td>\n",
       "      <td>1.235658e+07</td>\n",
       "      <td>16.329699</td>\n",
       "      <td>15.100592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.138282</td>\n",
       "      <td>3.930381e+06</td>\n",
       "      <td>15.184247</td>\n",
       "      <td>13.139628</td>\n",
       "      <td>3.931973e+06</td>\n",
       "      <td>15.184652</td>\n",
       "      <td>13.140033</td>\n",
       "      <td>3.933268e+06</td>\n",
       "      <td>15.184982</td>\n",
       "      <td>13.140363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.683307</td>\n",
       "      <td>1.053625e+07</td>\n",
       "      <td>16.170332</td>\n",
       "      <td>13.671312</td>\n",
       "      <td>1.221239e+07</td>\n",
       "      <td>16.317962</td>\n",
       "      <td>13.818941</td>\n",
       "      <td>1.039900e+07</td>\n",
       "      <td>16.157220</td>\n",
       "      <td>13.658199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.799625</td>\n",
       "      <td>5.922934e+06</td>\n",
       "      <td>15.594343</td>\n",
       "      <td>14.782410</td>\n",
       "      <td>5.957837e+06</td>\n",
       "      <td>15.600218</td>\n",
       "      <td>14.788286</td>\n",
       "      <td>5.944207e+06</td>\n",
       "      <td>15.597928</td>\n",
       "      <td>14.785996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.131217</td>\n",
       "      <td>1.092658e+06</td>\n",
       "      <td>13.904125</td>\n",
       "      <td>12.143863</td>\n",
       "      <td>1.110080e+06</td>\n",
       "      <td>13.919943</td>\n",
       "      <td>12.159682</td>\n",
       "      <td>1.140621e+06</td>\n",
       "      <td>13.947084</td>\n",
       "      <td>12.186822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3  ...  log_parea_pred_28       pred_29  log_pred_29  \\\n",
       "0   16.544464  ...          15.284537  1.458851e+07    16.495745   \n",
       "1   15.196062  ...          13.138282  3.930381e+06    15.184247   \n",
       "2   16.199646  ...          13.683307  1.053625e+07    16.170332   \n",
       "3   15.609807  ...          14.799625  5.922934e+06    15.594343   \n",
       "4   13.842395  ...          12.131217  1.092658e+06    13.904125   \n",
       "\n",
       "   log_parea_pred_29       pred_30  log_pred_30  log_parea_pred_30  \\\n",
       "0          15.266638  1.341823e+07    16.412125          15.183018   \n",
       "1          13.139628  3.931973e+06    15.184652          13.140033   \n",
       "2          13.671312  1.221239e+07    16.317962          13.818941   \n",
       "3          14.782410  5.957837e+06    15.600218          14.788286   \n",
       "4          12.143863  1.110080e+06    13.919943          12.159682   \n",
       "\n",
       "        pred_31  log_pred_31  log_parea_pred_31  \n",
       "0  1.235658e+07    16.329699          15.100592  \n",
       "1  3.933268e+06    15.184982          13.140363  \n",
       "2  1.039900e+07    16.157220          13.658199  \n",
       "3  5.944207e+06    15.597928          14.785996  \n",
       "4  1.140621e+06    13.947084          12.186822  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, idx, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv.loc[idx,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv.loc[idx,'building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score ?: 5975.543182526263; [5958.875163556781, 5986.8763753178655, 5980.878008704141]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = cv.reset_index(drop=True)\n",
    "#cv = cv.head(100)\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842,\n",
    "        0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "score_list = []\n",
    "\n",
    "kf = KFold(shuffle= True)\n",
    "for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "    best_score = {}\n",
    "    best_coeffs = {}\n",
    "\n",
    "    for metric in ['smooth']:\n",
    "    #for metric in ['mape', 'mae', 'mse']:\n",
    "        best_score[metric] = 0\n",
    "        best_coeffs[metric] = []\n",
    "        for x0 in x0s:\n",
    "#            print('Optimizing with init x0: {}'.format(x0))\n",
    "#            print()\n",
    "            minimize(objective, x0, args=(idx_train, metric, best_score, best_coeffs, False), tol=1e-4)\n",
    "    \n",
    "    val_pred_final = cv.loc[idx_val, cols_opt].dot(best_coeffs['smooth'])\n",
    "    if is_per_area:\n",
    "        val_pred_final = np.expm1(val_pred_final) * cv.loc[idx_val,'building_area']\n",
    "    else:\n",
    "        val_pred_final = np.expm1(val_pred_final)\n",
    "    score = cal_score(cv.loc[idx_val, 'total_price'], val_pred_final)\n",
    "    \n",
    "    score_list.append(score)\n",
    "\n",
    "print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741209262715\n",
      "coeffs:  [0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105163646\n",
      "coeffs:  [0.03125001 0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741210516372\n",
      "coeffs:  [0.03125    0.03125    0.03125001 0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105163964\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125001 0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105164584\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.67412105164595\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125001 0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  354.6741210516832\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  2284.7751756993\n",
      "coeffs:  [0.03256154 0.03256084 0.03256147 0.03256173 0.03256126 0.03256148\n",
      " 0.03255996 0.03256105 0.0325614  0.03256148 0.03256375 0.03256135\n",
      " 0.03256128 0.03256147 0.0325615  0.03256146 0.03256149 0.03256146\n",
      " 0.03256142 0.03256141 0.03256129 0.03256125 0.03256145 0.0325613\n",
      " 0.03256138 0.03256143 0.03256126 0.0325614  0.03256133 0.03256131\n",
      " 0.03256133 0.03134992]\n",
      "\n",
      "find better score:\n",
      "score:  5829.8695169568255\n",
      "coeffs:  [0.03224163 0.03224109 0.03224158 0.03224177 0.03224141 0.03224158\n",
      " 0.03224043 0.03224126 0.03224152 0.03224158 0.0322433  0.03224149\n",
      " 0.03224143 0.03224157 0.0322416  0.03224157 0.03224159 0.03224156\n",
      " 0.03224153 0.03224153 0.03224144 0.03224141 0.03224156 0.03224145\n",
      " 0.0322415  0.03224155 0.03224142 0.03224152 0.03224147 0.03224146\n",
      " 0.03224147 0.03132555]\n",
      "\n",
      "find better score:\n",
      "score:  5920.8739255846285\n",
      "coeffs:  [0.03220207 0.03220155 0.03220202 0.0322022  0.03220186 0.03220202\n",
      " 0.03220092 0.03220171 0.03220196 0.03220202 0.03220367 0.03220193\n",
      " 0.03220188 0.03220201 0.03220203 0.03220201 0.03220203 0.032202\n",
      " 0.03220197 0.03220197 0.03220188 0.03220186 0.032202   0.03220189\n",
      " 0.03220195 0.03220199 0.03220186 0.03220196 0.03220191 0.0322019\n",
      " 0.03220191 0.03132254]\n",
      "\n",
      "find better score:\n",
      "score:  5943.875037782587\n",
      "coeffs:  [0.03218477 0.03218426 0.03218472 0.0321849  0.03218457 0.03218472\n",
      " 0.03218364 0.03218442 0.03218467 0.03218473 0.03218634 0.03218463\n",
      " 0.03218458 0.03218472 0.03218474 0.03218471 0.03218473 0.03218471\n",
      " 0.03218468 0.03218467 0.03218459 0.03218456 0.0321847  0.0321846\n",
      " 0.03218465 0.03218469 0.03218457 0.03218467 0.03218461 0.03218461\n",
      " 0.03218462 0.03132122]\n",
      "\n",
      "find better score:\n",
      "score:  5949.874976200013\n",
      "coeffs:  [ 0.02848108  0.03945819  0.02991639  0.02910254  0.03421169  0.02979924\n",
      "  0.0349848   0.04729855  0.02922815  0.03021565 -0.02291767  0.03756594\n",
      "  0.03987757  0.02990443  0.0301812   0.03120635  0.03188136  0.03259433\n",
      "  0.03305599  0.03208468  0.03245427  0.03225176  0.04034586  0.04001167\n",
      "  0.0332292   0.03355019  0.03449599  0.03246811  0.031553    0.04238061\n",
      "  0.0400971  -0.00738579]\n",
      "\n",
      "find better score:\n",
      "score:  5962.875628101055\n",
      "coeffs:  [ 0.02515748  0.03984095  0.02765516  0.02950729  0.03545758  0.0276888\n",
      "  0.02857864  0.05684961  0.02629996  0.02868699 -0.05519632  0.0383092\n",
      "  0.04345203  0.02794852  0.02864079  0.03067311  0.0319742   0.0333942\n",
      "  0.03437967  0.03217919  0.03202657  0.03148977  0.04785778  0.04731761\n",
      "  0.03430226  0.03575112  0.03804585  0.03275719  0.03095736  0.05174302\n",
      "  0.04802423 -0.02064343]\n",
      "\n",
      "find better score:\n",
      "score:  5972.875758921555\n",
      "coeffs:  [ 0.01062572  0.03438576  0.01564979  0.03912175  0.04154583  0.01732333\n",
      "  0.04855647  0.08711376  0.01450414  0.01588763 -0.03824644  0.04075404\n",
      "  0.05786423  0.01317202  0.0149763   0.02164262  0.02376597  0.02996464\n",
      "  0.03074603  0.02241808  0.02989098  0.02848877  0.05183556  0.05981905\n",
      "  0.0280327   0.03722503  0.05508831  0.02289127  0.02229229  0.06559243\n",
      "  0.06108569 -0.05309786]\n",
      "\n",
      "find better score:\n",
      "score:  5974.876007390853\n",
      "coeffs:  [-0.00430309  0.00014639  0.00359567  0.05686346  0.05785197  0.00842705\n",
      "  0.04601643  0.1041112   0.00449103  0.00394229 -0.02758854  0.01586546\n",
      "  0.05133034 -0.00199926  0.00148647  0.01505579  0.01809494  0.03162122\n",
      "  0.03179244  0.01394794  0.03264401  0.03034881  0.06176854  0.08391566\n",
      "  0.02504023  0.04625266  0.08984769  0.01412823  0.01471     0.0919858\n",
      "  0.08571776 -0.09604499]\n",
      "\n",
      "find better score:\n",
      "score:  5979.876197288117\n",
      "coeffs:  [-0.02556585 -0.00236387 -0.01140335  0.07696475  0.07038721  0.00025037\n",
      "  0.02764319  0.13722649 -0.00289656 -0.01209044 -0.05984793  0.00912887\n",
      "  0.05574716 -0.02481918 -0.01808258  0.00850857  0.01214839  0.03990393\n",
      "  0.03407537 -0.00216202  0.01495189  0.01064657  0.05993041  0.12414116\n",
      "  0.02003044  0.06525616  0.16136722 -0.00296305 -0.00068182  0.12374142\n",
      "  0.11617076 -0.0729863 ]\n",
      "\n",
      "find better score:\n",
      "score:  5985.876653696775\n",
      "coeffs:  [-0.04605653  0.03151963 -0.0248928   0.06772483  0.14403742  0.00670256\n",
      "  0.04825459  0.11845131  0.01093238 -0.02750876 -0.11194587  0.00527699\n",
      "  0.03072023 -0.05531184 -0.04226745  0.01168191  0.01771539  0.07296206\n",
      "  0.03691829 -0.03738776  0.0202775   0.01252209 -0.01329733  0.17805204\n",
      "  0.00739171  0.10515135  0.29828721 -0.04048077 -0.03891416  0.12386618\n",
      "  0.09459006 -0.07110199]\n",
      "\n",
      "find better score:\n",
      "score:  5989.8767696511895\n",
      "coeffs:  [-0.04659384  0.05546471 -0.02384527  0.05040801  0.14162716  0.02118351\n",
      "  0.01430579  0.10551371  0.02818256 -0.02587083 -0.10781524  0.0181754\n",
      "  0.02950083 -0.06276309 -0.04528497  0.02393384  0.0326562   0.10139684\n",
      "  0.04287583 -0.05423717 -0.01693733 -0.02732382 -0.0419996   0.19466966\n",
      "  0.00336298  0.13418853  0.37534082 -0.05751616 -0.05580043  0.13396511\n",
      "  0.06683032 -0.10831684]\n",
      "\n",
      "find better score:\n",
      "score:  5994.876772769333\n",
      "coeffs:  [-0.0446566   0.04469108 -0.0229032   0.04352516  0.1428779   0.02534932\n",
      "  0.01712524  0.10665714  0.03035931 -0.0260295  -0.10823434  0.02149712\n",
      "  0.03394124 -0.06477012 -0.04592561  0.02619317  0.03621051  0.10691241\n",
      "  0.04104452 -0.06023779 -0.01938224 -0.03021183 -0.03579322  0.18993536\n",
      " -0.00082444  0.13729442  0.37844526 -0.06295558 -0.06201568  0.14546682\n",
      "  0.06371214 -0.10426455]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5998.876748409707\n",
      "coeffs:  [-0.04201284  0.04227231 -0.02446513  0.04419257  0.15377115  0.03276008\n",
      "  0.00333378  0.11507211  0.02990308 -0.02923727 -0.10346534  0.02193831\n",
      "  0.04371986 -0.07235266 -0.04971291  0.02921185  0.04280307  0.11788523\n",
      "  0.03525095 -0.07596438 -0.01483125 -0.0262999  -0.03141152  0.17762192\n",
      " -0.01221867  0.14321795  0.37389493 -0.07659412 -0.07826962  0.16173707\n",
      "  0.07509024 -0.09772082]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0]\n",
      "\n",
      "find better score:\n",
      "score:  6002.87661030072\n",
      "coeffs:  [-0.04022074  0.01043184 -0.01826028  0.0545511   0.14830453  0.03260304\n",
      "  0.01783987  0.11785695  0.03561798 -0.06369236 -0.1098837   0.0366819\n",
      "  0.05728057 -0.10344856 -0.03374385  0.03829215  0.04380739  0.11497733\n",
      " -0.00494467 -0.06550493 -0.03554945 -0.00478544  0.00489739  0.17789231\n",
      " -0.00297433  0.1460801   0.36373621 -0.06810277 -0.09173799  0.18100983\n",
      "  0.06701488 -0.08536315]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-1.9246396944334982, 1.0078496018064511, -1.1748201120541386, -0.977406380314725, 0.8422143130249589, 0.6283466139759182, -0.6900127818553948, -1.4730612880167209, 0.10144567035569169, 0.3798406667457737, 0.19630992943617467, -1.2127258429792382, 0.04880190195028937, 0.09426586154551765, -1.880153160527542, -0.05096465419127619, -2.354726899262992, -1.3291071367666842, -0.8050158919442789, 1.0346698510984074, -0.7482222798568038, -0.9751003819466662, 0.8830185679136295, -0.5534701165866343, -0.38179486993055767, -0.28221920696052943, -0.064550545141313, 3.100743297775113, -0.613884536153033, -0.6492922648190101, 1.3261821091514132, 3.033422818775435]\n",
      "\n",
      "Optimizing with init x0: [0.5265100029733415, -1.3582549199859892, -1.325778004208558, 0.31144894580582366, -1.1060196251296397, -1.3562375539119154, -0.2606753993756853, -0.7585097010625941, -1.8602875969921695, -0.18219759308102002, -1.0541934274639826, 0.2508933659301907, 0.774161023417089, -0.6228473690800014, 0.6061507308654493, 1.7436657151006925, -0.6197786502150054, -0.21307668909028568, 0.06995978214495327, -1.6665189132648648, 1.3498483189134143, 1.602616304760947, 1.3110957599935855, 0.9725038627500507, 1.1359716711417633, 1.4711991785350083, -0.2792456409826194, 2.0232059460031184, -0.1000618178014066, -0.5190461441463653, 0.1971115932345452, 1.7221342652311702]\n",
      "\n",
      "Optimizing with init x0: [0.512878949509439, -1.261631319837734, 0.647936727669646, -0.8064900071105889, -2.253720390487675, 0.008353586293825599, -1.3225831602452707, -0.35109097510072657, 0.8283720721855083, 0.38907227571825825, 0.08622227918549046, -1.1636469705017083, -0.33936205594761176, 0.3403485048954522, -0.18502214951574292, 1.6947703262029623, 0.7220914132605836, 0.20237680097891306, -0.5993664709105297, -1.830120636741942, 1.6746776446062037, -0.698144609398869, -0.49793798633765807, 1.2584504629217574, 0.3365481945119206, -1.136098822447947, 0.46547420496139186, 0.8990869625882375, 2.5922942300598257, 0.4765547211059912, -0.19008393122946451, 0.751503851698492]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842,\n",
    "        0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "for metric in ['smooth']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv.index, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smooth': 6002.87661030072}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'smooth': array([-0.04022074,  0.01043184, -0.01826028,  0.0545511 ,  0.14830453,\n",
       "         0.03260304,  0.01783987,  0.11785695,  0.03561798, -0.06369236,\n",
       "        -0.1098837 ,  0.0366819 ,  0.05728057, -0.10344856, -0.03374385,\n",
       "         0.03829215,  0.04380739,  0.11497733, -0.00494467, -0.06550493,\n",
       "        -0.03554945, -0.00478544,  0.00489739,  0.17789231, -0.00297433,\n",
       "         0.1460801 ,  0.36373621, -0.06810277, -0.09173799,  0.18100983,\n",
       "         0.06701488, -0.08536315])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['smooth'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean-log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idxs = [3, 5, 8, 12, 13, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
    "print([1/len(idxs) if i in idxs else 0 for i in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
