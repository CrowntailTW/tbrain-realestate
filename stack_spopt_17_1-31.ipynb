{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '17'\n",
    "models = '1-31'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = False\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "31\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.349368</td>\n",
       "      <td>12.120265</td>\n",
       "      <td>6.687262e+05</td>\n",
       "      <td>13.413132</td>\n",
       "      <td>12.184028</td>\n",
       "      <td>6.789011e+05</td>\n",
       "      <td>13.428232</td>\n",
       "      <td>12.199129</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.961478</td>\n",
       "      <td>13.564910</td>\n",
       "      <td>3.180461e+06</td>\n",
       "      <td>14.972537</td>\n",
       "      <td>13.575969</td>\n",
       "      <td>2.996046e+06</td>\n",
       "      <td>14.912804</td>\n",
       "      <td>13.516237</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.094058</td>\n",
       "      <td>14.374103</td>\n",
       "      <td>9.739343e+06</td>\n",
       "      <td>16.091684</td>\n",
       "      <td>14.371729</td>\n",
       "      <td>9.840726e+06</td>\n",
       "      <td>16.102040</td>\n",
       "      <td>14.382085</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.351248</td>\n",
       "      <td>13.743901</td>\n",
       "      <td>1.242492e+07</td>\n",
       "      <td>16.335215</td>\n",
       "      <td>13.727868</td>\n",
       "      <td>1.246321e+07</td>\n",
       "      <td>16.338292</td>\n",
       "      <td>13.730945</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.936413</td>\n",
       "      <td>12.391388</td>\n",
       "      <td>1.227169e+06</td>\n",
       "      <td>14.020221</td>\n",
       "      <td>12.475195</td>\n",
       "      <td>1.159105e+06</td>\n",
       "      <td>13.963160</td>\n",
       "      <td>12.418134</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "   ...  log_pred_29  log_parea_pred_29       pred_30  log_pred_30  \\\n",
       "0  ...    13.349368          12.120265  6.687262e+05    13.413132   \n",
       "1  ...    14.961478          13.564910  3.180461e+06    14.972537   \n",
       "2  ...    16.094058          14.374103  9.739343e+06    16.091684   \n",
       "3  ...    16.351248          13.743901  1.242492e+07    16.335215   \n",
       "4  ...    13.936413          12.391388  1.227169e+06    14.020221   \n",
       "\n",
       "   log_parea_pred_30       pred_31  log_pred_31  log_parea_pred_31  \\\n",
       "0          12.184028  6.789011e+05    13.428232          12.199129   \n",
       "1          13.575969  2.996046e+06    14.912804          13.516237   \n",
       "2          14.371729  9.840726e+06    16.102040          14.382085   \n",
       "3          13.727868  1.246321e+07    16.338292          13.730945   \n",
       "4          12.475195  1.159105e+06    13.963160          12.418134   \n",
       "\n",
       "   log_total_price  log_parea_total_price  \n",
       "0        13.381036              12.151933  \n",
       "1        15.015913              13.619345  \n",
       "2        16.074236              14.354282  \n",
       "3        16.469809              13.862462  \n",
       "4        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 98 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_28</th>\n",
       "      <th>pred_29</th>\n",
       "      <th>log_pred_29</th>\n",
       "      <th>log_parea_pred_29</th>\n",
       "      <th>pred_30</th>\n",
       "      <th>log_pred_30</th>\n",
       "      <th>log_parea_pred_30</th>\n",
       "      <th>pred_31</th>\n",
       "      <th>log_pred_31</th>\n",
       "      <th>log_parea_pred_31</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.284537</td>\n",
       "      <td>1.458851e+07</td>\n",
       "      <td>16.495745</td>\n",
       "      <td>15.266638</td>\n",
       "      <td>1.341823e+07</td>\n",
       "      <td>16.412125</td>\n",
       "      <td>15.183018</td>\n",
       "      <td>1.235658e+07</td>\n",
       "      <td>16.329699</td>\n",
       "      <td>15.100592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.138282</td>\n",
       "      <td>3.930381e+06</td>\n",
       "      <td>15.184247</td>\n",
       "      <td>13.139628</td>\n",
       "      <td>3.931973e+06</td>\n",
       "      <td>15.184652</td>\n",
       "      <td>13.140033</td>\n",
       "      <td>3.933268e+06</td>\n",
       "      <td>15.184982</td>\n",
       "      <td>13.140363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.683307</td>\n",
       "      <td>1.053625e+07</td>\n",
       "      <td>16.170332</td>\n",
       "      <td>13.671312</td>\n",
       "      <td>1.221239e+07</td>\n",
       "      <td>16.317962</td>\n",
       "      <td>13.818941</td>\n",
       "      <td>1.039900e+07</td>\n",
       "      <td>16.157220</td>\n",
       "      <td>13.658199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.799625</td>\n",
       "      <td>5.922934e+06</td>\n",
       "      <td>15.594343</td>\n",
       "      <td>14.782410</td>\n",
       "      <td>5.957837e+06</td>\n",
       "      <td>15.600218</td>\n",
       "      <td>14.788286</td>\n",
       "      <td>5.944207e+06</td>\n",
       "      <td>15.597928</td>\n",
       "      <td>14.785996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.131217</td>\n",
       "      <td>1.092658e+06</td>\n",
       "      <td>13.904125</td>\n",
       "      <td>12.143863</td>\n",
       "      <td>1.110080e+06</td>\n",
       "      <td>13.919943</td>\n",
       "      <td>12.159682</td>\n",
       "      <td>1.140621e+06</td>\n",
       "      <td>13.947084</td>\n",
       "      <td>12.186822</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3  ...  log_parea_pred_28       pred_29  log_pred_29  \\\n",
       "0   16.544464  ...          15.284537  1.458851e+07    16.495745   \n",
       "1   15.196062  ...          13.138282  3.930381e+06    15.184247   \n",
       "2   16.199646  ...          13.683307  1.053625e+07    16.170332   \n",
       "3   15.609807  ...          14.799625  5.922934e+06    15.594343   \n",
       "4   13.842395  ...          12.131217  1.092658e+06    13.904125   \n",
       "\n",
       "   log_parea_pred_29       pred_30  log_pred_30  log_parea_pred_30  \\\n",
       "0          15.266638  1.341823e+07    16.412125          15.183018   \n",
       "1          13.139628  3.931973e+06    15.184652          13.140033   \n",
       "2          13.671312  1.221239e+07    16.317962          13.818941   \n",
       "3          14.782410  5.957837e+06    15.600218          14.788286   \n",
       "4          12.143863  1.110080e+06    13.919943          12.159682   \n",
       "\n",
       "        pred_31  log_pred_31  log_parea_pred_31  \n",
       "0  1.235658e+07    16.329699          15.100592  \n",
       "1  3.933268e+06    15.184982          13.140363  \n",
       "2  1.039900e+07    16.157220          13.658199  \n",
       "3  5.944207e+06    15.597928          14.785996  \n",
       "4  1.140621e+06    13.947084          12.186822  \n",
       "\n",
       "[5 rows x 95 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, idx, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv.loc[idx,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv.loc[idx,'building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/model_selection/_split.py:426: FutureWarning: You should specify a value for 'n_splits' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV score ?: 5953.542888454808; [5963.87614336965, 5933.875253045275, 5962.877268949499]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = cv.reset_index(drop=True)\n",
    "#cv = cv.head(100)\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842,\n",
    "        0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "score_list = []\n",
    "\n",
    "kf = KFold(shuffle= True)\n",
    "for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "    best_score = {}\n",
    "    best_coeffs = {}\n",
    "\n",
    "    for metric in ['mape']:\n",
    "    #for metric in ['mape', 'mae', 'mse']:\n",
    "        best_score[metric] = 0\n",
    "        best_coeffs[metric] = []\n",
    "        for x0 in x0s:\n",
    "#            print('Optimizing with init x0: {}'.format(x0))\n",
    "#            print()\n",
    "            minimize(objective, x0, args=(idx_train, metric, best_score, best_coeffs, False), tol=1e-4)\n",
    "    \n",
    "    val_pred_final = cv.loc[idx_val, cols_opt].dot(best_coeffs['mape'])\n",
    "    if is_per_area:\n",
    "        val_pred_final = np.expm1(val_pred_final) * cv.loc[idx_val,'building_area']\n",
    "    else:\n",
    "        val_pred_final = np.expm1(val_pred_final)\n",
    "    score = cal_score(cv.loc[idx_val, 'total_price'], val_pred_final)\n",
    "    \n",
    "    score_list.append(score)\n",
    "\n",
    "print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125, 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  228.6362609930938\n",
      "coeffs:  [0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125 0.03125\n",
      " 0.03125 0.03125 0.03125 0.03125 0.03125]\n",
      "\n",
      "find better score:\n",
      "score:  228.6362611317718\n",
      "coeffs:  [0.03125001 0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  228.63626113177193\n",
      "coeffs:  [0.03125    0.03125    0.03125001 0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  228.6362611317767\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125001 0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  228.63626113177833\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  228.63626113182886\n",
      "coeffs:  [0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125001 0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125    0.03125    0.03125    0.03125    0.03125\n",
      " 0.03125    0.03125   ]\n",
      "\n",
      "find better score:\n",
      "score:  5008.861128718523\n",
      "coeffs:  [0.03203075 0.03203057 0.03203075 0.03203077 0.03203078 0.03203074\n",
      " 0.03203049 0.03203078 0.03203074 0.03203075 0.03203107 0.03203074\n",
      " 0.0320307  0.03203075 0.03203075 0.03203075 0.03203075 0.03203075\n",
      " 0.03203075 0.03203075 0.03203078 0.03203079 0.03203074 0.03203076\n",
      " 0.03203075 0.03203074 0.03203074 0.03203075 0.03203074 0.03203073\n",
      " 0.03203071 0.03130042]\n",
      "\n",
      "find better score:\n",
      "score:  5008.861128805858\n",
      "coeffs:  [0.03203076 0.03203057 0.03203075 0.03203077 0.03203078 0.03203074\n",
      " 0.03203049 0.03203078 0.03203074 0.03203075 0.03203107 0.03203074\n",
      " 0.0320307  0.03203075 0.03203075 0.03203075 0.03203075 0.03203075\n",
      " 0.03203075 0.03203075 0.03203078 0.03203079 0.03203074 0.03203076\n",
      " 0.03203075 0.03203074 0.03203074 0.03203075 0.03203074 0.03203073\n",
      " 0.03203071 0.03130042]\n",
      "\n",
      "find better score:\n",
      "score:  5008.861128805863\n",
      "coeffs:  [0.03203075 0.03203057 0.03203076 0.03203077 0.03203078 0.03203074\n",
      " 0.03203049 0.03203078 0.03203074 0.03203075 0.03203107 0.03203074\n",
      " 0.0320307  0.03203075 0.03203075 0.03203075 0.03203075 0.03203075\n",
      " 0.03203075 0.03203075 0.03203078 0.03203079 0.03203074 0.03203076\n",
      " 0.03203075 0.03203074 0.03203074 0.03203075 0.03203074 0.03203073\n",
      " 0.03203071 0.03130042]\n",
      "\n",
      "find better score:\n",
      "score:  5008.86112880588\n",
      "coeffs:  [0.03203075 0.03203057 0.03203075 0.03203077 0.0320308  0.03203074\n",
      " 0.03203049 0.03203078 0.03203074 0.03203075 0.03203107 0.03203074\n",
      " 0.0320307  0.03203075 0.03203075 0.03203075 0.03203075 0.03203075\n",
      " 0.03203075 0.03203075 0.03203078 0.03203079 0.03203074 0.03203076\n",
      " 0.03203075 0.03203074 0.03203074 0.03203075 0.03203074 0.03203073\n",
      " 0.03203071 0.03130042]\n",
      "\n",
      "find better score:\n",
      "score:  5008.861128805885\n",
      "coeffs:  [0.03203075 0.03203057 0.03203075 0.03203077 0.03203078 0.03203074\n",
      " 0.03203049 0.03203079 0.03203074 0.03203075 0.03203107 0.03203074\n",
      " 0.0320307  0.03203075 0.03203075 0.03203075 0.03203075 0.03203075\n",
      " 0.03203075 0.03203075 0.03203078 0.03203079 0.03203074 0.03203076\n",
      " 0.03203075 0.03203074 0.03203074 0.03203075 0.03203074 0.03203073\n",
      " 0.03203071 0.03130042]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875481365011\n",
      "coeffs:  [0.03207465 0.03239188 0.03215118 0.0320191  0.0323753  0.03211526\n",
      " 0.03256413 0.03247529 0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245497\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875481375739\n",
      "coeffs:  [0.03207466 0.03239188 0.03215118 0.0320191  0.0323753  0.03211526\n",
      " 0.03256413 0.03247529 0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245497\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5911.87548137575\n",
      "coeffs:  [0.03207465 0.0323919  0.03215118 0.0320191  0.0323753  0.03211526\n",
      " 0.03256413 0.03247529 0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245497\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5911.8754813757605\n",
      "coeffs:  [0.03207465 0.03239188 0.03215118 0.0320191  0.03237532 0.03211526\n",
      " 0.03256413 0.03247529 0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245497\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875481375761\n",
      "coeffs:  [0.03207465 0.03239188 0.03215118 0.0320191  0.0323753  0.03211526\n",
      " 0.03256413 0.0324753  0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245497\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875481375765\n",
      "coeffs:  [0.03207465 0.03239188 0.03215118 0.0320191  0.0323753  0.03211526\n",
      " 0.03256413 0.03247529 0.03210216 0.03214117 0.02983418 0.03230671\n",
      " 0.03229878 0.03215035 0.03213472 0.03216395 0.03216487 0.03219567\n",
      " 0.03216107 0.03216102 0.03233848 0.03235363 0.03231728 0.03245498\n",
      " 0.0322105  0.03212229 0.03223871 0.03218325 0.03220932 0.03237139\n",
      " 0.03229669 0.02946789]\n",
      "\n",
      "find better score:\n",
      "score:  5941.8757525138935\n",
      "coeffs:  [0.03176687 0.03296758 0.03221904 0.03158043 0.03355359 0.03199885\n",
      " 0.0331035  0.03372087 0.03187776 0.0320761  0.01921911 0.03282558\n",
      " 0.03266148 0.03215371 0.03204959 0.03225987 0.03231107 0.0324855\n",
      " 0.0323125  0.03224324 0.03343426 0.0334839  0.03304834 0.03399835\n",
      " 0.03255662 0.0321081  0.03250331 0.03243091 0.032497   0.03343514\n",
      " 0.03319741 0.02286462]\n",
      "\n",
      "find better score:\n",
      "score:  5944.875925567148\n",
      "coeffs:  [0.03137265 0.03345931 0.03226923 0.03122657 0.03496819 0.03183268\n",
      " 0.03327471 0.03511958 0.03159489 0.0319452  0.00761875 0.03330701\n",
      " 0.03295388 0.03210078 0.03190963 0.03233035 0.03242757 0.03278782\n",
      " 0.03244992 0.03227453 0.03478045 0.03487272 0.03382918 0.03571782\n",
      " 0.03290553 0.03206418 0.03280479 0.03266265 0.03281256 0.03462507\n",
      " 0.0341803  0.01572263]\n",
      "\n",
      "find better score:\n",
      "score:  5948.87623358664\n",
      "coeffs:  [ 0.03040032  0.03452861  0.0323913   0.03047184  0.03820076  0.03140351\n",
      "  0.03373706  0.03833291  0.03086845  0.03160369 -0.01919902  0.03441146\n",
      "  0.03367104  0.03195827  0.03154211  0.03248514  0.03269622  0.03350516\n",
      "  0.03276154  0.03231493  0.03788227  0.03807949  0.03564304  0.03978825\n",
      "  0.03370335  0.03194037  0.03361115  0.033179    0.03353642  0.03743661\n",
      "  0.03664773 -0.00095593]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5958.876627948367\n",
      "coeffs:  [ 0.02787818  0.03637302  0.03259742  0.02941103  0.04604568  0.03024134\n",
      "  0.03408882  0.0457697   0.0289421   0.0306263  -0.07975444  0.03636437\n",
      "  0.03502899  0.03149795  0.03051846  0.03274055  0.0332368   0.03518183\n",
      "  0.03342985  0.03224797  0.04530024  0.04575447  0.03972202  0.0495342\n",
      "  0.03549926  0.03162705  0.03588846  0.03424779  0.03520987  0.04408628\n",
      "  0.04257159 -0.03911001]\n",
      "\n",
      "find better score:\n",
      "score:  5960.876668142638\n",
      "coeffs:  [ 0.02635538  0.03645316  0.03251682  0.02965929  0.0493096   0.02946144\n",
      "  0.03329448  0.04888462  0.02777094  0.02999079 -0.10128821  0.03657154\n",
      "  0.03536909  0.03111985  0.02984551  0.0326986   0.03331159  0.03584088\n",
      "  0.03364813  0.03199743  0.04834688  0.04893121  0.04128503  0.05396502\n",
      "  0.03614813  0.03146285  0.03738042  0.03451507  0.03587883  0.04703462\n",
      "  0.04503235 -0.05367066]\n",
      "\n",
      "find better score:\n",
      "score:  5960.876675515882\n",
      "coeffs:  [ 0.02534738  0.03593241  0.03230726  0.03039076  0.0505514   0.02887792\n",
      "  0.03227882  0.05011632  0.02697275  0.02951279 -0.1059009   0.03609692\n",
      "  0.03532071  0.03076834  0.02934317  0.03252014  0.03317312  0.03603038\n",
      "  0.03364841  0.03168489  0.04946513  0.05012016  0.0417362   0.0559767\n",
      "  0.03628028  0.03134461  0.03838965  0.03443247  0.03608894  0.04827385\n",
      "  0.04596027 -0.05787323]\n",
      "\n",
      "find better score:\n",
      "score:  5960.876675515889\n",
      "coeffs:  [ 0.02534738  0.03593241  0.03230726  0.03039077  0.0505514   0.02887792\n",
      "  0.03227882  0.05011632  0.02697275  0.02951279 -0.1059009   0.03609692\n",
      "  0.03532071  0.03076834  0.02934317  0.03252014  0.03317312  0.03603038\n",
      "  0.03364841  0.03168489  0.04946513  0.05012016  0.0417362   0.0559767\n",
      "  0.03628028  0.03134461  0.03838965  0.03443247  0.03608894  0.04827385\n",
      "  0.04596027 -0.05787323]\n",
      "\n",
      "find better score:\n",
      "score:  5960.876675515894\n",
      "coeffs:  [ 0.02534738  0.03593241  0.03230726  0.03039076  0.0505514   0.02887792\n",
      "  0.03227882  0.05011632  0.02697275  0.02951279 -0.10590088  0.03609692\n",
      "  0.03532071  0.03076834  0.02934317  0.03252014  0.03317312  0.03603038\n",
      "  0.03364841  0.03168489  0.04946513  0.05012016  0.0417362   0.0559767\n",
      "  0.03628028  0.03134461  0.03838965  0.03443247  0.03608894  0.04827385\n",
      "  0.04596027 -0.05787323]\n",
      "\n",
      "find better score:\n",
      "score:  5962.876833694251\n",
      "coeffs:  [-0.01828306  0.016543    0.0189495   0.0697342   0.06921163  0.0017618\n",
      "  0.01124159  0.09150319 -0.00856064  0.00675651 -0.07971982  0.0170781\n",
      "  0.03873611  0.01277131  0.00561006  0.02044499  0.02210729  0.03703168\n",
      "  0.02841257  0.01254625  0.0641091   0.06719686  0.04132482  0.11684462\n",
      "  0.03288745  0.02425967  0.08066227  0.02293471  0.03746197  0.07884784\n",
      "  0.06445002 -0.08641056]\n",
      "\n",
      "find better score:\n",
      "score:  5964.876847967773\n",
      "coeffs:  [-0.02607576  0.01676677  0.01716873  0.07458746  0.06923323 -0.00286757\n",
      "  0.01677707  0.09966099 -0.01487718  0.00292342 -0.08510312  0.01669476\n",
      "  0.04081968  0.00998547  0.00155307  0.01872286  0.02065919  0.03781411\n",
      "  0.02762875  0.00894727  0.06370942  0.06726098  0.0398056   0.12869177\n",
      "  0.0325964   0.0229788   0.08913999  0.02108234  0.03797428  0.08368674\n",
      "  0.0669131  -0.08679859]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949416\n",
      "coeffs:  [-0.03149251  0.01500494  0.01619787  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876049\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786462\n",
      "  0.03282082  0.02240421  0.09572412  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949587\n",
      "coeffs:  [-0.03149249  0.01500494  0.01619787  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876049\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786462\n",
      "  0.03282082  0.02240421  0.09572412  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949591\n",
      "coeffs:  [-0.03149251  0.01500494  0.01619788  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876049\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786462\n",
      "  0.03282082  0.02240421  0.09572412  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949592\n",
      "coeffs:  [-0.03149251  0.01500494  0.01619787  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876051\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786462\n",
      "  0.03282082  0.02240421  0.09572412  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949595\n",
      "coeffs:  [-0.03149251  0.01500494  0.01619787  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876049\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786464\n",
      "  0.03282082  0.02240421  0.09572412  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876856949598\n",
      "coeffs:  [-0.03149251  0.01500494  0.01619787  0.07829945  0.07022922 -0.00595835\n",
      "  0.0177551   0.10437564 -0.01918812  0.00046438 -0.09067641  0.01471608\n",
      "  0.04076543  0.00828911 -0.00106625  0.01781814  0.01995472  0.03876049\n",
      "  0.027451    0.00671168  0.06435536  0.06826063  0.03920969  0.13786462\n",
      "  0.03282082  0.02240421  0.09572414  0.02013871  0.03877113  0.08779311\n",
      "  0.06928782 -0.08989108]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0]\n",
      "\n",
      "find better score:\n",
      "score:  5967.875615290288\n",
      "coeffs:  [0.         0.         0.05263158 0.         0.05263158 0.\n",
      " 0.         0.05263158 0.         0.         0.         0.05263158\n",
      " 0.05263158 0.         0.05263158 0.05263158 0.05263158 0.05263158\n",
      " 0.         0.05263158 0.         0.05263158 0.05263158 0.05263158\n",
      " 0.05263158 0.05263158 0.05263158 0.05263158 0.05263158 0.\n",
      " 0.05263158 0.        ]\n",
      "\n",
      "find better score:\n",
      "score:  5967.876864732974\n",
      "coeffs:  [-0.04451305  0.01554676  0.04277345  0.08348524  0.08342526 -0.02442229\n",
      "  0.02469982  0.09148885 -0.03243444 -0.0288779  -0.08703782  0.00519713\n",
      "  0.03297476 -0.02196949  0.02124937  0.03620286  0.03864656  0.05404498\n",
      " -0.01135417  0.02154517  0.03235905  0.08781572  0.06278014  0.13330872\n",
      "  0.04461335  0.03728363  0.1014006   0.03370472  0.0467694   0.05973887\n",
      "  0.06474666 -0.09147154]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-1.0002816207289291, 0.8691142193256435, -1.274593543507279, -0.0779756333541868, -0.20610742103419472, 0.4070408143466146, 0.4774126130344732, -1.0008209208579426, -0.439125127889783, -0.21725806695024838, 0.13701729669915785, 0.7151621143278234, 1.8484122348784255, -0.7106097962812747, 0.38359106456607756, -0.5116532089218171, -1.121776952663538, -0.6663317249733918, 0.09025391324086693, 0.8711553651693659, -1.0508298931292392, -0.20565958861547584, -0.6915383376782511, -0.7718862664896665, -0.46212994851815886, -0.6301641734863925, -0.7570704974409744, 1.2847203651427057, 0.42038450004015876, -0.009274428761146182, -2.167099473395166, -1.9848805360476711]\n",
      "\n",
      "Optimizing with init x0: [-1.7211276202790733, 0.2821952493733353, -0.12568715556383206, -1.4327786749016507, -0.5191585186317217, -0.550185288318647, 1.9135545996782932, 0.18629908102060921, 0.6328894250307792, -0.6017552688156182, 1.3554739608344475, -1.6892385550859053, -1.5458406323876936, -0.7055417716106268, -0.3310598457986617, 1.5472387161156345, 0.1143209944051645, 0.7755620249286517, 0.2716078654292209, 0.2534013533173143, 1.5611171552928944, 0.47527322275334133, 0.8303816005801982, 0.19325065459132174, 0.3057633967504993, 0.445470077742885, -0.413748410245703, -0.5004345902745122, 0.3715775899197594, -0.6015295576020724, 2.5497903070917567, 0.07175330825302796]\n",
      "\n",
      "Optimizing with init x0: [-0.27305416249410464, 0.44812916747104514, -0.564206855437378, 1.1618197113630995, 0.47719380531716304, 0.885894004463019, 0.1817429487536346, -0.8319465520001037, 1.9579639270236209, 0.16043780421552345, -0.49781481629650903, -0.7285114212107547, -0.13286538914147875, -0.28434317732806214, 0.17136560294362624, -0.2748433595473331, 1.4510644625444054, -0.6139688806164282, 0.6872289226275063, 2.1688626853829818, 0.11496713105992294, -0.10794068035483168, 0.6787834562118102, 0.4902736952136441, 1.0998289059422135, -1.497758581866868, 0.4463535247221116, 0.6169807465270593, -0.2349054583503739, 0.07316890674446462, -1.9473988802939097, -0.8037080376132378]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842,\n",
    "        0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842,\n",
    "        0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842,\n",
    "        0],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv.index, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 5967.876864732974}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-0.04451305,  0.01554676,  0.04277345,  0.08348524,  0.08342526,\n",
       "        -0.02442229,  0.02469982,  0.09148885, -0.03243444, -0.0288779 ,\n",
       "        -0.08703782,  0.00519713,  0.03297476, -0.02196949,  0.02124937,\n",
       "         0.03620286,  0.03864656,  0.05404498, -0.01135417,  0.02154517,\n",
       "         0.03235905,  0.08781572,  0.06278014,  0.13330872,  0.04461335,\n",
       "         0.03728363,  0.1014006 ,  0.03370472,  0.0467694 ,  0.05973887,\n",
       "         0.06474666, -0.09147154])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
