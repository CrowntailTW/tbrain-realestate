{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '20'\n",
    "models = '1-37'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = True\n",
    "add_intercept = True\n",
    "is_cv_on_opt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n",
      "32 model-32-lgb-remove_outlier_01-cv.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-kfold.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-one.csv\n",
      "33 model-33-lgb-remove_outlier_03-cv.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-kfold.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-one.csv\n",
      "34 model-34-lgb-remove_outlier_01-cv.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-kfold.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-one.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-cv.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-test-kfold.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-test-one.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-kfold.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "37 model-37-lgb-remove_outlier_05-cv.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-kfold.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "37\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n",
      "model-32-lgb-remove_outlier_01-cv.csv\n",
      "model-33-lgb-remove_outlier_03-cv.csv\n",
      "model-34-lgb-remove_outlier_01-cv.csv\n",
      "model-35-lgb-remove_outlier_03-2-cv.csv\n",
      "model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "model-37-lgb-remove_outlier_05-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n",
      "No. 31 file: model-32-lgb-remove_outlier_01-test-one.csv\n",
      "No. 32 file: model-33-lgb-remove_outlier_03-test-one.csv\n",
      "No. 33 file: model-34-lgb-remove_outlier_01-test-one.csv\n",
      "No. 34 file: model-35-lgb-remove_outlier_03-2-test-one.csv\n",
      "No. 35 file: model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "No. 36 file: model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_35</th>\n",
       "      <th>log_parea_pred_35</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.336691</td>\n",
       "      <td>12.107588</td>\n",
       "      <td>6.245441e+05</td>\n",
       "      <td>13.344779</td>\n",
       "      <td>12.115676</td>\n",
       "      <td>6.319899e+05</td>\n",
       "      <td>13.356630</td>\n",
       "      <td>12.127527</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.942103</td>\n",
       "      <td>13.545536</td>\n",
       "      <td>3.042045e+06</td>\n",
       "      <td>14.928041</td>\n",
       "      <td>13.531473</td>\n",
       "      <td>3.142342e+06</td>\n",
       "      <td>14.960479</td>\n",
       "      <td>13.563912</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.098990</td>\n",
       "      <td>14.379035</td>\n",
       "      <td>9.818275e+06</td>\n",
       "      <td>16.099756</td>\n",
       "      <td>14.379801</td>\n",
       "      <td>9.946933e+06</td>\n",
       "      <td>16.112775</td>\n",
       "      <td>14.392820</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.352854</td>\n",
       "      <td>13.745507</td>\n",
       "      <td>1.264691e+07</td>\n",
       "      <td>16.352924</td>\n",
       "      <td>13.745577</td>\n",
       "      <td>1.295773e+07</td>\n",
       "      <td>16.377203</td>\n",
       "      <td>13.769857</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.749632</td>\n",
       "      <td>12.204607</td>\n",
       "      <td>9.305770e+05</td>\n",
       "      <td>13.743561</td>\n",
       "      <td>12.198536</td>\n",
       "      <td>9.859947e+05</td>\n",
       "      <td>13.801407</td>\n",
       "      <td>12.256382</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "           ...            log_pred_35  log_parea_pred_35       pred_36  \\\n",
       "0          ...              13.336691          12.107588  6.245441e+05   \n",
       "1          ...              14.942103          13.545536  3.042045e+06   \n",
       "2          ...              16.098990          14.379035  9.818275e+06   \n",
       "3          ...              16.352854          13.745507  1.264691e+07   \n",
       "4          ...              13.749632          12.204607  9.305770e+05   \n",
       "\n",
       "   log_pred_36  log_parea_pred_36       pred_37  log_pred_37  \\\n",
       "0    13.344779          12.115676  6.319899e+05    13.356630   \n",
       "1    14.928041          13.531473  3.142342e+06    14.960479   \n",
       "2    16.099756          14.379801  9.946933e+06    16.112775   \n",
       "3    16.352924          13.745577  1.295773e+07    16.377203   \n",
       "4    13.743561          12.198536  9.859947e+05    13.801407   \n",
       "\n",
       "   log_parea_pred_37  log_total_price  log_parea_total_price  \n",
       "0          12.127527        13.381036              12.151933  \n",
       "1          13.563912        15.015913              13.619345  \n",
       "2          14.392820        16.074236              14.354282  \n",
       "3          13.769857        16.469809              13.862462  \n",
       "4          12.256382        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_35</th>\n",
       "      <th>log_pred_35</th>\n",
       "      <th>log_parea_pred_35</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.124128</td>\n",
       "      <td>1.313244e+07</td>\n",
       "      <td>16.390596</td>\n",
       "      <td>15.161489</td>\n",
       "      <td>1.298618e+07</td>\n",
       "      <td>16.379396</td>\n",
       "      <td>15.150290</td>\n",
       "      <td>1.304845e+07</td>\n",
       "      <td>16.384180</td>\n",
       "      <td>15.155073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.129532</td>\n",
       "      <td>3.896216e+06</td>\n",
       "      <td>15.175517</td>\n",
       "      <td>13.130898</td>\n",
       "      <td>3.897411e+06</td>\n",
       "      <td>15.175823</td>\n",
       "      <td>13.131204</td>\n",
       "      <td>3.897545e+06</td>\n",
       "      <td>15.175858</td>\n",
       "      <td>13.131239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.694473</td>\n",
       "      <td>1.078764e+07</td>\n",
       "      <td>16.193911</td>\n",
       "      <td>13.694891</td>\n",
       "      <td>1.049745e+07</td>\n",
       "      <td>16.166643</td>\n",
       "      <td>13.667623</td>\n",
       "      <td>1.035078e+07</td>\n",
       "      <td>16.152573</td>\n",
       "      <td>13.653552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.808651</td>\n",
       "      <td>6.102227e+06</td>\n",
       "      <td>15.624164</td>\n",
       "      <td>14.812232</td>\n",
       "      <td>6.139949e+06</td>\n",
       "      <td>15.630327</td>\n",
       "      <td>14.818395</td>\n",
       "      <td>6.120593e+06</td>\n",
       "      <td>15.627170</td>\n",
       "      <td>14.815237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.143297</td>\n",
       "      <td>1.104233e+06</td>\n",
       "      <td>13.914662</td>\n",
       "      <td>12.154401</td>\n",
       "      <td>1.106728e+06</td>\n",
       "      <td>13.916919</td>\n",
       "      <td>12.156657</td>\n",
       "      <td>1.098338e+06</td>\n",
       "      <td>13.909310</td>\n",
       "      <td>12.149048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3        ...          log_parea_pred_34       pred_35  \\\n",
       "0   16.544464        ...                  15.124128  1.313244e+07   \n",
       "1   15.196062        ...                  13.129532  3.896216e+06   \n",
       "2   16.199646        ...                  13.694473  1.078764e+07   \n",
       "3   15.609807        ...                  14.808651  6.102227e+06   \n",
       "4   13.842395        ...                  12.143297  1.104233e+06   \n",
       "\n",
       "   log_pred_35  log_parea_pred_35       pred_36  log_pred_36  \\\n",
       "0    16.390596          15.161489  1.298618e+07    16.379396   \n",
       "1    15.175517          13.130898  3.897411e+06    15.175823   \n",
       "2    16.193911          13.694891  1.049745e+07    16.166643   \n",
       "3    15.624164          14.812232  6.139949e+06    15.630327   \n",
       "4    13.914662          12.154401  1.106728e+06    13.916919   \n",
       "\n",
       "   log_parea_pred_36       pred_37  log_pred_37  log_parea_pred_37  \n",
       "0          15.150290  1.304845e+07    16.384180          15.155073  \n",
       "1          13.131204  3.897545e+06    15.175858          13.131239  \n",
       "2          13.667623  1.035078e+07    16.152573          13.653552  \n",
       "3          14.818395  6.120593e+06    15.627170          14.815237  \n",
       "4          12.156657  1.098338e+06    13.909310          12.149048  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n",
      "31 model-32 5930.875106\n",
      "32 model-33 5976.875715\n",
      "33 model-34 5942.875172\n",
      "34 model-35 5982.876110\n",
      "35 model-36 5989.876236\n",
      "36 model-37 5980.875836\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, idx, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv.loc[idx,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv.loc[idx,'building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv.loc[idx,'total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "      ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "if is_cv_on_opt:\n",
    "    cv = cv.reset_index(drop=True)\n",
    "    #cv = cv.head(100)\n",
    "\n",
    "    score_list = []\n",
    "\n",
    "    kf = KFold(shuffle= True)\n",
    "    for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "        best_score = {}\n",
    "        best_coeffs = {}\n",
    "\n",
    "        for metric in ['mape']:\n",
    "        #for metric in ['mape', 'mae', 'mse']:\n",
    "            best_score[metric] = 0\n",
    "            best_coeffs[metric] = []\n",
    "            for x0 in x0s:\n",
    "                print('Optimizing with init x0: {}'.format(x0))\n",
    "                print()\n",
    "                minimize(objective, x0, args=(idx_train, metric, best_score, best_coeffs, True), \n",
    "                         tol=1e-4)\n",
    "\n",
    "        val_pred_final = cv.loc[idx_val, cols_opt].dot(best_coeffs['mape'])\n",
    "        if is_per_area:\n",
    "            val_pred_final = np.expm1(val_pred_final) * cv.loc[idx_val, 'building_area']\n",
    "        else:\n",
    "            val_pred_final = np.expm1(val_pred_final)\n",
    "        score = cal_score(cv.loc[idx_val, 'total_price'], val_pred_final)\n",
    "\n",
    "        score_list.append(score)\n",
    "\n",
    "    print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421]\n",
      "\n",
      "find better score:\n",
      "score:  565.71333926492\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940665\n",
      "coeffs:  [0.0263158  0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940679\n",
      "coeffs:  [0.02631579 0.02631579 0.0263158  0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940707\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.0263158  0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940768\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.0263158  0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940825\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.0263158  0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  565.7133393940985\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.0263158  0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  5918.875873552535\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.8758735645615\n",
      "coeffs:  [0.02693951 0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.875873564586\n",
      "coeffs:  [0.0269395  0.02693941 0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.87587356459\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693956 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.875873564598\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693959 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.875873564616\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693959 0.02693956 0.02693958 0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.87587356462\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.0269396  0.02693959\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.875873564622\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.0269396\n",
      " 0.02693959 0.02636184]\n",
      "\n",
      "find better score:\n",
      "score:  5918.87587356463\n",
      "coeffs:  [0.0269395  0.0269394  0.02693951 0.02693952 0.02693955 0.0269395\n",
      " 0.02693933 0.02693958 0.02693949 0.0269395  0.02693965 0.02693954\n",
      " 0.02693951 0.0269395  0.0269395  0.0269395  0.0269395  0.0269395\n",
      " 0.0269395  0.0269395  0.02693955 0.02693955 0.02693951 0.02693952\n",
      " 0.0269395  0.02693949 0.02693949 0.0269395  0.0269395  0.0269395\n",
      " 0.02693948 0.02693956 0.02693958 0.02693956 0.02693958 0.02693959\n",
      " 0.0269396  0.02636184]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5945.876165634015\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634859\n",
      "coeffs:  [0.02672705 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634886\n",
      "coeffs:  [0.02672704 0.0271658  0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634893\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729205 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.8761656349125\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759459 0.02724897 0.02765814 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634916\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765816 0.02770276\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634919\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770278\n",
      " 0.02781771 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5945.876165634925\n",
      "coeffs:  [0.02672704 0.02716579 0.02681117 0.02671055 0.02716578 0.0267725\n",
      " 0.0272334  0.02729203 0.02674442 0.02677083 0.02432402 0.02714655\n",
      " 0.02708513 0.02678505 0.02676659 0.02680269 0.02681432 0.0268447\n",
      " 0.02679643 0.02678671 0.02713109 0.02714132 0.02701061 0.02713916\n",
      " 0.02684237 0.02675505 0.02684164 0.02682588 0.02684997 0.02706701\n",
      " 0.02702101 0.02723766 0.02759458 0.02724897 0.02765814 0.02770276\n",
      " 0.02781773 0.02457066]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876410405357\n",
      "coeffs:  [0.02563523 0.02821273 0.02616797 0.02565031 0.02820639 0.02590225\n",
      " 0.02819634 0.0289271  0.02574922 0.02586722 0.01181615 0.02805438\n",
      " 0.0277734  0.02596186 0.02585432 0.02606165 0.02612321 0.02631577\n",
      " 0.02602618 0.0259557  0.02806201 0.02810318 0.02728013 0.02800813\n",
      " 0.02628816 0.0257937  0.02626986 0.02620778 0.02635285 0.02762042\n",
      " 0.0274619  0.02856233 0.03068675 0.02862909 0.03106978 0.03132807\n",
      " 0.03196485 0.01642031]\n",
      "\n",
      "find better score:\n",
      "score:  5972.8768612015865\n",
      "coeffs:  [ 0.02324685  0.03020609  0.02478028  0.02344161  0.03048297  0.02400794\n",
      "  0.029942    0.03229264  0.02356907  0.02388956 -0.01396517  0.02975974\n",
      "  0.02906541  0.02415667  0.02385707  0.02444312  0.02460604  0.02515235\n",
      "  0.02434327  0.0241299   0.03009618  0.03020417  0.02776858  0.02981896\n",
      "  0.02506008  0.02370931  0.02506911  0.02483621  0.02524582  0.02876371\n",
      "  0.02846435  0.03143466  0.03737474  0.03161856  0.0384441   0.03917139\n",
      "  0.04098948 -0.00065238]\n",
      "\n",
      "find better score:\n",
      "score:  5986.877581285943\n",
      "coeffs:  [ 0.01785986  0.0339933   0.02165628  0.01903352  0.03551445  0.01974575\n",
      "  0.03305784  0.03934142  0.01866939  0.01941826 -0.06844841  0.0329229\n",
      "  0.03153977  0.02007145  0.01935317  0.02077569  0.02115413  0.02249334\n",
      "  0.02049394  0.01992494  0.03458022  0.03485386  0.02885577  0.03375725\n",
      "  0.02217713  0.01899316  0.02251749  0.02163703  0.0227124   0.0313316\n",
      "  0.03057066  0.03784939  0.05235879  0.03829348  0.05498576  0.05676979\n",
      "  0.06133954 -0.03682211]\n",
      "\n",
      "find better score:\n",
      "score:  6000.878040872252\n",
      "coeffs:  [ 0.00939309  0.03812859  0.01682615  0.01291721  0.04294997  0.01304036\n",
      "  0.0361078   0.04919251  0.01092095  0.01240113 -0.1442276   0.03626514\n",
      "  0.03436731  0.01369107  0.0122702   0.01499964  0.01570011  0.01824728\n",
      "  0.01439306  0.01319642  0.04108655  0.04162377  0.03044592  0.03973616\n",
      "  0.01748116  0.01163908  0.01902228  0.0164555   0.0186929   0.03528314\n",
      "  0.03343878  0.04770092  0.0756812   0.04857475  0.0806926   0.08412296\n",
      "  0.09332922 -0.08831384]\n",
      "\n",
      "find better score:\n",
      "score:  6000.878710418723\n",
      "coeffs:  [-0.02501674  0.01159567 -0.00071318  0.0178903   0.05318596 -0.01338934\n",
      "  0.01115973  0.05898581 -0.02044581 -0.01817947 -0.11358651  0.01626318\n",
      "  0.0226647  -0.01391916 -0.01844587 -0.01188614 -0.01039386 -0.00404373\n",
      " -0.01615104 -0.02218484  0.04744081  0.04918975  0.03247969  0.05240084\n",
      " -0.011359   -0.02057306  0.02078946 -0.0127607  -0.00099467  0.04649\n",
      "  0.04423985  0.0722407   0.1516605   0.07558454  0.16597916  0.17584153\n",
      "  0.21556448 -0.11571048]\n",
      "\n",
      "find better score:\n",
      "score:  6000.8787104193225\n",
      "coeffs:  [-0.02501673  0.01159567 -0.00071318  0.0178903   0.05318596 -0.01338934\n",
      "  0.01115973  0.05898581 -0.02044581 -0.01817947 -0.11358651  0.01626318\n",
      "  0.0226647  -0.01391916 -0.01844587 -0.01188614 -0.01039386 -0.00404373\n",
      " -0.01615104 -0.02218484  0.04744081  0.04918975  0.03247969  0.05240084\n",
      " -0.011359   -0.02057306  0.02078946 -0.0127607  -0.00099467  0.04649\n",
      "  0.04423985  0.0722407   0.1516605   0.07558454  0.16597916  0.17584153\n",
      "  0.21556448 -0.11571048]\n",
      "\n",
      "find better score:\n",
      "score:  6000.878710419347\n",
      "coeffs:  [-0.02501674  0.01159569 -0.00071318  0.0178903   0.05318596 -0.01338934\n",
      "  0.01115973  0.05898581 -0.02044581 -0.01817947 -0.11358651  0.01626318\n",
      "  0.0226647  -0.01391916 -0.01844587 -0.01188614 -0.01039386 -0.00404373\n",
      " -0.01615104 -0.02218484  0.04744081  0.04918975  0.03247969  0.05240084\n",
      " -0.011359   -0.02057306  0.02078946 -0.0127607  -0.00099467  0.04649\n",
      "  0.04423985  0.0722407   0.1516605   0.07558454  0.16597916  0.17584153\n",
      "  0.21556448 -0.11571048]\n",
      "\n",
      "find better score:\n",
      "score:  6000.878710419355\n",
      "coeffs:  [-0.02501674  0.01159567 -0.00071318  0.0178903   0.05318596 -0.01338934\n",
      "  0.01115974  0.05898581 -0.02044581 -0.01817947 -0.11358651  0.01626318\n",
      "  0.0226647  -0.01391916 -0.01844587 -0.01188614 -0.01039386 -0.00404373\n",
      " -0.01615104 -0.02218484  0.04744081  0.04918975  0.03247969  0.05240084\n",
      " -0.011359   -0.02057306  0.02078946 -0.0127607  -0.00099467  0.04649\n",
      "  0.04423985  0.0722407   0.1516605   0.07558454  0.16597916  0.17584153\n",
      "  0.21556448 -0.11571048]\n",
      "\n",
      "find better score:\n",
      "score:  6009.878738862841\n",
      "coeffs:  [-2.45839621e-02  1.41935905e-02  6.47326312e-05  1.86708574e-02\n",
      "  5.25030288e-02 -1.28359597e-02  1.50271236e-02  6.06937668e-02\n",
      " -2.00067837e-02 -1.80839240e-02 -1.04108966e-01  1.88589152e-02\n",
      "  2.51569373e-02 -1.37669198e-02 -1.83382268e-02 -1.19038090e-02\n",
      " -1.04240147e-02 -4.19558450e-03 -1.68250323e-02 -2.27544719e-02\n",
      "  4.67147921e-02  4.84629067e-02  3.27872989e-02  5.20834782e-02\n",
      " -1.20269520e-02 -2.12643807e-02  2.11614697e-02 -1.31552621e-02\n",
      " -1.03235428e-03  4.62655361e-02  4.44490644e-02  6.94010969e-02\n",
      "  1.47417908e-01  7.28175534e-02  1.61853262e-01  1.71787310e-01\n",
      "  2.12009994e-01 -1.07264093e-01]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6009.878772854012\n",
      "coeffs:  [-0.0277781   0.01904403  0.00029299  0.01881709  0.05378404 -0.01458505\n",
      "  0.02298416  0.06711363 -0.02274517 -0.02146482 -0.10307538  0.02422978\n",
      "  0.03003961 -0.01652904 -0.0216996  -0.0149438  -0.01336654 -0.00691004\n",
      " -0.0223574  -0.02840893  0.04738081  0.0493178   0.03481827  0.0547765\n",
      " -0.01682755 -0.02748375  0.0218366  -0.01728612 -0.00308953  0.04802581\n",
      "  0.04718144  0.06646812  0.14809758  0.07039037  0.16434231  0.17543947\n",
      "  0.22089076 -0.10256617]\n",
      "\n",
      "find better score:\n",
      "score:  6012.8787813449635\n",
      "coeffs:  [-0.02928795  0.02050078  0.00078458  0.01853205  0.05496038 -0.01524578\n",
      "  0.02583761  0.06958381 -0.02398025 -0.02296337 -0.10783492  0.02605493\n",
      "  0.03136156 -0.01767166 -0.0231913  -0.01623585 -0.01460354 -0.00801068\n",
      " -0.02512614 -0.03119711  0.04821177  0.05027288  0.03628983  0.05681014\n",
      " -0.0190937  -0.03072155  0.02239637 -0.01916651 -0.00383743  0.04938601\n",
      "  0.04892005  0.06530469  0.14906573  0.06951604  0.16637201  0.17814617\n",
      "  0.22656047 -0.10291737]\n",
      "\n",
      "find better score:\n",
      "score:  6012.878781345083\n",
      "coeffs:  [-0.02928794  0.02050078  0.00078458  0.01853205  0.05496038 -0.01524578\n",
      "  0.02583761  0.06958381 -0.02398025 -0.02296337 -0.10783492  0.02605493\n",
      "  0.03136156 -0.01767166 -0.0231913  -0.01623585 -0.01460354 -0.00801068\n",
      " -0.02512614 -0.03119711  0.04821177  0.05027288  0.03628983  0.05681014\n",
      " -0.0190937  -0.03072155  0.02239637 -0.01916651 -0.00383743  0.04938601\n",
      "  0.04892005  0.06530469  0.14906573  0.06951604  0.16637201  0.17814617\n",
      "  0.22656047 -0.10291737]\n",
      "\n",
      "find better score:\n",
      "score:  6012.878781345088\n",
      "coeffs:  [-0.02928795  0.02050078  0.00078459  0.01853205  0.05496038 -0.01524578\n",
      "  0.02583761  0.06958381 -0.02398025 -0.02296337 -0.10783492  0.02605493\n",
      "  0.03136156 -0.01767166 -0.0231913  -0.01623585 -0.01460354 -0.00801068\n",
      " -0.02512614 -0.03119711  0.04821177  0.05027288  0.03628983  0.05681014\n",
      " -0.0190937  -0.03072155  0.02239637 -0.01916651 -0.00383743  0.04938601\n",
      "  0.04892005  0.06530469  0.14906573  0.06951604  0.16637201  0.17814617\n",
      "  0.22656047 -0.10291737]\n",
      "\n",
      "find better score:\n",
      "score:  6012.878781345089\n",
      "coeffs:  [-0.02928795  0.02050078  0.00078458  0.01853205  0.05496038 -0.01524578\n",
      "  0.02583761  0.06958381 -0.02398025 -0.02296337 -0.10783492  0.02605493\n",
      "  0.03136156 -0.01767166 -0.0231913  -0.01623585 -0.01460354 -0.00801068\n",
      " -0.02512614 -0.03119711  0.04821177  0.05027288  0.03628983  0.05681014\n",
      " -0.0190937  -0.03072155  0.02239637 -0.01916651 -0.00383743  0.04938601\n",
      "  0.04892005  0.06530469  0.14906573  0.06951604  0.16637201  0.17814617\n",
      "  0.22656048 -0.10291737]\n",
      "\n",
      "find better score:\n",
      "score:  6017.878967939595\n",
      "coeffs:  [-0.03604489  0.0086785   0.05547466  0.0185591   0.05900509  0.00391779\n",
      "  0.03172335  0.07110529 -0.02235019 -0.02371408 -0.12481552  0.02593506\n",
      "  0.0148406  -0.00713784 -0.0230434  -0.01375368 -0.01194057 -0.00657175\n",
      " -0.08095625 -0.08322613  0.04498434  0.05082509  0.07749866  0.12171132\n",
      " -0.05829968 -0.10174905  0.07221346 -0.04103238  0.00893314  0.08004703\n",
      "  0.0875084   0.00649196  0.10907899  0.02085223  0.15574174  0.18649657\n",
      "  0.32762388 -0.07266069]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879002425473\n",
      "coeffs:  [-0.03838745  0.00912891  0.074573    0.01651115  0.05217558  0.010861\n",
      "  0.0303815   0.07393733 -0.02162292 -0.02163084 -0.12315065  0.02667997\n",
      "  0.01214295 -0.00111769 -0.02067207 -0.01061029 -0.00885557 -0.00438641\n",
      " -0.09870197 -0.09954493  0.03600506  0.04309344  0.08438384  0.14254898\n",
      " -0.07011479 -0.12494472  0.09100414 -0.04656239  0.01507654  0.08441943\n",
      "  0.09156053 -0.01075109  0.09653584  0.00733099  0.15318484  0.1905659\n",
      "  0.36443566 -0.08479491]\n",
      "\n",
      "find better score:\n",
      "score:  6017.87901580566\n",
      "coeffs:  [-0.04055337  0.00821216  0.09043834  0.01512252  0.04835772  0.0164893\n",
      "  0.0288073   0.07533282 -0.02122288 -0.02021386 -0.12272931  0.02636563\n",
      "  0.00894793  0.00361465 -0.01903394 -0.00828539 -0.00654194 -0.00275273\n",
      " -0.11379411 -0.1134658   0.03027767  0.03843783  0.09064337  0.16015349\n",
      " -0.08024471 -0.14460579  0.10663828 -0.05145623  0.01997226  0.08860061\n",
      "  0.09588538 -0.02519932  0.08632864 -0.00401543  0.15139423  0.1943544\n",
      "  0.39564972 -0.09112671]\n",
      "\n",
      "find better score:\n",
      "score:  6017.87909774498\n",
      "coeffs:  [-0.05631177  0.01858087  0.13926879  0.00376096  0.066921    0.03082327\n",
      "  0.02241867  0.07466613 -0.02752238 -0.00805195 -0.12195141  0.01861889\n",
      "  0.00965861  0.02897304 -0.00716182  0.00806758  0.01006385  0.00985023\n",
      " -0.1593162  -0.15378139  0.03866054  0.05181109  0.06275524  0.20359004\n",
      " -0.10633896 -0.20849188  0.1618133  -0.05739728  0.04170118  0.06360552\n",
      "  0.06969281 -0.05718577  0.03854723 -0.0248863   0.13299269  0.19773423\n",
      "  0.48960888 -0.09009176]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879103186492\n",
      "coeffs:  [-0.05898013  0.01816618  0.14031659  0.00243189  0.06633421  0.03027132\n",
      "  0.02496382  0.07353905 -0.02971084 -0.00694849 -0.1240337   0.01728003\n",
      "  0.01038749  0.03109902 -0.00620265  0.00961513  0.01168444  0.01111381\n",
      " -0.16048257 -0.15477746  0.03752937  0.05114063  0.06040976  0.204035\n",
      " -0.10635178 -0.2109287   0.16480041 -0.05614017  0.04345233  0.06276264\n",
      "  0.07019625 -0.05580775  0.03498845 -0.02285214  0.13126645  0.19763876\n",
      "  0.49317125 -0.08446971]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879110701951\n",
      "coeffs:  [-0.06525305  0.01745     0.1432769  -0.00087538  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.8791107020825\n",
      "coeffs:  [-0.06525303  0.01745     0.1432769  -0.00087538  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879110702084\n",
      "coeffs:  [-0.06525305  0.01745001  0.1432769  -0.00087538  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879110702085\n",
      "coeffs:  [-0.06525305  0.01745     0.1432769  -0.00087536  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879110702086\n",
      "coeffs:  [-0.06525305  0.01745     0.1432769  -0.00087538  0.06456271  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879110702088\n",
      "coeffs:  [-0.06525305  0.01745     0.1432769  -0.00087538  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855838  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.05263871  0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6018.879110702089\n",
      "coeffs:  [-0.06525305  0.01745     0.1432769  -0.00087538  0.06456269  0.02915105\n",
      "  0.02902965  0.07135429 -0.03473427 -0.0043792  -0.12855839  0.01400859\n",
      "  0.0119309   0.03610754 -0.0039456   0.01324245  0.01546482  0.01404637\n",
      " -0.1638018  -0.15767425  0.03441238  0.04910353  0.05432518  0.20574228\n",
      " -0.10682116 -0.21731416  0.17228111 -0.05352583  0.04761769  0.06017411\n",
      "  0.06995354 -0.0526387   0.02775866 -0.01804988  0.12853184  0.1988338\n",
      "  0.50404238 -0.07703327]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879140004473\n",
      "coeffs:  [-0.09873693  0.01747878  0.14282553 -0.0105232   0.06521909  0.01586384\n",
      "  0.02320481  0.07337695 -0.0649516   0.00233104 -0.12299141  0.00666481\n",
      "  0.02599671  0.05386459  0.00072511  0.02571465  0.02928954  0.02370116\n",
      " -0.17391721 -0.16673935  0.02837864  0.04871848  0.03065062  0.19578695\n",
      " -0.10591562 -0.23961924  0.19448668 -0.03914262  0.06099723  0.0577031\n",
      "  0.06928046 -0.02623977 -0.00514711  0.01505643  0.1148331   0.20375621\n",
      "  0.53366877 -0.08810938]\n",
      "\n",
      "find better score:\n",
      "score:  6021.87914891653\n",
      "coeffs:  [-0.12290914  0.01440427  0.14653462 -0.01508623  0.0672427   0.00776279\n",
      "  0.01953069  0.07678906 -0.08675276  0.00523566 -0.12379309  0.00477828\n",
      "  0.03380696  0.06583276  0.00218639  0.03326243  0.03800898  0.02943962\n",
      " -0.18646027 -0.1783041   0.02502357  0.04993683  0.02881843  0.19404805\n",
      " -0.10935903 -0.26201735  0.21231335 -0.03128025  0.07033302  0.06948498\n",
      "  0.08338612 -0.01491838 -0.03621778  0.03201261  0.10060225  0.20499342\n",
      "  0.55723616 -0.09160624]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879194717998\n",
      "coeffs:  [-0.15303956  0.01854738  0.20035623  0.00940388  0.07112001  0.03255531\n",
      "  0.02707223  0.07232101 -0.11713806 -0.00148174 -0.12269365  0.01744797\n",
      "  0.0070121   0.11337821 -0.02441575  0.05700281  0.07795617  0.04468883\n",
      " -0.24066485 -0.22164111  0.00973471  0.07002137 -0.01487276  0.17903467\n",
      " -0.10696704 -0.37378706  0.1975816   0.04000693  0.07019419  0.12503386\n",
      "  0.08022311  0.01495223 -0.17604702  0.09319126  0.06943063  0.27842941\n",
      "  0.58170506 -0.08843711]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879194718073\n",
      "coeffs:  [-0.15303955  0.01854738  0.20035623  0.00940388  0.07112001  0.03255531\n",
      "  0.02707223  0.07232101 -0.11713806 -0.00148174 -0.12269365  0.01744797\n",
      "  0.0070121   0.11337821 -0.02441575  0.05700281  0.07795617  0.04468883\n",
      " -0.24066485 -0.22164111  0.00973471  0.07002137 -0.01487276  0.17903467\n",
      " -0.10696704 -0.37378706  0.1975816   0.04000693  0.07019419  0.12503386\n",
      "  0.08022311  0.01495223 -0.17604702  0.09319126  0.06943063  0.27842941\n",
      "  0.58170506 -0.08843711]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879194718074\n",
      "coeffs:  [-0.15303956  0.01854738  0.20035623  0.00940388  0.07112002  0.03255531\n",
      "  0.02707223  0.07232101 -0.11713806 -0.00148174 -0.12269365  0.01744797\n",
      "  0.0070121   0.11337821 -0.02441575  0.05700281  0.07795617  0.04468883\n",
      " -0.24066485 -0.22164111  0.00973471  0.07002137 -0.01487276  0.17903467\n",
      " -0.10696704 -0.37378706  0.1975816   0.04000693  0.07019419  0.12503386\n",
      "  0.08022311  0.01495223 -0.17604702  0.09319126  0.06943063  0.27842941\n",
      "  0.58170506 -0.08843711]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879194718075\n",
      "coeffs:  [-0.15303956  0.01854738  0.20035623  0.00940388  0.07112001  0.03255531\n",
      "  0.02707223  0.07232101 -0.11713806 -0.00148174 -0.12269365  0.01744797\n",
      "  0.00701211  0.11337821 -0.02441575  0.05700281  0.07795617  0.04468883\n",
      " -0.24066485 -0.22164111  0.00973471  0.07002137 -0.01487276  0.17903467\n",
      " -0.10696704 -0.37378706  0.1975816   0.04000693  0.07019419  0.12503386\n",
      "  0.08022311  0.01495223 -0.17604702  0.09319126  0.06943063  0.27842941\n",
      "  0.58170506 -0.08843711]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-0.5136885327963769, 0.35381500908391694, 0.47878067020078885, -0.9252897808591912, 1.609282630917699, 0.08633139099087953, -1.2644783770861148, 0.3009261420430286, -1.2600636588118348, 0.9488342293951498, 0.7351944898914453, -1.1718005638074036, -1.7198002826231962, 0.6478365332451109, -1.6368029051297515, -0.6923384641158459, -0.24391733165946003, 1.104964837404514, 0.5638154120223081, -0.0035276287441908596, 0.6828234950216309, -0.09112111637610086, 0.07666948085242198, -0.3008073701912709, -0.2697099958240404, 0.1883256150989415, -0.1960261172322328, 0.248863667414328, 1.4871052230373232, -0.25068555765267564, -0.9882327233392266, -0.16921172963107722, 0.5697316857924096, 0.14389340120699973, 1.0821957428247562, 1.425521333970177, -0.3659803453546313, 1.3394991400192422]\n",
      "\n",
      "Optimizing with init x0: [-0.047718422033979455, 0.5669253020613391, 0.7592988430359959, -0.5338785739169307, -0.06424974670160251, -0.0321015837640589, 1.5198825362770942, 1.6258528333673752, 0.532396403157812, -0.13269041920087576, -0.2665582792332948, -1.1046039760314987, 0.07018142286391488, 0.007093412107864818, 0.8784626324786912, 1.5022562069453174, -1.0351539243205665, 0.1584027665466012, 0.1866107789358542, -1.1129078257545033, 0.32953304047156584, 1.4879419622861665, -0.41111601098441963, -0.8979675597880022, 1.0666611612605106, -1.2246419337604533, 1.5205903139432433, 1.5586107408537662, -0.48128430958796886, -0.08957915472053592, 0.35260230322521346, -0.7793802377696017, -2.7470105767706143, -0.5402372742745597, -0.20302446761130513, 1.1222787244981556, 0.10615976295975874, 1.638698885697484]\n",
      "\n",
      "Optimizing with init x0: [-0.3384712300658542, -1.0611999115869275, -0.23771309553491984, 0.27731027388157514, 2.089286276597167, 1.2709593358283482, -0.7026689845925356, -0.9408315874198504, 1.7166145259269587, -0.1516827802240514, -0.18686518999183363, 0.32434504553251586, 1.19688921812324, -0.7749416643448198, 0.10718351929704431, -0.7129529286881763, -0.39548601568798114, 0.2941704738053147, 0.837770971290415, -0.07124330636252539, 1.0508320401264262, -0.2957773295601094, -1.7275434418944458, 2.194586511663102, -1.031876209279838, -1.6041083520821529, 0.35999809267244287, -1.068661288576822, 1.9374525024614049, -1.2889975130459685, -0.4252623271246784, -0.09714024719025313, 0.5418559266759974, 0.3813152486882704, -0.4566690600217854, 0.301645348107239, -0.27450443149492665, -0.35527478717814776]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879222709078\n",
      "coeffs:  [-0.17318267  0.0125698   0.16876009  0.00384933  0.08253443  0.04838978\n",
      "  0.02617404  0.07606046 -0.08579963 -0.15264174 -0.1212155   0.01336743\n",
      "  0.0188556   0.32748396 -0.23770706  0.07435266  0.23027305 -0.06669312\n",
      "  0.02462264 -0.31773231 -0.13433522  0.19913821 -0.00495649  0.17265459\n",
      " -0.12402458 -0.66018424  0.23750258  0.32318038  0.01366438  0.11421175\n",
      "  0.06940971 -0.14173023 -0.17085557  0.20660609 -0.09548042  0.46433897\n",
      "  0.58394954 -0.08498894]\n",
      "\n",
      "find better score:\n",
      "score:  6022.87922286373\n",
      "coeffs:  [-0.1730817   0.01241443  0.1682879   0.00386742  0.08184907  0.04776177\n",
      "  0.02626011  0.07679423 -0.08327711 -0.15320324 -0.12111602  0.01314897\n",
      "  0.01849786  0.33085995 -0.23962352  0.07546816  0.23080474 -0.06844991\n",
      "  0.01892299 -0.31991477 -0.13524182  0.19958204 -0.00342096  0.17267095\n",
      " -0.12016932 -0.65273816  0.23308969  0.32490785  0.01171318  0.11260078\n",
      "  0.06924814 -0.14126243 -0.1711789   0.20656847 -0.09475746  0.46175894\n",
      "  0.58579902 -0.08541194]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv.index, metric, best_score, best_coeffs, True), \n",
    "                 tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 6022.87922286373}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-0.1730817 ,  0.01241443,  0.1682879 ,  0.00386742,  0.08184907,\n",
       "         0.04776177,  0.02626011,  0.07679423, -0.08327711, -0.15320324,\n",
       "        -0.12111602,  0.01314897,  0.01849786,  0.33085995, -0.23962352,\n",
       "         0.07546816,  0.23080474, -0.06844991,  0.01892299, -0.31991477,\n",
       "        -0.13524182,  0.19958204, -0.00342096,  0.17267095, -0.12016932,\n",
       "        -0.65273816,  0.23308969,  0.32490785,  0.01171318,  0.11260078,\n",
       "         0.06924814, -0.14126243, -0.1711789 ,  0.20656847, -0.09475746,\n",
       "         0.46175894,  0.58579902, -0.08541194])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:, cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prices = np.sort(df_train['total_price'].unique())\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return array[(np.fabs(array - value)).argmin()]\n",
    "\n",
    "def correct_prices(sq):\n",
    "    return [find_nearest(unique_prices, x) for x in sq]\n",
    "\n",
    "test_pred_final['total_price'] = correct_prices(test_pred_final['total_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHtJJREFUeJzt3X10VfWd7/H3V4gGDAYFzRWxE1w4Dg60IPGp9vaGUUesomPlVnmwgyNi7ZXamdYpvZVq770dnevoVevTZaK1VGNUWntBaMV0iNguHxBUwMYHZKgGp9DiIiUssQS/94+9k5yEPJydnJ29s/N5rZXFPjv77PM5WeF889u/3/79zN0RERHJ1yFJBxARkYFFhUNERCJR4RARkUhUOEREJBIVDhERiUSFQ0REIlHhEBGRSFQ4REQkEhUOERGJZGjSAeIwevRoLy8vB2Dv3r0cfvjhyQbqRFpzQXqzpTUXpDdbWnNBerOlNRfEn239+vV/cPejezzQ3TP3NXXqVG+xZs0aT6O05nJPb7a05nJPb7a05nJPb7a05nKPPxvwiufxGatLVSIiEokKh4iIRKLCISIikWSyc1xEJKr9+/fT0NBAaWkp9fX1ScfpVKGyFRcXM3bsWIqKinr1fBUOERGgoaGBESNGMGrUKI444oik43Rqz549jBgxok/ncHd27dpFQ0MD48aN69U5dKlKRATYt28fo0aNwsySjhIrM2PUqFHs27ev1+dIfYvDzA4H7gP+BNS5+6MJRxKRjMp60WjR1/eZSIvDzB4ys51mtrnD/ulm9paZbTGzReHuLwLL3P1q4KJ+DysiIu0k1eJ4GLgHWNqyw8yGAPcC5wINwDozWw6MBTaFhx3o35gZVn1Z2/bsx5PLIZJS5YtWFvR82269oNvv7969m+rqar761a9GOu8XvvAFqqurGTlyZF/iRZJI4XD3tWZW3mH3acAWd98KYGY1wMUERWQs8Brqk+mT3P8I2z6dYBAROcju3bu57777Dioczc3NDB3a9Uf1qlWr4o52EAvuMu9/YeF42t0nho9nAtPdfX74+ArgdOBbBK2TfcCvuurjMLMFwAKAsrKyqTU1NQA0NTVRUlIS63vpjSRybdre2Lo9adiutm8cdUK74/Qziy6t2dKaC9KXrbS0lPHjx3PgwAGGDBnCpO+vLej5N33n891+f968eaxatYoTTzyRoUOHUlxczMiRI3n77bd59dVXmTVrFg0NDXz88cdce+21XHnllQBMnDiR5557jqamJi699FLOPPNMXnrpJY499lhqamoYNmxYp6+3ZcsWGhsb2+2bNm3aenev6Om9pL5z3N33AlfmcdwSYAlARUWFV1ZWAlBXV0fLdpokkWteuxbHM23fqGx/qUo/s+jSmi2tuSB92err6xkxYkRBhrx2pqdz3n777bz11lts3LiRuro6LrjgAjZv3tw6ZHbp0qUUFRUxdOhQTj31VObMmdM6CqylAL/77rs8/vjjTJ48mS996UusXr2auXPndvp6xcXFTJkypVfvJU2XfrYDx+c8Hhvuy5uZzTCzJR2rqIjIQHPaaae1u8/i7rvv5rOf/SxnnHEG77//Pu+8885Bzxk3bhyTJ08GYOrUqWzbti2WbGkqHOuAE81snJkdClwOLI9yAndf4e4LSktLYwkoItJfcqdPr6uro7a2ltraWl5//XWmTJnS6X0Yhx12WOv2kCFDaG5ujiVbUsNxHwNeAE4yswYzu8rdm4HrgGeAeuAJd38jiXyDWfmilWza3ljwESUi0r2Wy2SdaWxs5Mgjj2T48OG8+eabvPjii/2crr2kRlXN6mL/KqDXQwTMbAYwY/z48b09hYgI0PPw2UIbNWoUZ511FhMnTmTYsGGUlZW1fm/69Ok88MADVFRUMGHCBM4444x+zdZR6jvHo3D3FcCKioqKq5POkgm610OkX1VXV3e6/7DDDuPnP/95px33Lf0Yo0ePZvPmtnuqv/nNb8aWM019HCIiMgBkqnBoVJWISPx0qWoQqSq6rXW7NmdK/3PyeG67u877+dqviKRLpgqHHCz3A7+qizVbahdX5jy6odNjcosO1UvbtnP6PlRcRAYHFY6Ma/eBXyC19Ttat/NprYhItqiPQ0REIslUi0N9HKHcYbQRVRXdxkc2m6qiaqCsx+Mj59GwXhko+vD/qFM9/O73dlp1gDvvvJMFCxYwfPjw3qaLJFOFYzBLasr0fPpHRKRnXU2rno8777yTuXPnqnBIdqhPRKRnixYt4t1332Xy5Mmce+65HHPMMTzxxBN8/PHHXHLJJXzve99j7969XH755TQ0NHDgwAEWL17Mjh07+OCDD5g2bRqjR49mzZo1sWfNVOHQlCOFlfuBn4/2HfEaVSUSxa233srmzZt57bXXWL16NcuWLePll1/G3bnoootYu3Yt7733HmPGjGHlyuAKQ2NjI6Wlpdxxxx2sWbOG0aNH90vWTHWOa3ZcEcmC1atXs3r1aqZMmcIpp5zCm2++yTvvvMPJJ5/Ms88+y7e+9S2ef/55kvqsy1SLQ9Kjfd+HiETh7nz729/mmmuuabd/z549bNiwgVWrVnHjjTdy9tln893vfrff86lwDGDqmBbJjtxp1c877zwWL17MnDlzKCkpYfv27RQVFbF7924+9alPMXfuXEaOHElVVVW75/bXpSoVDulfGporA0U//37mTqt+/vnnM3v2bM4880wASkpKeOSRR3jjjTeYOXMmhxxyCEVFRdx///0ALFiwgOnTpzNmzBh1jkelzvH00wgrka51nFb9+uuvb/f4mGOO4ZJLLjnoeQsXLmThwoWxZsulznEREYkkUy0OGWB02UpkQFLhkHRQEZEUcPekI/SLvr5PFQ5JTLv+jgkFmhdLpJeKi4vZtWsXhx56aNJRYuXu7Nq1i+Li4l6fQ4VDUkGd5pK0sWPH0tDQwO7du/v0oRqnffv2FSRbcXExY8eO7fXzVTgyKOpUISICRUVFjBs3jrq6OqZMmZJ0nE6lJVumRlVpPQ4RkfhlqsUxKNbj6GKNgDhW+hMR6UymWhwiIhI/FQ4REYlEhUNERCJR4RARkUhUOEREJBIVDhERiSRTw3GzqnzRytbtbZ9OMEgScocfj7k2uRwi0ipThUPrcWRP7l3w9d5IZXJRRCSUqcIxKG4AHAS6W6+8Xevr1gv6IY2IdKQ+DhERiSRTLY4BTetRiMgAocIhA0a57aCqKGdN5uqlwb8qtCL9SpeqREQkErU4BhittSEiSVOLQ0REIlHhEBGRSFQ4UqK2fkfrV+69CiIiaaPCISIikahzPC4592WUb/xy67budo6H7igX6T+pLxxmdgLwHaDU3WcmnUfSo2WE2Xxd2hPpV7EWDjN7CLgQ2OnuE3P2TwfuAoYAVe5+a1fncPetwFVmtizOrKlVfRlVRRqCKyLpEXeL42HgHmBpyw4zGwLcC5wLNADrzGw5QRG5pcPz/87dd8acUTKkqug23VEuErNYC4e7rzWz8g67TwO2hC0JzKwGuNjdbyFonYhEUlV0W88HaS4wkYIxd4/3BYLC8XTLpSozmwlMd/f54eMrgNPd/bounj8K+D5BC6UqLDCdHbcAWABQVlY2taamBoCmpiZKSkoK+Zby8+HW1s1NH41q3Z50XClwcK49H7zdur3Ny1qP48Ot7NnXHHPY9j4pPopD9n3Yr6+Zj3xzjSju4e+ho04oUKI2if2e9SCtuSC92dKaC+LPNm3atPXuXtHTcanvHHf3XcBX8jhuCbAEoKKiwisrKwGoq6ujZbtfVd/fujlvU86oqjlBlo65ahff3Lo9Aai0srbv9fM0Ix9NmM2w+uqeD+xn+ebKLbPnTDj45zh//w0FH3mV2O9ZD9KaC9KbLa25ID3ZkriPYztwfM7jseE+EREZAJJocawDTjSzcQQF43JgdiFOrKVjpSNNCilSeLG2OMzsMeAF4CQzazCzq9y9GbgOeAaoB55w9zcK8XruvsLdF5SWlhbidCIi0om4R1XN6mL/KmBVoV9PLQ4RkfilvnM8CndfAayoqKi4OuksfaVLLCKSVprkUEREIlHhEBGRSDJ1qWog9HG0zOL6jUnNzMuZnK+qKKlEIiLRZKrFoVFVIiLxy1SLYyBomVfpI5sNHJdsGBGRXshU4UjrpaquJuHLa3I+iYUWfhLpPV2qEhGRSDLV4hDJx0EtPa3fIRJJplocIiISv0y1ONLUx6E7v0UkqzJVOLI05YgkQ53mIj3TpSoREYkkUy2OpJXrTnARGQRUOApI92VkR1XRbRptJdIFXaoSEZFIMlU4zGyGmS1pbGxMOooMILX1O6it39HuUmN3+0UGu0xdqtKoKukLXWoUyU+mWhwiIhI/FQ6RHgQd5ZcFXyKiwiEiItGocIiISCSZKhwaVSUiEj+Nquoj3S0uIoNNplocIiISPxUOERGJRIVDJA+6i1ykTab6OET6g9bskMFOLQ4REYkk7xaHmX0G+M/hw+fd/fV4IomISJrl1eIws+uBR4Fjwq9HzGxhnMFERCSd8m1xXAWc7u57Aczsn4EXgB/EFUwkjXJn0J2//4bW/o5vTGqmMqFMIv0t3z4OAw7kPD4Q7ksV3TkuIhK/fAvHD4GXzOxmM7sZeBF4MLZUveTuK9x9QWlpadJRREQyK69LVe5+h5nVAZ8Ld13p7q/GlmoA0eI/IjLYdFs4zOwId/+jmR0FbAu/Wr53lLt/GG88ERFJm55aHNXAhcB6wHP2W/j4hJhyiaRebmuznr9PMIlI/+q2cLj7heG/4/onjoiIpF2+93H8Mp99IiKSfT31cRQDw4HRZnYkbUNwjwCOizmbiIikUE99HNcAXwfGEPRztBSOPwL3xJhLRERSqqc+jruAu8xsobvrLnEREcn7Po4fmNlE4GSgOGf/0riCpVr1ZUknkDTL/f2Y/XhyOURiklfhMLObgEqCwrEKOB/4FTAoC0dt/Y6kI4iIJCbfSQ5nAp8BXnX3K82sDHgkvlhtzOxvgAsIOuQfdPfV/fG6IlGU2w61RGXQyHeuqn3u/gnQbGZHADuB43t6kpk9ZGY7zWxzh/3TzewtM9tiZou6O4e7/8zdrwa+Auh/pqRWy/KyapFK1vXY4jAzAzaa2UjgXwlGVzURTKvek4cJRl+1XtIysyHAvcC5QAOwzsyWA0OAWzo8/+/cfWe4fWP4PBERSVCPhcPd3cxOc/fdwANm9gvgCHffmMdz15pZeYfdpwFb3H0rgJnVABe7+y0E05u0ExauW4Gfu/uGnl5TJG20Rrlkjbl7zweZ/Qi4x93XRX6BoHA87e4Tw8czgenuPj98fAXBIlHXdfH8rwF/C6wDXnP3B7o4bgGwAKCsrGxqTU0NAE1NTZSUlESN3a09H7zd53N8UnwUh+xL5xyRac2W1lxwcLYRxeHfZEedwKbtbevDTDquf6f8j+P3v1DSmi2tuSD+bNOmTVvv7hU9HZdv5/jpwBwz+y2wl3CSQ3f/dB8y5sXd7wbuzuO4JcASgIqKCq+srASgrq6Olu1CqV18c5/P8dGE2Qyrr+57mBikNVtac8HB2SonlIUbjzMvt8Uxp7Jfc8Xx+18oac2W1lyQnmz5Fo7zCvia22nfsT423NdnZjYDmDF+/PhCnE4kPrrXQwawfG8A/G0BX3MdcKKZjSMoGJcDswtxYndfAayoqKi4uhDnE+mtlpFV83NaGyJZke9w3F4xs8cIRl+dZGYNZnaVuzcD1wHPAPXAE+7+Rpw5RESkcPK9VNUr7j6ri/2rCO5ALyhdqhIRiV+shaO/6VKVpM1Ba9JXD8pZeiRjMlU4RAYq3eshA0msfRz9zcxmmNmSxsbGng8WEZFeyVThcPcV7r6gtLR/b7ISERlMdKlKJMV6fQmr5T6R4vMIVkQQKZxMFQ6NqpK0y50595yWu8tFBhhdqhIRkUgyVThERCR+KhwiIhJJpvo4Ci5nIrryjV9u3a4qSiKMZFb1ZVQVtfV91C4Obhqcv/+GpBKllyaHTIVMtTh0H4eISPwyVTjUOS4iEr9MFQ4REYmfCoeIiESiznGRhOTeDCgykGSqxaHOcZH29uxrpnzRynZTl4j0VaZaHHGux3HQugoiMcv9nWs3NLerIam5+7vSl+GsGgoroUy1OEREJH4qHCIiEokKh4iIRKLCISIikWSqcGhUlYhI/DJVODTliIhI/DJVOEREJH6Zuo9DJMtabuKrKtqhZWclUSocIgNQ63QliyuB7tcvb72RsHppzKm6oZsHM0WXqkREJBIVDhERiUSFQ0REIlHhEBGRSNQ5LjJI5K7/oVFZ0heZanHoznERkfhlqsUR53ocIoNN7uJP2269IMEkkjaZanGIiEj8VDhERCSSTF2qEpH2neBMSC6HZJdaHCIiEokKh4iIRKLCISL9prZ+B+WLVrYbsSUDjwqHiIhEosIhIiKRaFSVyADQuqZGIeWukdHpa+5g/v4bop0n6lobhVqnI+p5srQ+SALvRYVDRHqtfNFKqoqC4b9R57/atL2R5jfzf25fXksKK/WXqsxsgpk9YGbLzOzapPOIiAx2sRYOM3vIzHaa2eYO+6eb2VtmtsXMFnV3Dnevd/evAF8Czoozr4iI9CzuFsfDwPTcHWY2BLgXOB84GZhlZieb2SQze7rD1zHhcy4CVgKrYs4rIiI9iLWPw93Xmll5h92nAVvcfSuAmdUAF7v7LcCFXZxnObDczFYC1fElFhkculqbo910JSJdMHeP9wWCwvG0u08MH88Eprv7/PDxFcDp7n5dF8+vBL4IHAZsdPd7uzhuAbAAoKysbGpNTQ0ATU1NlJSU9C78h1tbN/fsa+7dObrwSfFRHLLvw4Kes1DSmi2tuSD5bCOK2/4GzP1dzSdXV88F2OZBUZl0XGm7/w8cdQIQdHCX246284T7DxI+d8++5tZzlg2DYfvyeG6o29fqJFu3ujm+T58ZMes0W9T33o1p06atd/eKno5L/agqd68D6vI4bgmwBKCiosIrKysBqKuro2U7sur7WzcL/ZfYRxNmM6w+nY2ntGZLay5IPltlF62GfHJ19VyA28PhuNvmVLb7/0BlMOxz3qKVVBVVt52nsovhoOFza+t3tJ7zG5OamfBmHs8NdftanWTrVjfH9+kzI2adZov63gsgiVFV24Hjcx6PDff1mVYAFBGJXxKFYx1wopmNM7NDgcuB5YU4sbuvcPcFpaWlhTidiIh0ItZLVWb2GFAJjDazBuAmd3/QzK4DngGGAA+5+xtx5ugtdRTKQBH372ruzXcA81M6SWFt/Y522bTkbTziHlU1q4v9q4hhaK2ZzQBmjB8/vtCnFhGRUOrvHI9Cl6pEROKXqcIhIiLxy1Th0KgqEZH4Zapw6FKViEj8MlU4REQkfqm/c1xEBobcobC5w2A7DuWVgS9TLQ71cYiIxC9ThUN9HCIi8ctU4RARkfipcIiISCSZKhzq4xARiV+mCof6OERE4pepwiEiIvFT4RARkUh0A2AH5Tlz+VcVJRhEpJ/EsZZHeYHW68jnPL25wTD3PZ8TOVW6JPFeMtXiUOe4iEj8MlU41DkuIhK/TBUOERGJnwqHiIhEosIhIiKRqHCIiEgkKhwiIhJJpgqHhuOKiMQvU4VDw3FFROKXqcIhIiLxU+EQEZFIVDhERCQSFQ4REYlEhUNERCJR4RARkUi0HoeIpEo+a3DU1u9gfsQ1P/qy1k7uc7fdekG0J2dQplocugFQRCR+mSocugFQRCR+mSocIiISPxUOERGJRIVDREQiUeEQEZFIVDhERCQSFQ4REYlEhUNERCIxd086Q8GZ2e+B34YPRwN/SDBOV9KaC9KbLa25IL3Z0poL0pstrbkg/mx/5u5H93RQJgtHLjN7xd0rks7RUVpzQXqzpTUXpDdbWnNBerOlNRekJ5suVYmISCQqHCIiEslgKBxLkg7QhbTmgvRmS2suSG+2tOaC9GZLay5ISbbM93GIiEhhDYYWh4iIFFCmC4eZTTezt8xsi5ktSjoPgJk9ZGY7zWxz0lk6MrPjzWyNmf3GzN4ws+uTzgRgZsVm9rKZvR7m+l7SmXKZ2RAze9XMnk46Sy4z22Zmm8zsNTN7Jek8LcxspJktM7M3zazezM5MOhOAmZ0U/qxavv5oZl9POheAmf19+Lu/2cweM7PiRPNk9VKVmQ0B3gbOBRqAdcAsd/9Nwrk+DzQBS919YpJZOjKzY4Fj3X2DmY0A1gN/k4KfmQGHu3uTmRUBvwKud/cXk8zVwsz+AagAjnD3C5PO08LMtgEV7p6qexLM7EfA8+5eZWaHAsPdfXfSuXKFnx/bgdPd/bc9HR9zluMIfudPdvePzOwJYJW7P5xUpiy3OE4Dtrj7Vnf/E1ADXJxwJtx9LfBh0jk64+7/4e4bwu09QD1wXLKpwANN4cOi8CsVf/GY2VjgAqAq6SwDgZmVAp8HHgRw9z+lrWiEzgbeTbpo5BgKDDOzocBw4IMkw2S5cBwHvJ/zuIEUfAgOFGZWDkwBXko2SSC8HPQasBN41t1TkQu4E/hH4JOkg3TCgdVmtt7MFiQdJjQO+D3ww/DyXpWZHZ50qE5cDjyWdAgAd98O/AvwHvAfQKO7r04yU5YLh/SSmZUAPwG+7u5/TDoPgLsfcPfJwFjgNDNL/DKfmV0I7HT39Uln6cLn3P0U4Hzgv4WXSZM2FDgFuN/dpwB7gVT0P7YIL59dBDyZdBYAMzuS4GrJOGAMcLiZzU0yU5YLx3bg+JzHY8N90o2wD+EnwKPu/tOk83QUXtZYA0xPOgtwFnBR2JdQA/yVmT2SbKQ24V+quPtO4CmCy7dJawAaclqMywgKSZqcD2xw9x1JBwmdA/y7u//e3fcDPwU+m2SgLBeOdcCJZjYu/AvicmB5wplSLeyEfhCod/c7ks7TwsyONrOR4fYwggEPbyabCtz92+4+1t3LCX6//s3dE/1LsIWZHR4OcCC8FPTXQOIj+dz9d8D7ZnZSuOtsINHBF52YRUouU4XeA84ws+Hh/9GzCfofEzM0yRePk7s3m9l1wDPAEOAhd38j4ViY2WNAJTDazBqAm9z9wWRTtToLuALYFPYnAPx3d1+VYCaAY4EfhSNdDgGecPdUDX1NoTLgqeBzhqFAtbv/ItlIrRYCj4Z/0G0Frkw4T6uwyJ4LXJN0lhbu/pKZLQM2AM3AqyR8B3lmh+OKiEg8snypSkREYqDCISIikahwiIhIJCocIiISiQqHiIhEosIhIiKRqHBI6phZU89Hdfv8ZWZ2Qm/OZWYVZnZ3uD3PzO7pLqOZjQnH2Geamf2Fmb1gZh+b2Tdz9h9qZmvDyfdkkFDhkEwxs78Ehrj71t48391fcfevRTj+A3ef2ZvX6otCflCbWbmZ1fVw2IfA1wgm22sVzjz9S+CyQuWR9FPhkNSywG3h4jWbzOyycP8hZnZfuBDQs2a2ysxaPrznAP+vw3n+T7gIzi/N7OhwX52ZVYTbo8P5pjCzys4WZAqnrnkhzPG/cvaXW7goV9hC+amZ/cLM3jGz/51z3FVm9rYFC1L9a1ctmfDYGWb2Ujh7bK2ZlYX7bzazH5vZr4EfhzMG32Zm68xso5ldEx5XEr7XDWHePi8n4O473X0dsL+Tb/+M4Ocug4QKh6TZF4HJwGcIJnq7zYLFpr4IlAMnE0yRkruC3FkEC1C1OBx4xd3/EngOuKmXWe4imNF1EsHU1l2ZTPDX9yTgMgtWVRwDLAbOCPP9RQ+v9SvgjHD22BqCadtbnAyc4+6zgKsIptg+FTgVuNrMxgH7gEvCmXGnAbeHcxzFZXP4+jJI6LqkpNnngMfc/QCww8yeI/iA+hzwpLt/AvzOzNbkPOdYgvUeWnwCPB5uP0Iws2hvnAVcGm7/GPjnLo77pbs3ApjZb4A/A0YDz7n7h+H+J4E/7+a1xgKPh0XyUODfc7633N0/Crf/Gvh0TmurFDiRYAbafwqnUf+EYB2aMuB3uS9iZk8RTNV9KPCpnPnJ7nL3H3aTrx13P2BmfzKzEeECYJJxKhySNR8B3a3H3DI5WzNtLe5812/OZ2K3j3O2D9C7/2M/AO5w9+VmVgncnPO9vTnbBix092dyn2xm84Cjganuvj+8DHfQe3T3S8Ljy4GH3b2yF1lbHEbQ0pFBQJeqJM2eJ7jcMyTsm/g88DLwa+DSsK+jjGC24Rb1wPicx4cALX+Rzya4DASwDZgabufTuf1rgqnTIfr1/HXAfzGzI8NO7Ut7OL6UtrVj/rab454BrrVgDRXM7M/D2V1LCRaY2m9m0whaPbExs1HAH8K1ImQQUOGQNHsK2Ai8Dvwb8I/heg4/Ibgc8xuCy08bgMbwOStpX0j2EqwYuBn4K+B/hPv/heBD91WCS0k9uZ5gFb1NRFyCOFxQ6Z9oK3rbcvJ25mbgSTNbD/yhm+OqCH4GG8L3938JWjiPAhVh1i9TgLVLzOw/hcsA/ANwo5k1mNkR4benEfzcZZDQtOoyIJlZibs3hX/tvgyc5e6/s2ChpzXh4wPJpmyTk3coQUF8yN2fSjpXIZjZT4FF7v520lmkf6iPQwaqpy1YFfBQ4H+GLRHc/SMzu4mgVfBekgE7uNnMziHoa1hNMIR1wLNgMaafqWgMLmpxiCTEzL4D/NcOu5909+8nkUckXyocIiISiTrHRUQkEhUOERGJRIVDREQiUeEQEZFIVDhERCSS/w97rFZpkBZaiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
