{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '11'\n",
    "models = '1-11,14-17'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = True\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 14, 15, 16, 17]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "15\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 12 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 13 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 14 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_15</th>\n",
       "      <th>log_parea_pred_15</th>\n",
       "      <th>pred_16</th>\n",
       "      <th>log_pred_16</th>\n",
       "      <th>log_parea_pred_16</th>\n",
       "      <th>pred_17</th>\n",
       "      <th>log_pred_17</th>\n",
       "      <th>log_parea_pred_17</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.411432</td>\n",
       "      <td>12.182328</td>\n",
       "      <td>6.542462e+05</td>\n",
       "      <td>13.391241</td>\n",
       "      <td>12.162137</td>\n",
       "      <td>6.552449e+05</td>\n",
       "      <td>13.392766</td>\n",
       "      <td>12.163663</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.963920</td>\n",
       "      <td>13.567353</td>\n",
       "      <td>3.128284e+06</td>\n",
       "      <td>14.955995</td>\n",
       "      <td>13.559428</td>\n",
       "      <td>3.130186e+06</td>\n",
       "      <td>14.956603</td>\n",
       "      <td>13.560036</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.091430</td>\n",
       "      <td>14.371475</td>\n",
       "      <td>9.758797e+06</td>\n",
       "      <td>16.093680</td>\n",
       "      <td>14.373725</td>\n",
       "      <td>9.787304e+06</td>\n",
       "      <td>16.096597</td>\n",
       "      <td>14.376642</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.351229</td>\n",
       "      <td>13.743883</td>\n",
       "      <td>1.266868e+07</td>\n",
       "      <td>16.354644</td>\n",
       "      <td>13.747297</td>\n",
       "      <td>1.270893e+07</td>\n",
       "      <td>16.357815</td>\n",
       "      <td>13.750469</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.923267</td>\n",
       "      <td>12.378241</td>\n",
       "      <td>1.122232e+06</td>\n",
       "      <td>13.930831</td>\n",
       "      <td>12.385805</td>\n",
       "      <td>1.110012e+06</td>\n",
       "      <td>13.919882</td>\n",
       "      <td>12.374856</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "   ...  log_pred_15  log_parea_pred_15       pred_16  log_pred_16  \\\n",
       "0  ...    13.411432          12.182328  6.542462e+05    13.391241   \n",
       "1  ...    14.963920          13.567353  3.128284e+06    14.955995   \n",
       "2  ...    16.091430          14.371475  9.758797e+06    16.093680   \n",
       "3  ...    16.351229          13.743883  1.266868e+07    16.354644   \n",
       "4  ...    13.923267          12.378241  1.122232e+06    13.930831   \n",
       "\n",
       "   log_parea_pred_16       pred_17  log_pred_17  log_parea_pred_17  \\\n",
       "0          12.162137  6.552449e+05    13.392766          12.163663   \n",
       "1          13.559428  3.130186e+06    14.956603          13.560036   \n",
       "2          14.373725  9.787304e+06    16.096597          14.376642   \n",
       "3          13.747297  1.270893e+07    16.357815          13.750469   \n",
       "4          12.385805  1.110012e+06    13.919882          12.374856   \n",
       "\n",
       "   log_total_price  log_parea_total_price  \n",
       "0        13.381036              12.151933  \n",
       "1        15.015913              13.619345  \n",
       "2        16.074236              14.354282  \n",
       "3        16.469809              13.862462  \n",
       "4        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_14</th>\n",
       "      <th>pred_15</th>\n",
       "      <th>log_pred_15</th>\n",
       "      <th>log_parea_pred_15</th>\n",
       "      <th>pred_16</th>\n",
       "      <th>log_pred_16</th>\n",
       "      <th>log_parea_pred_16</th>\n",
       "      <th>pred_17</th>\n",
       "      <th>log_pred_17</th>\n",
       "      <th>log_parea_pred_17</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.270289</td>\n",
       "      <td>1.476388e+07</td>\n",
       "      <td>16.507694</td>\n",
       "      <td>15.278587</td>\n",
       "      <td>1.388634e+07</td>\n",
       "      <td>16.446416</td>\n",
       "      <td>15.217310</td>\n",
       "      <td>1.449905e+07</td>\n",
       "      <td>16.489594</td>\n",
       "      <td>15.260487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.144670</td>\n",
       "      <td>3.928353e+06</td>\n",
       "      <td>15.183731</td>\n",
       "      <td>13.139112</td>\n",
       "      <td>3.918650e+06</td>\n",
       "      <td>15.181258</td>\n",
       "      <td>13.136639</td>\n",
       "      <td>3.917960e+06</td>\n",
       "      <td>15.181082</td>\n",
       "      <td>13.136463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.677153</td>\n",
       "      <td>1.062900e+07</td>\n",
       "      <td>16.179096</td>\n",
       "      <td>13.680076</td>\n",
       "      <td>1.073546e+07</td>\n",
       "      <td>16.189063</td>\n",
       "      <td>13.690042</td>\n",
       "      <td>1.063343e+07</td>\n",
       "      <td>16.179513</td>\n",
       "      <td>13.680493</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.815150</td>\n",
       "      <td>6.085773e+06</td>\n",
       "      <td>15.621464</td>\n",
       "      <td>14.809532</td>\n",
       "      <td>6.080935e+06</td>\n",
       "      <td>15.620669</td>\n",
       "      <td>14.808737</td>\n",
       "      <td>6.119193e+06</td>\n",
       "      <td>15.626941</td>\n",
       "      <td>14.815009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.116189</td>\n",
       "      <td>1.061918e+06</td>\n",
       "      <td>13.875588</td>\n",
       "      <td>12.115326</td>\n",
       "      <td>1.072461e+06</td>\n",
       "      <td>13.885468</td>\n",
       "      <td>12.125206</td>\n",
       "      <td>1.084776e+06</td>\n",
       "      <td>13.896885</td>\n",
       "      <td>12.136623</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3  ...  log_parea_pred_14       pred_15  log_pred_15  \\\n",
       "0   16.544464  ...          15.270289  1.476388e+07    16.507694   \n",
       "1   15.196062  ...          13.144670  3.928353e+06    15.183731   \n",
       "2   16.199646  ...          13.677153  1.062900e+07    16.179096   \n",
       "3   15.609807  ...          14.815150  6.085773e+06    15.621464   \n",
       "4   13.842395  ...          12.116189  1.061918e+06    13.875588   \n",
       "\n",
       "   log_parea_pred_15       pred_16  log_pred_16  log_parea_pred_16  \\\n",
       "0          15.278587  1.388634e+07    16.446416          15.217310   \n",
       "1          13.139112  3.918650e+06    15.181258          13.136639   \n",
       "2          13.680076  1.073546e+07    16.189063          13.690042   \n",
       "3          14.809532  6.080935e+06    15.620669          14.808737   \n",
       "4          12.115326  1.072461e+06    13.885468          12.125206   \n",
       "\n",
       "        pred_17  log_pred_17  log_parea_pred_17  \n",
       "0  1.449905e+07    16.489594          15.260487  \n",
       "1  3.917960e+06    15.181082          13.136463  \n",
       "2  1.063343e+07    16.179513          13.680493  \n",
       "3  6.119193e+06    15.626941          14.815009  \n",
       "4  1.084776e+06    13.896885          12.136623  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-14 5908.873901\n",
      "12 model-15 5900.873836\n",
      "13 model-16 5907.874126\n",
      "14 model-17 5905.874165\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, metric):\n",
    "    cv_pred_final = cv.loc[:,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    global best_score\n",
    "    global best_coeffs\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        print('find better score:')\n",
    "        print('score: ', score)\n",
    "        print('coeffs: ', x)\n",
    "        print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306661839966\n",
      "coeffs:  [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670970732\n",
      "coeffs:  [0.06250001 0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670971289\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.06250001 0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670977765\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.06250001 0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  110.213515428704\n",
      "coeffs:  [0.06910995 0.06910808 0.0691099  0.06911035 0.06910995 0.06910991\n",
      " 0.06910721 0.06911015 0.06910987 0.06910985 0.06911504 0.06910986\n",
      " 0.06910988 0.06910987 0.06910988 0.06299122]\n",
      "\n",
      "find better score:\n",
      "score:  1768.798682955031\n",
      "coeffs:  [0.06539629 0.06539548 0.06539627 0.06539647 0.0653963  0.06539628\n",
      " 0.0653951  0.06539638 0.06539626 0.06539625 0.06539852 0.06539625\n",
      " 0.06539627 0.06539626 0.06539626 0.06271524]\n",
      "\n",
      "find better score:\n",
      "score:  1768.7986830785892\n",
      "coeffs:  [0.06539631 0.06539548 0.06539627 0.06539647 0.0653963  0.06539628\n",
      " 0.0653951  0.06539638 0.06539626 0.06539625 0.06539852 0.06539625\n",
      " 0.06539627 0.06539626 0.06539626 0.06271524]\n",
      "\n",
      "find better score:\n",
      "score:  1768.7986830785928\n",
      "coeffs:  [0.06539629 0.06539548 0.06539629 0.06539647 0.0653963  0.06539628\n",
      " 0.0653951  0.06539638 0.06539626 0.06539625 0.06539852 0.06539625\n",
      " 0.06539627 0.06539626 0.06539626 0.06271524]\n",
      "\n",
      "find better score:\n",
      "score:  1768.798683078611\n",
      "coeffs:  [0.06539629 0.06539548 0.06539627 0.06539647 0.06539631 0.06539628\n",
      " 0.0653951  0.06539638 0.06539626 0.06539625 0.06539852 0.06539625\n",
      " 0.06539627 0.06539626 0.06539626 0.06271524]\n",
      "\n",
      "find better score:\n",
      "score:  5422.866987594094\n",
      "coeffs:  [0.06607492 0.06607391 0.06607489 0.06607514 0.06607492 0.0660749\n",
      " 0.06607344 0.06607503 0.06607488 0.06607486 0.06607767 0.06607487\n",
      " 0.06607488 0.06607488 0.06607488 0.06276567]\n",
      "\n",
      "find better score:\n",
      "score:  5422.866987652707\n",
      "coeffs:  [0.06607493 0.06607391 0.06607489 0.06607514 0.06607492 0.0660749\n",
      " 0.06607344 0.06607503 0.06607488 0.06607486 0.06607767 0.06607487\n",
      " 0.06607488 0.06607488 0.06607488 0.06276567]\n",
      "\n",
      "find better score:\n",
      "score:  5422.866987652714\n",
      "coeffs:  [0.06607492 0.06607391 0.06607491 0.06607514 0.06607492 0.0660749\n",
      " 0.06607344 0.06607503 0.06607488 0.06607486 0.06607767 0.06607487\n",
      " 0.06607488 0.06607488 0.06607488 0.06276567]\n",
      "\n",
      "find better score:\n",
      "score:  5422.866987652737\n",
      "coeffs:  [0.06607492 0.06607391 0.06607489 0.06607514 0.06607494 0.0660749\n",
      " 0.06607344 0.06607503 0.06607488 0.06607486 0.06607767 0.06607487\n",
      " 0.06607488 0.06607488 0.06607488 0.06276567]\n",
      "\n",
      "find better score:\n",
      "score:  5858.870755504076\n",
      "coeffs:  [0.06654057 0.06646738 0.06660779 0.06640277 0.06685784 0.06657349\n",
      " 0.06648492 0.06657508 0.06656301 0.06662482 0.06452608 0.06663365\n",
      " 0.06662073 0.06664605 0.06664777 0.06103412]\n",
      "\n",
      "find better score:\n",
      "score:  5874.874209387862\n",
      "coeffs:  [0.06631539 0.06627711 0.06635009 0.06624433 0.06647923 0.06633238\n",
      " 0.06628593 0.06633326 0.06632695 0.06635887 0.0652764  0.06636343\n",
      " 0.06635677 0.06636984 0.06637073 0.06187147]\n",
      "\n",
      "find better score:\n",
      "score:  5874.874209401269\n",
      "coeffs:  [0.0663154  0.06627711 0.06635009 0.06624433 0.06647923 0.06633238\n",
      " 0.06628593 0.06633326 0.06632695 0.06635887 0.0652764  0.06636343\n",
      " 0.06635677 0.06636984 0.06637073 0.06187147]\n",
      "\n",
      "find better score:\n",
      "score:  5874.874209401273\n",
      "coeffs:  [0.06631539 0.06627711 0.0663501  0.06624433 0.06647923 0.06633238\n",
      " 0.06628593 0.06633326 0.06632695 0.06635887 0.0652764  0.06636343\n",
      " 0.06635677 0.06636984 0.06637073 0.06187147]\n",
      "\n",
      "find better score:\n",
      "score:  5874.874209401297\n",
      "coeffs:  [0.06631539 0.06627711 0.06635009 0.06624433 0.06647925 0.06633238\n",
      " 0.06628593 0.06633326 0.06632695 0.06635887 0.0652764  0.06636343\n",
      " 0.06635677 0.06636984 0.06637073 0.06187147]\n",
      "\n",
      "find better score:\n",
      "score:  5906.874722462834\n",
      "coeffs:  [0.06724456 0.06574542 0.0676248  0.06635179 0.06931293 0.06747595\n",
      " 0.06527872 0.06715576 0.06734339 0.06776936 0.05267879 0.06782809\n",
      " 0.06773905 0.06798105 0.06803997 0.05284287]\n",
      "\n",
      "find better score:\n",
      "score:  5915.874999859242\n",
      "coeffs:  [0.06818192 0.06519071 0.06902504 0.06639143 0.07254699 0.06868164\n",
      " 0.06378    0.06824603 0.06836184 0.06925749 0.03851002 0.06939246\n",
      " 0.06920453 0.06971398 0.06983211 0.04219684]\n",
      "\n",
      "find better score:\n",
      "score:  5934.87583636496\n",
      "coeffs:  [ 0.07193137  0.06297187  0.07462597  0.06655002  0.08548321  0.07350439\n",
      "  0.0577851   0.07260712  0.07243566  0.07521001 -0.01816503  0.07564993\n",
      "  0.07506648  0.07664566  0.07700066 -0.00038728]\n",
      "\n",
      "find better score:\n",
      "score:  5934.8758363655925\n",
      "coeffs:  [ 0.07193138  0.06297187  0.07462597  0.06655002  0.08548321  0.07350439\n",
      "  0.0577851   0.07260712  0.07243566  0.07521001 -0.01816503  0.07564993\n",
      "  0.07506648  0.07664566  0.07700066 -0.00038728]\n",
      "\n",
      "find better score:\n",
      "score:  5934.875836365599\n",
      "coeffs:  [ 0.07193137  0.06297187  0.07462598  0.06655002  0.08548321  0.07350439\n",
      "  0.0577851   0.07260712  0.07243566  0.07521001 -0.01816503  0.07564993\n",
      "  0.07506648  0.07664566  0.07700066 -0.00038728]\n",
      "\n",
      "find better score:\n",
      "score:  5934.875836365618\n",
      "coeffs:  [ 0.07193137  0.06297187  0.07462597  0.06655002  0.08548322  0.07350439\n",
      "  0.0577851   0.07260712  0.07243566  0.07521001 -0.01816503  0.07564993\n",
      "  0.07506648  0.07664566  0.07700066 -0.00038728]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876274084613\n",
      "coeffs:  [ 0.07756837  0.05900466  0.08373285  0.06730524  0.10769943  0.08114763\n",
      "  0.04751117  0.08044792  0.07871626  0.0849002  -0.11096996  0.08591474\n",
      "  0.08458532  0.0881482   0.08894403 -0.07168866]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275283\n",
      "coeffs:  [ 0.07251174  0.05627485  0.08112036  0.07008556  0.11194272  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275781\n",
      "coeffs:  [ 0.07251175  0.05627485  0.08112036  0.07008556  0.11194272  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275784\n",
      "coeffs:  [ 0.07251174  0.05627486  0.08112036  0.07008556  0.11194272  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275788\n",
      "coeffs:  [ 0.07251174  0.05627485  0.08112038  0.07008556  0.11194272  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275796\n",
      "coeffs:  [ 0.07251174  0.05627485  0.08112036  0.07008558  0.11194272  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5948.876337275804\n",
      "coeffs:  [ 0.07251174  0.05627485  0.08112036  0.07008556  0.11194274  0.07754414\n",
      "  0.04499126  0.08491899  0.07431684  0.08262713 -0.09303334  0.08396675\n",
      "  0.0822068   0.08700063  0.0879736  -0.07128618]\n",
      "\n",
      "find better score:\n",
      "score:  5951.8763854501285\n",
      "coeffs:  [ 0.06442318  0.0504569   0.07831481  0.0753702   0.12443708  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5951.876385450135\n",
      "coeffs:  [ 0.06442319  0.0504569   0.07831481  0.0753702   0.12443708  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5951.87638545014\n",
      "coeffs:  [ 0.06442318  0.05045691  0.07831481  0.0753702   0.12443708  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5951.876385450141\n",
      "coeffs:  [ 0.06442318  0.0504569   0.07831482  0.0753702   0.12443708  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5951.876385450147\n",
      "coeffs:  [ 0.06442318  0.0504569   0.07831481  0.07537021  0.12443708  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5951.876385450153\n",
      "coeffs:  [ 0.06442318  0.0504569   0.07831481  0.0753702   0.12443709  0.07260677\n",
      "  0.03846533  0.09497737  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5951.876385450154\n",
      "coeffs:  [ 0.06442318  0.0504569   0.07831481  0.0753702   0.12443708  0.07260677\n",
      "  0.03846533  0.09497738  0.06760441  0.08058043 -0.08048914  0.08264033\n",
      "  0.07990334  0.08741263  0.08881394 -0.08575263]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876420476083\n",
      "coeffs:  [ 0.05116755  0.04078176  0.07437522  0.08413418  0.14681545  0.06486983\n",
      "  0.02747244  0.11266676  0.05676691  0.07798508 -0.0680091   0.08132371\n",
      "  0.07685474  0.08912088  0.0913066  -0.11487316]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876424586274\n",
      "coeffs:  [ 0.05066112  0.04036093  0.07467303  0.08437222  0.14872186  0.0648133\n",
      "  0.02733632  0.11378618  0.05646342  0.07839802 -0.07281855  0.0818519\n",
      "  0.07722971  0.08989301  0.09215081 -0.11863717]\n",
      "\n",
      "find better score:\n",
      "score:  5954.876424586277\n",
      "coeffs:  [ 0.05066112  0.04036093  0.07467303  0.08437222  0.14872186  0.0648133\n",
      "  0.02733632  0.11378618  0.05646342  0.07839802 -0.07281855  0.0818519\n",
      "  0.07722971  0.08989301  0.09215081 -0.11863715]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03972207102621735, -0.9297438947176777, -0.15485387425449446, 0.9020171214756327, 2.7290192415094934, 0.06937253292819484, 0.5451364361054207, 2.07466701220561, -0.08043049136928021, 1.7801025546900116, -0.506898548749846, 0.19925180292488592, 1.580100366001101, -0.3103856451108657, -0.5265560879545358, -1.4684488384457435]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-2.1122369666782315, 0.2305242708454739, -0.622899062733903, 0.1938246311237144, -0.740870755054716, -0.41802791346156526, -0.6080437897961751, -1.106691071677159, -1.1120260599266687, -0.25173667047862713, 1.4871211331380767, 1.0460408618170747, 1.53451960163091, 0.20075410725724077, -0.024741814675871984, 0.6381472567807771]\n",
      "\n",
      "Optimizing with init x0: [-0.16210389449191376, 2.0282426185568743, 0.8463494933417586, 0.5688863756724017, 1.0926407715149298, -2.6202247860606844, 0.2906880026066536, -0.14117014463081132, 0.8153404568504985, 0.9082642060294497, 0.433621925361761, 0.8977118335482885, 0.04148670286377694, -2.6977170872532854, 1.237665318980641, -1.404187071738447]\n",
      "\n",
      "Optimizing with init x0: [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306661839966\n",
      "coeffs:  [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670970732\n",
      "coeffs:  [0.06250001 0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670971289\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.06250001 0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670977765\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.06250001 0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  82.10986464088477\n",
      "coeffs:  [0.06939212 0.06939641 0.06939261 0.06938496 0.06936711 0.06939245\n",
      " 0.06939587 0.06939735 0.06939296 0.06939295 0.06937728 0.06939307\n",
      " 0.06939309 0.06939293 0.06939287 0.06297625]\n",
      "\n",
      "find better score:\n",
      "score:  2152.811872584065\n",
      "coeffs:  [0.06550486 0.06550673 0.06550507 0.06550174 0.06549396 0.065505\n",
      " 0.06550649 0.06550714 0.06550522 0.06550522 0.06549839 0.06550528\n",
      " 0.06550528 0.06550521 0.06550519 0.06270764]\n",
      "\n",
      "find better score:\n",
      "score:  2152.8118727035826\n",
      "coeffs:  [0.06550487 0.06550673 0.06550507 0.06550174 0.06549396 0.065505\n",
      " 0.06550649 0.06550714 0.06550522 0.06550522 0.06549839 0.06550528\n",
      " 0.06550528 0.06550521 0.06550519 0.06270764]\n",
      "\n",
      "find better score:\n",
      "score:  2152.811872703586\n",
      "coeffs:  [0.06550486 0.06550673 0.06550509 0.06550174 0.06549396 0.065505\n",
      " 0.06550649 0.06550714 0.06550522 0.06550522 0.06549839 0.06550528\n",
      " 0.06550528 0.06550521 0.06550519 0.06270764]\n",
      "\n",
      "find better score:\n",
      "score:  2152.8118727036067\n",
      "coeffs:  [0.06550486 0.06550673 0.06550507 0.06550174 0.06549397 0.065505\n",
      " 0.06550649 0.06550714 0.06550522 0.06550522 0.06549839 0.06550528\n",
      " 0.06550528 0.06550521 0.06550519 0.06270764]\n",
      "\n",
      "find better score:\n",
      "score:  5877.874239014634\n",
      "coeffs:  [0.06626993 0.06627227 0.06627019 0.06626601 0.06625625 0.0662701\n",
      " 0.06627198 0.06627279 0.06627038 0.06627038 0.06626181 0.06627045\n",
      " 0.06627045 0.06627037 0.06627034 0.06276051]\n",
      "\n",
      "find better score:\n",
      "score:  5877.874239026905\n",
      "coeffs:  [0.06626994 0.06627227 0.06627019 0.06626601 0.06625625 0.0662701\n",
      " 0.06627198 0.06627279 0.06627038 0.06627038 0.06626181 0.06627045\n",
      " 0.06627045 0.06627037 0.06627034 0.06276051]\n",
      "\n",
      "find better score:\n",
      "score:  5877.87423902691\n",
      "coeffs:  [0.06626993 0.06627227 0.06627021 0.06626601 0.06625625 0.0662701\n",
      " 0.06627198 0.06627279 0.06627038 0.06627038 0.06626181 0.06627045\n",
      " 0.06627045 0.06627037 0.06627034 0.06276051]\n",
      "\n",
      "find better score:\n",
      "score:  5877.8742390269335\n",
      "coeffs:  [0.06626993 0.06627227 0.06627019 0.06626601 0.06625626 0.0662701\n",
      " 0.06627198 0.06627279 0.06627038 0.06627038 0.06626181 0.06627045\n",
      " 0.06627045 0.06627037 0.06627034 0.06276051]\n",
      "\n",
      "find better score:\n",
      "score:  5887.874063596688\n",
      "coeffs:  [-0.28228666  0.06335383  0.64878216 -0.02653126  0.09512273 -0.21939657\n",
      "  0.08853838  0.05693012  0.34743214 -0.0253592  -0.177504    2.38320974\n",
      " -2.44744587 -0.6783458   1.17584942 -0.03092364]\n",
      "\n",
      "find better score:\n",
      "score:  5914.8749480355655\n",
      "coeffs:  [-0.08153267  0.02620861  0.52079418 -0.00813862  0.09563322  0.02024393\n",
      "  0.10788832  0.14710438  0.05631462 -0.11357892 -0.16181791  1.40911754\n",
      " -1.99682421  0.04225086  0.9368028  -0.00809569]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03972207102621735, -0.9297438947176777, -0.15485387425449446, 0.9020171214756327, 2.7290192415094934, 0.06937253292819484, 0.5451364361054207, 2.07466701220561, -0.08043049136928021, 1.7801025546900116, -0.506898548749846, 0.19925180292488592, 1.580100366001101, -0.3103856451108657, -0.5265560879545358, -1.4684488384457435]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-2.1122369666782315, 0.2305242708454739, -0.622899062733903, 0.1938246311237144, -0.740870755054716, -0.41802791346156526, -0.6080437897961751, -1.106691071677159, -1.1120260599266687, -0.25173667047862713, 1.4871211331380767, 1.0460408618170747, 1.53451960163091, 0.20075410725724077, -0.024741814675871984, 0.6381472567807771]\n",
      "\n",
      "Optimizing with init x0: [-0.16210389449191376, 2.0282426185568743, 0.8463494933417586, 0.5688863756724017, 1.0926407715149298, -2.6202247860606844, 0.2906880026066536, -0.14117014463081132, 0.8153404568504985, 0.9082642060294497, 0.433621925361761, 0.8977118335482885, 0.04148670286377694, -2.6977170872532854, 1.237665318980641, -1.404187071738447]\n",
      "\n",
      "Optimizing with init x0: [0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625, 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306661839966\n",
      "coeffs:  [0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625\n",
      " 0.0625 0.0625 0.0625 0.0625 0.0625 0.0625]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670970732\n",
      "coeffs:  [0.06250001 0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670971289\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.06250001 0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  32.46306670977765\n",
      "coeffs:  [0.0625     0.0625     0.0625     0.0625     0.0625     0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625     0.06250001 0.0625\n",
      " 0.0625     0.0625     0.0625     0.0625    ]\n",
      "\n",
      "find better score:\n",
      "score:  1452.7845783022967\n",
      "coeffs:  [0.06528465 0.06531663 0.06528719 0.0652715  0.06521055 0.06528654\n",
      " 0.06530071 0.06532217 0.06528896 0.06528757 0.06526025 0.06528849\n",
      " 0.06528801 0.06528691 0.06528754 0.0626762 ]\n",
      "\n",
      "find better score:\n",
      "score:  1452.7845784288459\n",
      "coeffs:  [0.06528466 0.06531663 0.06528719 0.0652715  0.06521055 0.06528654\n",
      " 0.06530071 0.06532217 0.06528896 0.06528757 0.06526025 0.06528849\n",
      " 0.06528801 0.06528691 0.06528754 0.0626762 ]\n",
      "\n",
      "find better score:\n",
      "score:  1452.784578428849\n",
      "coeffs:  [0.06528465 0.06531663 0.06528721 0.0652715  0.06521055 0.06528654\n",
      " 0.06530071 0.06532217 0.06528896 0.06528757 0.06526025 0.06528849\n",
      " 0.06528801 0.06528691 0.06528754 0.0626762 ]\n",
      "\n",
      "find better score:\n",
      "score:  1452.7845784288638\n",
      "coeffs:  [0.06528465 0.06531663 0.06528719 0.0652715  0.06521057 0.06528654\n",
      " 0.06530071 0.06532217 0.06528896 0.06528757 0.06526025 0.06528849\n",
      " 0.06528801 0.06528691 0.06528754 0.0626762 ]\n",
      "\n",
      "find better score:\n",
      "score:  2329.7759687872376\n",
      "coeffs:  [ 0.07085329  0.11693349  0.0715703  -0.07679661  0.50200555  0.05764674\n",
      "  0.00929491  0.20916486  0.07588798  0.02588963 -0.15367009  0.03747642\n",
      "  0.01944235  0.01642259  0.03099974 -0.02083781]\n",
      "\n",
      "find better score:\n",
      "score:  5710.872266740091\n",
      "coeffs:  [ 0.06792574  0.08979746  0.06826714 -0.00210852  0.27237356  0.06166314\n",
      "  0.0387383   0.13354384  0.07031586  0.04660193 -0.03857397  0.05209779\n",
      "  0.04354434  0.04211156  0.04902553  0.0230672 ]\n",
      "\n",
      "find better score:\n",
      "score:  5710.872266781437\n",
      "coeffs:  [ 0.06792576  0.08979746  0.06826714 -0.00210852  0.27237356  0.06166314\n",
      "  0.0387383   0.13354384  0.07031586  0.04660193 -0.03857397  0.05209779\n",
      "  0.04354434  0.04211156  0.04902553  0.0230672 ]\n",
      "\n",
      "find better score:\n",
      "score:  5710.872266781443\n",
      "coeffs:  [ 0.06792574  0.08979746  0.06826716 -0.00210852  0.27237356  0.06166314\n",
      "  0.0387383   0.13354384  0.07031586  0.04660193 -0.03857397  0.05209779\n",
      "  0.04354434  0.04211156  0.04902553  0.0230672 ]\n",
      "\n",
      "find better score:\n",
      "score:  5710.872266781448\n",
      "coeffs:  [ 0.06792574  0.08979746  0.06826714 -0.00210851  0.27237356  0.06166314\n",
      "  0.0387383   0.13354384  0.07031586  0.04660193 -0.03857397  0.05209779\n",
      "  0.04354434  0.04211156  0.04902553  0.0230672 ]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "find better score:\n",
      "score:  5828.869558149154\n",
      "coeffs:  [0.06674593 0.06730138 0.06674593 0.06711623 0.06276525 0.06674593\n",
      " 0.06776425 0.06730138 0.06674593 0.06711623 0.06674593 0.06702366\n",
      " 0.06702366 0.06711623 0.06702366 0.00472128]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03972207102621735, -0.9297438947176777, -0.15485387425449446, 0.9020171214756327, 2.7290192415094934, 0.06937253292819484, 0.5451364361054207, 2.07466701220561, -0.08043049136928021, 1.7801025546900116, -0.506898548749846, 0.19925180292488592, 1.580100366001101, -0.3103856451108657, -0.5265560879545358, -1.4684488384457435]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-2.1122369666782315, 0.2305242708454739, -0.622899062733903, 0.1938246311237144, -0.740870755054716, -0.41802791346156526, -0.6080437897961751, -1.106691071677159, -1.1120260599266687, -0.25173667047862713, 1.4871211331380767, 1.0460408618170747, 1.53451960163091, 0.20075410725724077, -0.024741814675871984, 0.6381472567807771]\n",
      "\n",
      "Optimizing with init x0: [-0.16210389449191376, 2.0282426185568743, 0.8463494933417586, 0.5688863756724017, 1.0926407715149298, -2.6202247860606844, 0.2906880026066536, -0.14117014463081132, 0.8153404568504985, 0.9082642060294497, 0.433621925361761, 0.8977118335482885, 0.04148670286377694, -2.6977170872532854, 1.237665318980641, -1.404187071738447]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [ [1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "#for metric in ['mape']:\n",
    "for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        try:\n",
    "            minimize(objective, x0, args=(metric))\n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 5954.876424586277,\n",
       " 'mae': 5914.8749480355655,\n",
       " 'mse': 5828.869558149154}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([ 0.05066112,  0.04036093,  0.07467303,  0.08437222,  0.14872186,\n",
       "         0.0648133 ,  0.02733632,  0.11378618,  0.05646342,  0.07839802,\n",
       "        -0.07281855,  0.0818519 ,  0.07722971,  0.08989301,  0.09215081,\n",
       "        -0.11863715]),\n",
       " 'mae': array([-0.08153267,  0.02620861,  0.52079418, -0.00813862,  0.09563322,\n",
       "         0.02024393,  0.10788832,  0.14710438,  0.05631462, -0.11357892,\n",
       "        -0.16181791,  1.40911754, -1.99682421,  0.04225086,  0.9368028 ,\n",
       "        -0.00809569]),\n",
       " 'mse': array([0.06674593, 0.06730138, 0.06674593, 0.06711623, 0.06276525,\n",
       "        0.06674593, 0.06776425, 0.06730138, 0.06674593, 0.06711623,\n",
       "        0.06674593, 0.06702366, 0.06702366, 0.06711623, 0.06702366,\n",
       "        0.00472128])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1/17 if i in [3, 4, 7, 8, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26] else 0 \\\n",
    " for i in list(range(1,24)) + list(range(25,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
