{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape, cal_score_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '19'\n",
    "models = '1-34,36-37'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = True\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n",
      "32 model-32-lgb-remove_outlier_01-cv.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-kfold.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-one.csv\n",
      "33 model-33-lgb-remove_outlier_03-cv.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-kfold.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-one.csv\n",
      "34 model-34-lgb-remove_outlier_01-cv.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-kfold.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-one.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-kfold.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "37 model-37-lgb-remove_outlier_05-cv.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-kfold.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "36\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n",
      "model-32-lgb-remove_outlier_01-cv.csv\n",
      "model-33-lgb-remove_outlier_03-cv.csv\n",
      "model-34-lgb-remove_outlier_01-cv.csv\n",
      "model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "model-37-lgb-remove_outlier_05-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n",
      "No. 31 file: model-32-lgb-remove_outlier_01-test-one.csv\n",
      "No. 32 file: model-33-lgb-remove_outlier_03-test-one.csv\n",
      "No. 33 file: model-34-lgb-remove_outlier_01-test-one.csv\n",
      "No. 34 file: model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "No. 35 file: model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360546</td>\n",
       "      <td>12.131443</td>\n",
       "      <td>6.245441e+05</td>\n",
       "      <td>13.344779</td>\n",
       "      <td>12.115676</td>\n",
       "      <td>6.319899e+05</td>\n",
       "      <td>13.356630</td>\n",
       "      <td>12.127527</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.934792</td>\n",
       "      <td>13.538225</td>\n",
       "      <td>3.042045e+06</td>\n",
       "      <td>14.928041</td>\n",
       "      <td>13.531473</td>\n",
       "      <td>3.142342e+06</td>\n",
       "      <td>14.960479</td>\n",
       "      <td>13.563912</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.111430</td>\n",
       "      <td>14.391475</td>\n",
       "      <td>9.818275e+06</td>\n",
       "      <td>16.099756</td>\n",
       "      <td>14.379801</td>\n",
       "      <td>9.946933e+06</td>\n",
       "      <td>16.112775</td>\n",
       "      <td>14.392820</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.360720</td>\n",
       "      <td>13.753373</td>\n",
       "      <td>1.264691e+07</td>\n",
       "      <td>16.352924</td>\n",
       "      <td>13.745577</td>\n",
       "      <td>1.295773e+07</td>\n",
       "      <td>16.377203</td>\n",
       "      <td>13.769857</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833961</td>\n",
       "      <td>12.288935</td>\n",
       "      <td>9.305770e+05</td>\n",
       "      <td>13.743561</td>\n",
       "      <td>12.198536</td>\n",
       "      <td>9.859947e+05</td>\n",
       "      <td>13.801407</td>\n",
       "      <td>12.256382</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "           ...            log_pred_34  log_parea_pred_34       pred_36  \\\n",
       "0          ...              13.360546          12.131443  6.245441e+05   \n",
       "1          ...              14.934792          13.538225  3.042045e+06   \n",
       "2          ...              16.111430          14.391475  9.818275e+06   \n",
       "3          ...              16.360720          13.753373  1.264691e+07   \n",
       "4          ...              13.833961          12.288935  9.305770e+05   \n",
       "\n",
       "   log_pred_36  log_parea_pred_36       pred_37  log_pred_37  \\\n",
       "0    13.344779          12.115676  6.319899e+05    13.356630   \n",
       "1    14.928041          13.531473  3.142342e+06    14.960479   \n",
       "2    16.099756          14.379801  9.946933e+06    16.112775   \n",
       "3    16.352924          13.745577  1.295773e+07    16.377203   \n",
       "4    13.743561          12.198536  9.859947e+05    13.801407   \n",
       "\n",
       "   log_parea_pred_37  log_total_price  log_parea_total_price  \n",
       "0          12.127527        13.381036              12.151933  \n",
       "1          13.563912        15.015913              13.619345  \n",
       "2          14.392820        16.074236              14.354282  \n",
       "3          13.769857        16.469809              13.862462  \n",
       "4          12.256382        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_33</th>\n",
       "      <th>pred_34</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.177853</td>\n",
       "      <td>1.265085e+07</td>\n",
       "      <td>16.353235</td>\n",
       "      <td>15.124128</td>\n",
       "      <td>1.298618e+07</td>\n",
       "      <td>16.379396</td>\n",
       "      <td>15.150290</td>\n",
       "      <td>1.304845e+07</td>\n",
       "      <td>16.384180</td>\n",
       "      <td>15.155073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.129452</td>\n",
       "      <td>3.890897e+06</td>\n",
       "      <td>15.174151</td>\n",
       "      <td>13.129532</td>\n",
       "      <td>3.897411e+06</td>\n",
       "      <td>15.175823</td>\n",
       "      <td>13.131204</td>\n",
       "      <td>3.897545e+06</td>\n",
       "      <td>15.175858</td>\n",
       "      <td>13.131239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.676769</td>\n",
       "      <td>1.078313e+07</td>\n",
       "      <td>16.193493</td>\n",
       "      <td>13.694473</td>\n",
       "      <td>1.049745e+07</td>\n",
       "      <td>16.166643</td>\n",
       "      <td>13.667623</td>\n",
       "      <td>1.035078e+07</td>\n",
       "      <td>16.152573</td>\n",
       "      <td>13.653552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.815015</td>\n",
       "      <td>6.080412e+06</td>\n",
       "      <td>15.620583</td>\n",
       "      <td>14.808651</td>\n",
       "      <td>6.139949e+06</td>\n",
       "      <td>15.630327</td>\n",
       "      <td>14.818395</td>\n",
       "      <td>6.120593e+06</td>\n",
       "      <td>15.627170</td>\n",
       "      <td>14.815237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.159895</td>\n",
       "      <td>1.092040e+06</td>\n",
       "      <td>13.903559</td>\n",
       "      <td>12.143297</td>\n",
       "      <td>1.106728e+06</td>\n",
       "      <td>13.916919</td>\n",
       "      <td>12.156657</td>\n",
       "      <td>1.098338e+06</td>\n",
       "      <td>13.909310</td>\n",
       "      <td>12.149048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3        ...          log_parea_pred_33       pred_34  \\\n",
       "0   16.544464        ...                  15.177853  1.265085e+07   \n",
       "1   15.196062        ...                  13.129452  3.890897e+06   \n",
       "2   16.199646        ...                  13.676769  1.078313e+07   \n",
       "3   15.609807        ...                  14.815015  6.080412e+06   \n",
       "4   13.842395        ...                  12.159895  1.092040e+06   \n",
       "\n",
       "   log_pred_34  log_parea_pred_34       pred_36  log_pred_36  \\\n",
       "0    16.353235          15.124128  1.298618e+07    16.379396   \n",
       "1    15.174151          13.129532  3.897411e+06    15.175823   \n",
       "2    16.193493          13.694473  1.049745e+07    16.166643   \n",
       "3    15.620583          14.808651  6.139949e+06    15.630327   \n",
       "4    13.903559          12.143297  1.106728e+06    13.916919   \n",
       "\n",
       "   log_parea_pred_36       pred_37  log_pred_37  log_parea_pred_37  \n",
       "0          15.150290  1.304845e+07    16.384180          15.155073  \n",
       "1          13.131204  3.897545e+06    15.175858          13.131239  \n",
       "2          13.667623  1.035078e+07    16.152573          13.653552  \n",
       "3          14.818395  6.120593e+06    15.627170          14.815237  \n",
       "4          12.156657  1.098338e+06    13.909310          12.149048  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n",
      "31 model-32 5930.875106\n",
      "32 model-33 5976.875715\n",
      "33 model-34 5942.875172\n",
      "34 model-36 5989.876236\n",
      "35 model-37 5980.875836\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, cv, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv[cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "      ]\n",
    "bounds = tuple([(0, 1) for i in range(len_x-1)] + [(-2, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV\n",
    "(skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.03846021  0.00062566 -0.03117297  0.0022633  -0.03071847  0.01749487\n",
      "  0.08838549  0.00329446  0.09265428 -0.0070245   0.04951577  0.07034371\n",
      "  0.05030559  0.03186655  0.03716567  0.01666125 -0.01613149  0.06202454\n",
      "  0.03040203  0.03326463  0.05830177 -0.04199244  0.02952393 -0.00491137\n",
      "  0.02777167  0.00680121 -0.01672517  0.04532399]\n",
      "\n",
      "Optimizing with init x0: [ 0.06978301  0.00716537  0.01933011 -0.04041742  0.03065218 -0.0445668\n",
      "  0.02177403  0.09387119 -0.0091588   0.04360813  0.0228007   0.00906132\n",
      "  0.02944168  0.08750569  0.03127045  0.07687615  0.02886889  0.01880305\n",
      " -0.02339895  0.00698907 -0.03777497  0.03324249  0.05073555  0.02176212\n",
      "  0.07462535  0.06523475 -0.04306402  0.06929561]\n",
      "\n",
      "Optimizing with init x0: [ 0.04733216  0.01769283  0.06722644  0.0327374   0.02392443  0.0763044\n",
      "  0.00937986  0.02932873  0.02586816  0.08313561  0.0832105   0.04584757\n",
      " -0.04382431  0.06313654  0.07997944  0.02523787  0.03105419  0.01871397\n",
      "  0.00151872  0.06255577  0.0190668   0.00805016  0.01590134  0.00189762\n",
      "  0.00588149  0.00291054  0.00714683  0.02285781]\n",
      "\n",
      "Optimizing with init x0: [0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.03846021  0.00062566 -0.03117297  0.0022633  -0.03071847  0.01749487\n",
      "  0.08838549  0.00329446  0.09265428 -0.0070245   0.04951577  0.07034371\n",
      "  0.05030559  0.03186655  0.03716567  0.01666125 -0.01613149  0.06202454\n",
      "  0.03040203  0.03326463  0.05830177 -0.04199244  0.02952393 -0.00491137\n",
      "  0.02777167  0.00680121 -0.01672517  0.04532399]\n",
      "\n",
      "Optimizing with init x0: [ 0.06978301  0.00716537  0.01933011 -0.04041742  0.03065218 -0.0445668\n",
      "  0.02177403  0.09387119 -0.0091588   0.04360813  0.0228007   0.00906132\n",
      "  0.02944168  0.08750569  0.03127045  0.07687615  0.02886889  0.01880305\n",
      " -0.02339895  0.00698907 -0.03777497  0.03324249  0.05073555  0.02176212\n",
      "  0.07462535  0.06523475 -0.04306402  0.06929561]\n",
      "\n",
      "Optimizing with init x0: [ 0.04733216  0.01769283  0.06722644  0.0327374   0.02392443  0.0763044\n",
      "  0.00937986  0.02932873  0.02586816  0.08313561  0.0832105   0.04584757\n",
      " -0.04382431  0.06313654  0.07997944  0.02523787  0.03105419  0.01871397\n",
      "  0.00151872  0.06255577  0.0190668   0.00805016  0.01590134  0.00189762\n",
      "  0.00588149  0.00291054  0.00714683  0.02285781]\n",
      "\n",
      "Optimizing with init x0: [0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.03846021  0.00062566 -0.03117297  0.0022633  -0.03071847  0.01749487\n",
      "  0.08838549  0.00329446  0.09265428 -0.0070245   0.04951577  0.07034371\n",
      "  0.05030559  0.03186655  0.03716567  0.01666125 -0.01613149  0.06202454\n",
      "  0.03040203  0.03326463  0.05830177 -0.04199244  0.02952393 -0.00491137\n",
      "  0.02777167  0.00680121 -0.01672517  0.04532399]\n",
      "\n",
      "Optimizing with init x0: [ 0.06978301  0.00716537  0.01933011 -0.04041742  0.03065218 -0.0445668\n",
      "  0.02177403  0.09387119 -0.0091588   0.04360813  0.0228007   0.00906132\n",
      "  0.02944168  0.08750569  0.03127045  0.07687615  0.02886889  0.01880305\n",
      " -0.02339895  0.00698907 -0.03777497  0.03324249  0.05073555  0.02176212\n",
      "  0.07462535  0.06523475 -0.04306402  0.06929561]\n",
      "\n",
      "Optimizing with init x0: [ 0.04733216  0.01769283  0.06722644  0.0327374   0.02392443  0.0763044\n",
      "  0.00937986  0.02932873  0.02586816  0.08313561  0.0832105   0.04584757\n",
      " -0.04382431  0.06313654  0.07997944  0.02523787  0.03105419  0.01871397\n",
      "  0.00151872  0.06255577  0.0190668   0.00805016  0.01590134  0.00189762\n",
      "  0.00588149  0.00291054  0.00714683  0.02285781]\n",
      "\n",
      "CV score ?: 5979.876215571559; [5976.874373263616, 5991.875402853464, 5970.8788705976]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = cv.reset_index(drop=True)\n",
    "#cv = cv.head(100)\n",
    "\n",
    "score_list = []\n",
    "\n",
    "kf = KFold(shuffle= True)\n",
    "for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "    best_score = {}\n",
    "    best_coeffs = {}\n",
    "    \n",
    "    cv_fold_train = cv.loc[idx_train].reset_index(drop=True)\n",
    "    cv_fold_val = cv.loc[idx_train].reset_index(drop=True)\n",
    "    \n",
    "    for metric in ['smooth']:\n",
    "    #for metric in ['mape', 'mae', 'mse']:\n",
    "        best_score[metric] = 0\n",
    "        best_coeffs[metric] = []\n",
    "        for x0 in x0s:\n",
    "            print('Optimizing with init x0: {}'.format(x0))\n",
    "            print()\n",
    "            minimize(objective, x0, args=(cv_fold_train, metric, best_score, best_coeffs, \n",
    "                                          True), \n",
    "                     tol=1e-4) #, bounds=bounds\n",
    "    \n",
    "    val_pred_final = cv_fold_val[cols_opt].dot(best_coeffs['smooth'])\n",
    "    if is_per_area:\n",
    "        val_pred_final = np.expm1(val_pred_final) * cv_fold_val['building_area']\n",
    "    else:\n",
    "        val_pred_final = np.expm1(val_pred_final)\n",
    "    score = cal_score(cv_fold_val['total_price'], val_pred_final)\n",
    "    \n",
    "    score_list.append(score)\n",
    "\n",
    "print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.7076148557613\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.707614984484\n",
      "coeffs:  [0.02702704 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.7076149844853\n",
      "coeffs:  [0.02702703 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.7076149844879\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702704 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.7076149844938\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.7076149844996\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  528.707614984518\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  641.6131398852162\n",
      "coeffs:  [0.0283361  0.02833586 0.02833604 0.02833623 0.02833588 0.02833604\n",
      " 0.02833508 0.02833591 0.02833596 0.02833599 0.02833844 0.02833613\n",
      " 0.02833616 0.02833603 0.02833603 0.02833603 0.02833601 0.02833598\n",
      " 0.02833603 0.02833603 0.02833593 0.02833591 0.02833596 0.02833597\n",
      " 0.028336   0.02833603 0.02833591 0.02833603 0.02833599 0.02833583\n",
      " 0.02833608 0.02833591 0.02833584 0.0283359  0.02833574 0.02833566\n",
      " 0.02712629]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864012993637\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064759\n",
      "coeffs:  [0.0275769  0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064769\n",
      "coeffs:  [0.02757689 0.0275768  0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064787\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.02757681 0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064794\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757682 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064813\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757679 0.0275768  0.02757673 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.864013064818\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757675 0.0275767\n",
      " 0.02706872]\n",
      "\n",
      "find better score:\n",
      "score:  5187.8640130648255\n",
      "coeffs:  [0.02757689 0.02757679 0.02757686 0.02757694 0.0275768  0.02757686\n",
      " 0.02757646 0.02757681 0.02757683 0.02757684 0.02757787 0.0275769\n",
      " 0.02757691 0.02757686 0.02757686 0.02757686 0.02757685 0.02757684\n",
      " 0.02757686 0.02757686 0.02757682 0.0275768  0.02757683 0.02757683\n",
      " 0.02757685 0.02757686 0.02757681 0.02757686 0.02757684 0.02757677\n",
      " 0.02757688 0.02757681 0.02757678 0.0275768  0.02757673 0.02757672\n",
      " 0.02706872]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5921.8758365628855\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.875836573617\n",
      "coeffs:  [0.02768828 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.8758365736385\n",
      "coeffs:  [0.02768826 0.02768815 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.875836573644\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768817 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.875836573649\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768818 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.875836573672\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768814 0.02768816 0.02768808 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.8758365736785\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768809 0.02768804\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5921.875836573686\n",
      "coeffs:  [0.02768826 0.02768814 0.02768823 0.02768833 0.02768815 0.02768823\n",
      " 0.02768774 0.02768817 0.02768819 0.0276882  0.02768944 0.02768828\n",
      " 0.02768829 0.02768822 0.02768822 0.02768823 0.02768821 0.0276882\n",
      " 0.02768822 0.02768823 0.02768818 0.02768816 0.02768819 0.02768819\n",
      " 0.02768821 0.02768823 0.02768817 0.02768823 0.0276882  0.02768812\n",
      " 0.02768825 0.02768817 0.02768813 0.02768816 0.02768808 0.02768805\n",
      " 0.02707716]\n",
      "\n",
      "find better score:\n",
      "score:  5962.875778696105\n",
      "coeffs:  [0.02771712 0.02771699 0.02771709 0.02771719 0.02771701 0.02771709\n",
      " 0.02771658 0.02771702 0.02771705 0.02771706 0.02771835 0.02771714\n",
      " 0.02771715 0.02771708 0.02771708 0.02771709 0.02771707 0.02771706\n",
      " 0.02771708 0.02771709 0.02771703 0.02771702 0.02771705 0.02771705\n",
      " 0.02771707 0.02771709 0.02771702 0.02771709 0.02771706 0.02771698\n",
      " 0.02771711 0.02771702 0.02771698 0.02771702 0.02771693 0.02771689\n",
      " 0.02707935]\n",
      "\n",
      "find better score:\n",
      "score:  5965.875755166247\n",
      "coeffs:  [ 0.0237458   0.03477335  0.02462457  0.0238746   0.02718017  0.02446831\n",
      "  0.0334415   0.03854007  0.02428537  0.02439809 -0.00688934  0.03339813\n",
      "  0.03474176  0.024337    0.02443567  0.02493337  0.02528352  0.02566182\n",
      "  0.02563566  0.02516811  0.02596415  0.02581452  0.03025437  0.03006575\n",
      "  0.02581082  0.02586133  0.0269723   0.02543776  0.0252917   0.03127789\n",
      "  0.03053207  0.03175058  0.03766474  0.03186494  0.03969585  0.03993245\n",
      "  0.00046557]\n",
      "\n",
      "find better score:\n",
      "score:  5989.8765784435245\n",
      "coeffs:  [ 0.01441885  0.03790465  0.01663363  0.02134069  0.02373605  0.01652496\n",
      "  0.02301528  0.05193514  0.01552483  0.01635019 -0.04068431  0.03479625\n",
      "  0.04249018  0.0164424   0.01700455  0.01882662  0.01955193  0.02062189\n",
      "  0.02167956  0.01955826  0.01986709  0.019066    0.03572205  0.03521305\n",
      "  0.0213588   0.0234039   0.02777546  0.02016651  0.01954672  0.03871348\n",
      "  0.04068515  0.04276962  0.06419084  0.04285001  0.07024458  0.07107675\n",
      " -0.00242276]\n",
      "\n",
      "find better score:\n",
      "score:  6005.877606120528\n",
      "coeffs:  [-0.00734488 -0.01507929 -0.00324948  0.01396039  0.06921918 -0.00058108\n",
      "  0.07334838  0.05760992 -0.00387617 -0.01301446 -0.02829699 -0.00699761\n",
      "  0.02834742 -0.01178682 -0.01046353 -0.00395273 -0.00321112  0.00155706\n",
      " -0.00459891 -0.01432703  0.04358493  0.04109198  0.03288328  0.040954\n",
      " -0.00842281  0.00638631  0.04594341 -0.01259658 -0.00832137  0.04758066\n",
      "  0.04843369  0.05881959  0.14245244  0.05877476  0.17067671  0.17964588\n",
      " -0.06991512]\n",
      "\n",
      "find better score:\n",
      "score:  6007.877691541409\n",
      "coeffs:  [-0.00937106 -0.00105966 -0.00334197  0.01298935  0.07346562 -0.00081263\n",
      "  0.07418928  0.07592381 -0.00515604 -0.02002644 -0.01781954  0.00206778\n",
      "  0.04312637 -0.01829095 -0.0173186  -0.0102325  -0.00929669 -0.00491114\n",
      " -0.01812262 -0.02953603  0.03943179  0.03550167  0.02821417  0.03720343\n",
      " -0.02359931 -0.00290918  0.05749064 -0.02649466 -0.01665586  0.0450926\n",
      "  0.04907406  0.05047617  0.15707104  0.05073801  0.19634506  0.21165944\n",
      " -0.06997262]\n",
      "\n",
      "find better score:\n",
      "score:  6013.877872498907\n",
      "coeffs:  [-0.00475638  0.0018077   0.00384027  0.01149249  0.07629064  0.00619405\n",
      "  0.05023149  0.0794847   0.00029127 -0.02143134 -0.02463347 -0.00067744\n",
      "  0.0432938  -0.01917995 -0.01872897 -0.01135247 -0.00992657 -0.00704012\n",
      " -0.03014365 -0.04299309  0.03260111  0.02670597  0.0277535   0.03596971\n",
      " -0.03736495 -0.00979346  0.07809973 -0.03781933 -0.02073094  0.04629327\n",
      "  0.05222316  0.03976268  0.17205439  0.04062966  0.22569135  0.2509658\n",
      " -0.07003461]\n",
      "\n",
      "find better score:\n",
      "score:  6022.878209186213\n",
      "coeffs:  [ 0.00960744  0.00492439  0.02422051  0.00380108  0.07077211  0.02511765\n",
      "  0.06898573  0.07285813  0.01404223 -0.01800576 -0.06344903 -0.00441927\n",
      "  0.03726609 -0.01438567 -0.0148268  -0.0070547  -0.00367408 -0.00521152\n",
      " -0.05214341 -0.06550001  0.0098089  -0.00132145  0.03278122  0.04187868\n",
      " -0.06200083 -0.02132235  0.11978249 -0.05491998 -0.02305488  0.05122365\n",
      "  0.05578578  0.00474219  0.18155784  0.00687399  0.26573188  0.31340075\n",
      " -0.05437805]\n",
      "\n",
      "find better score:\n",
      "score:  6029.878651315357\n",
      "coeffs:  [-0.00672537  0.04143337  0.04665554 -0.02160168  0.11262819  0.02821646\n",
      "  0.01802086  0.07965188 -0.01117305 -0.00498368 -0.09350371 -0.0056913\n",
      "  0.0519602   0.00533847  0.01093266  0.01920767  0.03740825  0.01324528\n",
      " -0.09165413 -0.09250825  0.00056012 -0.02659883  0.05975268  0.09381617\n",
      " -0.11188707 -0.0259399   0.20550774 -0.0637801  -0.00266294  0.07246896\n",
      "  0.07970309 -0.13064101  0.11426304 -0.12174603  0.29346166  0.43635007\n",
      " -0.13548523]\n",
      "\n",
      "find better score:\n",
      "score:  6030.878688545659\n",
      "coeffs:  [-0.01445073  0.03781693  0.04400447 -0.0218689   0.11687388  0.02329132\n",
      "  0.0166325   0.08200772 -0.01900735 -0.0060664  -0.09878748 -0.00710884\n",
      "  0.0523195   0.00476189  0.01160184  0.02024786  0.04065356  0.01381159\n",
      " -0.0951776  -0.09509127 -0.00081351 -0.02935543  0.06235551  0.09985329\n",
      " -0.11690188 -0.02516264  0.21358689 -0.06437558 -0.00105461  0.07659204\n",
      "  0.0799283  -0.13671104  0.11171377 -0.12703112  0.30174508  0.45773607\n",
      " -0.12283091]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6032.878593159788\n",
      "coeffs:  [-0.02277119  0.029507    0.04427154 -0.01285329  0.10126435  0.02017544\n",
      "  0.02143604  0.07360453 -0.02480761 -0.00944561 -0.08817088  0.00095247\n",
      "  0.0448999   0.00163046  0.01268057  0.02133307  0.04801808  0.01219837\n",
      " -0.09942061 -0.09847021 -0.02243784 -0.05281199  0.05497072  0.10074328\n",
      " -0.12520418 -0.0217677   0.2260912  -0.06222849  0.00326915  0.07408066\n",
      "  0.07763793 -0.1268708   0.10594463 -0.11468579  0.31644191  0.49893641\n",
      " -0.11625347]\n",
      "\n",
      "find better score:\n",
      "score:  6043.878669613554\n",
      "coeffs:  [-0.02481838  0.02341519  0.05345714  0.00372843  0.11882754  0.0250469\n",
      "  0.02643662  0.05856711 -0.02316829 -0.02045843 -0.10043108  0.02476975\n",
      "  0.03195325 -0.00901263  0.00930856  0.01848037  0.05687567  0.00527976\n",
      " -0.11241325 -0.11010929 -0.01613941 -0.04912807  0.03497402  0.08884512\n",
      " -0.14593355 -0.02315558  0.23018148 -0.06406293  0.00248318  0.06202331\n",
      "  0.07544532 -0.10537559  0.08133387 -0.08851004  0.32643347  0.54075097\n",
      " -0.08504484]\n",
      "\n",
      "find better score:\n",
      "score:  6044.8786733751795\n",
      "coeffs:  [-0.05116561  0.00593752  0.05719396 -0.00164596  0.15583805  0.03630498\n",
      "  0.02912051  0.07292468 -0.03728879 -0.06067748 -0.10703565  0.00215755\n",
      "  0.04265496 -0.05727153  0.02648423  0.03481912  0.18471885 -0.00674467\n",
      " -0.18730904 -0.15519141 -0.01212317 -0.088449    0.0365824   0.08781926\n",
      " -0.27763359  0.03236318  0.26021945 -0.0222399   0.00771409  0.09608628\n",
      "  0.08276383 -0.05722151 -0.15264594  0.00662134  0.39251241  0.62779283\n",
      " -0.0582413 ]\n",
      "\n",
      "find better score:\n",
      "score:  6045.878633220588\n",
      "coeffs:  [-0.06897239  0.01754415  0.06394628 -0.00337576  0.14967041  0.02702393\n",
      "  0.0298829   0.06644094 -0.0333764  -0.13013087 -0.10761373 -0.00249356\n",
      "  0.03882478 -0.1891896   0.09783116  0.04139772  0.42462382 -0.11647932\n",
      " -0.29864518 -0.16963027  0.0372413  -0.13747489  0.04564308  0.09824309\n",
      " -0.45917368  0.20635832  0.26110543  0.14449161 -0.01556761  0.07133406\n",
      "  0.07913386 -0.13516425 -0.23567525  0.11479022  0.46849646  0.6228662\n",
      " -0.05744194]\n",
      "\n",
      "find better score:\n",
      "score:  6045.878638241998\n",
      "coeffs:  [-0.06642886  0.01746509  0.0639164  -0.00295412  0.14933593  0.02460031\n",
      "  0.02950678  0.06690181 -0.03304911 -0.12982079 -0.10800244 -0.00242899\n",
      "  0.03996815 -0.19435467  0.10488655  0.03803322  0.42592359 -0.11950069\n",
      " -0.30406673 -0.17413792  0.03871152 -0.13780888  0.04255716  0.10052182\n",
      " -0.45447497  0.21023615  0.25964762  0.14948925 -0.01344295  0.07392672\n",
      "  0.07786994 -0.14411788 -0.2246555   0.12174235  0.45763237  0.62032253\n",
      " -0.05776964]\n",
      "\n",
      "find better score:\n",
      "score:  6048.878645518197\n",
      "coeffs:  [-0.06217154  0.01740486  0.06292191 -0.00183362  0.14862534  0.02040762\n",
      "  0.02836149  0.06811455 -0.0322408  -0.12909785 -0.10854952 -0.00259116\n",
      "  0.04195767 -0.20315196  0.11659729  0.03161927  0.42612639 -0.12313026\n",
      " -0.31171447 -0.1819875   0.04101242 -0.1375252   0.03742019  0.10447794\n",
      " -0.4428958   0.2179555   0.25554435  0.15772695 -0.00889587  0.07919413\n",
      "  0.07544265 -0.1621647  -0.20670538  0.13108477  0.43970306  0.61692404\n",
      " -0.0579831 ]\n",
      "\n",
      "find better score:\n",
      "score:  6048.878646764444\n",
      "coeffs:  [-0.06265422  0.01743533  0.06167293 -0.00219248  0.14860964  0.02155392\n",
      "  0.02828722  0.06854074 -0.03177375 -0.12909351 -0.10827618 -0.00249907\n",
      "  0.04107227 -0.20275083  0.11545939  0.03080071  0.42310314 -0.11905909\n",
      " -0.31124985 -0.18462548  0.03994992 -0.13668086  0.03649302  0.10509635\n",
      " -0.43940072  0.21787702  0.25411257  0.15541016 -0.00633388  0.08002963\n",
      "  0.07453535 -0.16085232 -0.21484197  0.13170241  0.44436567  0.6201431\n",
      " -0.05797835]\n",
      "\n",
      "find better score:\n",
      "score:  6048.878646938946\n",
      "coeffs:  [-0.06357108  0.01770955  0.05899222 -0.0026077   0.14773594  0.02239205\n",
      "  0.02813649  0.06926576 -0.02952671 -0.12896305 -0.10770025 -0.00251146\n",
      "  0.04025812 -0.20411186  0.11598567  0.02746599  0.41695796 -0.11221951\n",
      " -0.31083266 -0.19111716  0.03841652 -0.13423704  0.03576827  0.1039736\n",
      " -0.42872138  0.22209921  0.25079039  0.15272855 -0.00166741  0.08186903\n",
      "  0.07331816 -0.16455751 -0.22598     0.13329434  0.45200738  0.62312777\n",
      " -0.0580035 ]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:5: RuntimeWarning: overflow encountered in expm1\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-4.52152323e-03  5.56103191e-02  3.20549709e-02 -2.22639125e-02\n",
      " -4.99122548e-02  1.28073710e-02 -2.22958707e-03  3.80858999e-02\n",
      "  3.43723895e-02  4.63502444e-02 -9.37565795e-03  4.49006545e-02\n",
      " -3.84241488e-05  1.66862596e-02  3.34355187e-02  1.48045975e-02\n",
      "  4.94707194e-02  2.40915488e-02 -1.85167712e-03  2.66944106e-02\n",
      " -1.08517871e-02  6.58085815e-03  4.55037708e-02  4.42926560e-02\n",
      "  1.35931991e-02  3.82700369e-02  1.34676001e-02  4.56270965e-02\n",
      "  7.76483558e-02  3.59042662e-02  3.33388515e-02  2.64755613e-02\n",
      "  3.75101649e-02  4.99731949e-02  1.30677342e-02  3.21550092e-02\n",
      "  4.04994866e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6049.878642911193\n",
      "coeffs:  [-0.0662279   0.01728208  0.05598231 -0.00381111  0.14698154  0.02335327\n",
      "  0.02828085  0.06887918 -0.0264824  -0.12899839 -0.10743578 -0.00252525\n",
      "  0.04062566 -0.21360138  0.12528819  0.02178604  0.4132497  -0.10334989\n",
      " -0.31968853 -0.20731687  0.03800755 -0.13244829  0.03527936  0.10161471\n",
      " -0.41255174  0.23621531  0.24931676  0.15372999  0.00090934  0.08237545\n",
      "  0.07381691 -0.18065202 -0.23235677  0.14527066  0.45944308  0.62370872\n",
      " -0.05774944]\n",
      "\n",
      "Optimizing with init x0: [ 0.02771751  0.02799867  0.03534158  0.01621177  0.03888188  0.06264292\n",
      "  0.05121593  0.01319516  0.00790523  0.03385288  0.02617405  0.03099743\n",
      "  0.01397298  0.0657081   0.05324447 -0.0049226   0.02754532  0.05784771\n",
      "  0.04052084  0.04075627  0.02110424 -0.00452859  0.00338649  0.04701352\n",
      "  0.04993973  0.00340114  0.02515287  0.00216358  0.01833466  0.06265832\n",
      "  0.04335434  0.00570269  0.06365586  0.01408893  0.02186951  0.08686455\n",
      "  0.02789186]\n",
      "\n",
      "Optimizing with init x0: [ 0.02273647  0.04549401 -0.00036987  0.0228196   0.02851507  0.05096764\n",
      "  0.00066023  0.0285235   0.04859261  0.00526207  0.00362135  0.02155547\n",
      " -0.00770761  0.01750189  0.0659852  -0.0452333   0.00806553  0.08801061\n",
      "  0.00804339  0.03017062  0.02495686  0.05007964  0.02300859  0.0369266\n",
      "  0.02867105  0.02440115 -0.02206146 -0.03657525  0.044084   -0.01098111\n",
      "  0.01466162  0.05176518  0.05783176  0.03309942  0.03450828  0.07019442\n",
      "  0.03229879]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "for metric in ['smooth']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smooth': 6049.878642911193}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'smooth': array([-0.0662279 ,  0.01728208,  0.05598231, -0.00381111,  0.14698154,\n",
       "         0.02335327,  0.02828085,  0.06887918, -0.0264824 , -0.12899839,\n",
       "        -0.10743578, -0.00252525,  0.04062566, -0.21360138,  0.12528819,\n",
       "         0.02178604,  0.4132497 , -0.10334989, -0.31968853, -0.20731687,\n",
       "         0.03800755, -0.13244829,  0.03527936,  0.10161471, -0.41255174,\n",
       "         0.23621531,  0.24931676,  0.15372999,  0.00090934,  0.08237545,\n",
       "         0.07381691, -0.18065202, -0.23235677,  0.14527066,  0.45944308,\n",
       "         0.62370872, -0.05774944])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['smooth'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prices = np.sort(df_train['total_price'].unique())\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return array[(np.fabs(array - value)).argmin()]\n",
    "\n",
    "def correct_prices(sq):\n",
    "    return [find_nearest(unique_prices, x) for x in sq]\n",
    "\n",
    "test_pred_final['total_price'] = correct_prices(test_pred_final['total_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHtJJREFUeJzt3X10VfWd7/H3V4gGDAYFzRWxE1w4Dg60IPGp9vaGUUesomPlVnmwgyNi7ZXamdYpvZVq770dnevoVevTZaK1VGNUWntBaMV0iNguHxBUwMYHZKgGp9DiIiUssQS/94+9k5yEPJydnJ29s/N5rZXFPjv77PM5WeF889u/3/79zN0RERHJ1yFJBxARkYFFhUNERCJR4RARkUhUOEREJBIVDhERiUSFQ0REIlHhEBGRSFQ4REQkEhUOERGJZGjSAeIwevRoLy8vB2Dv3r0cfvjhyQbqRFpzQXqzpTUXpDdbWnNBerOlNRfEn239+vV/cPejezzQ3TP3NXXqVG+xZs0aT6O05nJPb7a05nJPb7a05nJPb7a05nKPPxvwiufxGatLVSIiEokKh4iIRKLCISIikWSyc1xEJKr9+/fT0NBAaWkp9fX1ScfpVKGyFRcXM3bsWIqKinr1fBUOERGgoaGBESNGMGrUKI444oik43Rqz549jBgxok/ncHd27dpFQ0MD48aN69U5dKlKRATYt28fo0aNwsySjhIrM2PUqFHs27ev1+dIfYvDzA4H7gP+BNS5+6MJRxKRjMp60WjR1/eZSIvDzB4ys51mtrnD/ulm9paZbTGzReHuLwLL3P1q4KJ+DysiIu0k1eJ4GLgHWNqyw8yGAPcC5wINwDozWw6MBTaFhx3o35gZVn1Z2/bsx5PLIZJS5YtWFvR82269oNvv7969m+rqar761a9GOu8XvvAFqqurGTlyZF/iRZJI4XD3tWZW3mH3acAWd98KYGY1wMUERWQs8Brqk+mT3P8I2z6dYBAROcju3bu57777Dioczc3NDB3a9Uf1qlWr4o52EAvuMu9/YeF42t0nho9nAtPdfX74+ArgdOBbBK2TfcCvuurjMLMFwAKAsrKyqTU1NQA0NTVRUlIS63vpjSRybdre2Lo9adiutm8cdUK74/Qziy6t2dKaC9KXrbS0lPHjx3PgwAGGDBnCpO+vLej5N33n891+f968eaxatYoTTzyRoUOHUlxczMiRI3n77bd59dVXmTVrFg0NDXz88cdce+21XHnllQBMnDiR5557jqamJi699FLOPPNMXnrpJY499lhqamoYNmxYp6+3ZcsWGhsb2+2bNm3aenev6Om9pL5z3N33AlfmcdwSYAlARUWFV1ZWAlBXV0fLdpokkWteuxbHM23fqGx/qUo/s+jSmi2tuSB92err6xkxYkRBhrx2pqdz3n777bz11lts3LiRuro6LrjgAjZv3tw6ZHbp0qUUFRUxdOhQTj31VObMmdM6CqylAL/77rs8/vjjTJ48mS996UusXr2auXPndvp6xcXFTJkypVfvJU2XfrYDx+c8Hhvuy5uZzTCzJR2rqIjIQHPaaae1u8/i7rvv5rOf/SxnnHEG77//Pu+8885Bzxk3bhyTJ08GYOrUqWzbti2WbGkqHOuAE81snJkdClwOLI9yAndf4e4LSktLYwkoItJfcqdPr6uro7a2ltraWl5//XWmTJnS6X0Yhx12WOv2kCFDaG5ujiVbUsNxHwNeAE4yswYzu8rdm4HrgGeAeuAJd38jiXyDWfmilWza3ljwESUi0r2Wy2SdaWxs5Mgjj2T48OG8+eabvPjii/2crr2kRlXN6mL/KqDXQwTMbAYwY/z48b09hYgI0PPw2UIbNWoUZ511FhMnTmTYsGGUlZW1fm/69Ok88MADVFRUMGHCBM4444x+zdZR6jvHo3D3FcCKioqKq5POkgm610OkX1VXV3e6/7DDDuPnP/95px33Lf0Yo0ePZvPmtnuqv/nNb8aWM019HCIiMgBkqnBoVJWISPx0qWoQqSq6rXW7NmdK/3PyeG67u877+dqviKRLpgqHHCz3A7+qizVbahdX5jy6odNjcosO1UvbtnP6PlRcRAYHFY6Ma/eBXyC19Ttat/NprYhItqiPQ0REIslUi0N9HKHcYbQRVRXdxkc2m6qiaqCsx+Mj59GwXhko+vD/qFM9/O73dlp1gDvvvJMFCxYwfPjw3qaLJFOFYzBLasr0fPpHRKRnXU2rno8777yTuXPnqnBIdqhPRKRnixYt4t1332Xy5Mmce+65HHPMMTzxxBN8/PHHXHLJJXzve99j7969XH755TQ0NHDgwAEWL17Mjh07+OCDD5g2bRqjR49mzZo1sWfNVOHQlCOFlfuBn4/2HfEaVSUSxa233srmzZt57bXXWL16NcuWLePll1/G3bnoootYu3Yt7733HmPGjGHlyuAKQ2NjI6Wlpdxxxx2sWbOG0aNH90vWTHWOa3ZcEcmC1atXs3r1aqZMmcIpp5zCm2++yTvvvMPJJ5/Ms88+y7e+9S2ef/55kvqsy1SLQ9Kjfd+HiETh7nz729/mmmuuabd/z549bNiwgVWrVnHjjTdy9tln893vfrff86lwDGDqmBbJjtxp1c877zwWL17MnDlzKCkpYfv27RQVFbF7924+9alPMXfuXEaOHElVVVW75/bXpSoVDulfGporA0U//37mTqt+/vnnM3v2bM4880wASkpKeOSRR3jjjTeYOXMmhxxyCEVFRdx///0ALFiwgOnTpzNmzBh1jkelzvH00wgrka51nFb9+uuvb/f4mGOO4ZJLLjnoeQsXLmThwoWxZsulznEREYkkUy0OGWB02UpkQFLhkHRQEZEUcPekI/SLvr5PFQ5JTLv+jgkFmhdLpJeKi4vZtWsXhx56aNJRYuXu7Nq1i+Li4l6fQ4VDUkGd5pK0sWPH0tDQwO7du/v0oRqnffv2FSRbcXExY8eO7fXzVTgyKOpUISICRUVFjBs3jrq6OqZMmZJ0nE6lJVumRlVpPQ4RkfhlqsUxKNbj6GKNgDhW+hMR6UymWhwiIhI/FQ4REYlEhUNERCJR4RARkUhUOEREJBIVDhERiSRTw3GzqnzRytbtbZ9OMEgScocfj7k2uRwi0ipThUPrcWRP7l3w9d5IZXJRRCSUqcIxKG4AHAS6W6+8Xevr1gv6IY2IdKQ+DhERiSRTLY4BTetRiMgAocIhA0a57aCqKGdN5uqlwb8qtCL9SpeqREQkErU4BhittSEiSVOLQ0REIlHhEBGRSFQ4UqK2fkfrV+69CiIiaaPCISIikahzPC4592WUb/xy67budo6H7igX6T+pLxxmdgLwHaDU3WcmnUfSo2WE2Xxd2hPpV7EWDjN7CLgQ2OnuE3P2TwfuAoYAVe5+a1fncPetwFVmtizOrKlVfRlVRRqCKyLpEXeL42HgHmBpyw4zGwLcC5wLNADrzGw5QRG5pcPz/87dd8acUTKkqug23VEuErNYC4e7rzWz8g67TwO2hC0JzKwGuNjdbyFonYhEUlV0W88HaS4wkYIxd4/3BYLC8XTLpSozmwlMd/f54eMrgNPd/bounj8K+D5BC6UqLDCdHbcAWABQVlY2taamBoCmpiZKSkoK+Zby8+HW1s1NH41q3Z50XClwcK49H7zdur3Ny1qP48Ot7NnXHHPY9j4pPopD9n3Yr6+Zj3xzjSju4e+ho04oUKI2if2e9SCtuSC92dKaC+LPNm3atPXuXtHTcanvHHf3XcBX8jhuCbAEoKKiwisrKwGoq6ujZbtfVd/fujlvU86oqjlBlo65ahff3Lo9Aai0srbv9fM0Ix9NmM2w+uqeD+xn+ebKLbPnTDj45zh//w0FH3mV2O9ZD9KaC9KbLa25ID3ZkriPYztwfM7jseE+EREZAJJocawDTjSzcQQF43JgdiFOrKVjpSNNCilSeLG2OMzsMeAF4CQzazCzq9y9GbgOeAaoB55w9zcK8XruvsLdF5SWlhbidCIi0om4R1XN6mL/KmBVoV9PLQ4RkfilvnM8CndfAayoqKi4OuksfaVLLCKSVprkUEREIlHhEBGRSDJ1qWog9HG0zOL6jUnNzMuZnK+qKKlEIiLRZKrFoVFVIiLxy1SLYyBomVfpI5sNHJdsGBGRXshU4UjrpaquJuHLa3I+iYUWfhLpPV2qEhGRSDLV4hDJx0EtPa3fIRJJplocIiISv0y1ONLUx6E7v0UkqzJVOLI05YgkQ53mIj3TpSoREYkkUy2OpJXrTnARGQRUOApI92VkR1XRbRptJdIFXaoSEZFIMlU4zGyGmS1pbGxMOooMILX1O6it39HuUmN3+0UGu0xdqtKoKukLXWoUyU+mWhwiIhI/FQ6RHgQd5ZcFXyKiwiEiItGocIiISCSZKhwaVSUiEj+Nquoj3S0uIoNNplocIiISPxUOERGJRIVDJA+6i1ykTab6OET6g9bskMFOLQ4REYkk7xaHmX0G+M/hw+fd/fV4IomISJrl1eIws+uBR4Fjwq9HzGxhnMFERCSd8m1xXAWc7u57Aczsn4EXgB/EFUwkjXJn0J2//4bW/o5vTGqmMqFMIv0t3z4OAw7kPD4Q7ksV3TkuIhK/fAvHD4GXzOxmM7sZeBF4MLZUveTuK9x9QWlpadJRREQyK69LVe5+h5nVAZ8Ld13p7q/GlmoA0eI/IjLYdFs4zOwId/+jmR0FbAu/Wr53lLt/GG88ERFJm55aHNXAhcB6wHP2W/j4hJhyiaRebmuznr9PMIlI/+q2cLj7heG/4/onjoiIpF2+93H8Mp99IiKSfT31cRQDw4HRZnYkbUNwjwCOizmbiIikUE99HNcAXwfGEPRztBSOPwL3xJhLRERSqqc+jruAu8xsobvrLnEREcn7Po4fmNlE4GSgOGf/0riCpVr1ZUknkDTL/f2Y/XhyOURiklfhMLObgEqCwrEKOB/4FTAoC0dt/Y6kI4iIJCbfSQ5nAp8BXnX3K82sDHgkvlhtzOxvgAsIOuQfdPfV/fG6IlGU2w61RGXQyHeuqn3u/gnQbGZHADuB43t6kpk9ZGY7zWxzh/3TzewtM9tiZou6O4e7/8zdrwa+Auh/pqRWy/KyapFK1vXY4jAzAzaa2UjgXwlGVzURTKvek4cJRl+1XtIysyHAvcC5QAOwzsyWA0OAWzo8/+/cfWe4fWP4PBERSVCPhcPd3cxOc/fdwANm9gvgCHffmMdz15pZeYfdpwFb3H0rgJnVABe7+y0E05u0ExauW4Gfu/uGnl5TJG20Rrlkjbl7zweZ/Qi4x93XRX6BoHA87e4Tw8czgenuPj98fAXBIlHXdfH8rwF/C6wDXnP3B7o4bgGwAKCsrGxqTU0NAE1NTZSUlESN3a09H7zd53N8UnwUh+xL5xyRac2W1lxwcLYRxeHfZEedwKbtbevDTDquf6f8j+P3v1DSmi2tuSD+bNOmTVvv7hU9HZdv5/jpwBwz+y2wl3CSQ3f/dB8y5sXd7wbuzuO4JcASgIqKCq+srASgrq6Olu1CqV18c5/P8dGE2Qyrr+57mBikNVtac8HB2SonlIUbjzMvt8Uxp7Jfc8Xx+18oac2W1lyQnmz5Fo7zCvia22nfsT423NdnZjYDmDF+/PhCnE4kPrrXQwawfG8A/G0BX3MdcKKZjSMoGJcDswtxYndfAayoqKi4uhDnE+mtlpFV83NaGyJZke9w3F4xs8cIRl+dZGYNZnaVuzcD1wHPAPXAE+7+Rpw5RESkcPK9VNUr7j6ri/2rCO5ALyhdqhIRiV+shaO/6VKVpM1Ba9JXD8pZeiRjMlU4RAYq3eshA0msfRz9zcxmmNmSxsbGng8WEZFeyVThcPcV7r6gtLR/b7ISERlMdKlKJMV6fQmr5T6R4vMIVkQQKZxMFQ6NqpK0y50595yWu8tFBhhdqhIRkUgyVThERCR+KhwiIhJJpvo4Ci5nIrryjV9u3a4qSiKMZFb1ZVQVtfV91C4Obhqcv/+GpBKllyaHTIVMtTh0H4eISPwyVTjUOS4iEr9MFQ4REYmfCoeIiESiznGRhOTeDCgykGSqxaHOcZH29uxrpnzRynZTl4j0VaZaHHGux3HQugoiMcv9nWs3NLerIam5+7vSl+GsGgoroUy1OEREJH4qHCIiEokKh4iIRKLCISIikWSqcGhUlYhI/DJVODTliIhI/DJVOEREJH6Zuo9DJMtabuKrKtqhZWclUSocIgNQ63QliyuB7tcvb72RsHppzKm6oZsHM0WXqkREJBIVDhERiUSFQ0REIlHhEBGRSNQ5LjJI5K7/oVFZ0heZanHoznERkfhlqsUR53ocIoNN7uJP2269IMEkkjaZanGIiEj8VDhERCSSTF2qEpH2neBMSC6HZJdaHCIiEokKh4iIRKLCISL9prZ+B+WLVrYbsSUDjwqHiIhEosIhIiKRaFSVyADQuqZGIeWukdHpa+5g/v4bop0n6lobhVqnI+p5srQ+SALvRYVDRHqtfNFKqoqC4b9R57/atL2R5jfzf25fXksKK/WXqsxsgpk9YGbLzOzapPOIiAx2sRYOM3vIzHaa2eYO+6eb2VtmtsXMFnV3Dnevd/evAF8Czoozr4iI9CzuFsfDwPTcHWY2BLgXOB84GZhlZieb2SQze7rD1zHhcy4CVgKrYs4rIiI9iLWPw93Xmll5h92nAVvcfSuAmdUAF7v7LcCFXZxnObDczFYC1fElFhkculqbo910JSJdMHeP9wWCwvG0u08MH88Eprv7/PDxFcDp7n5dF8+vBL4IHAZsdPd7uzhuAbAAoKysbGpNTQ0ATU1NlJSU9C78h1tbN/fsa+7dObrwSfFRHLLvw4Kes1DSmi2tuSD5bCOK2/4GzP1dzSdXV88F2OZBUZl0XGm7/w8cdQIQdHCX246284T7DxI+d8++5tZzlg2DYfvyeG6o29fqJFu3ujm+T58ZMes0W9T33o1p06atd/eKno5L/agqd68D6vI4bgmwBKCiosIrKysBqKuro2U7sur7WzcL/ZfYRxNmM6w+nY2ntGZLay5IPltlF62GfHJ19VyA28PhuNvmVLb7/0BlMOxz3qKVVBVVt52nsovhoOFza+t3tJ7zG5OamfBmHs8NdftanWTrVjfH9+kzI2adZov63gsgiVFV24Hjcx6PDff1mVYAFBGJXxKFYx1wopmNM7NDgcuB5YU4sbuvcPcFpaWlhTidiIh0ItZLVWb2GFAJjDazBuAmd3/QzK4DngGGAA+5+xtx5ugtdRTKQBH372ruzXcA81M6SWFt/Y522bTkbTziHlU1q4v9q4hhaK2ZzQBmjB8/vtCnFhGRUOrvHI9Cl6pEROKXqcIhIiLxy1Th0KgqEZH4Zapw6FKViEj8MlU4REQkfqm/c1xEBobcobC5w2A7DuWVgS9TLQ71cYiIxC9ThUN9HCIi8ctU4RARkfipcIiISCSZKhzq4xARiV+mCof6OERE4pepwiEiIvFT4RARkUh0A2AH5Tlz+VcVJRhEpJ/EsZZHeYHW68jnPL25wTD3PZ8TOVW6JPFeMtXiUOe4iEj8MlU41DkuIhK/TBUOERGJnwqHiIhEosIhIiKRqHCIiEgkKhwiIhJJpgqHhuOKiMQvU4VDw3FFROKXqcIhIiLxU+EQEZFIVDhERCQSFQ4REYlEhUNERCJR4RARkUi0HoeIpEo+a3DU1u9gfsQ1P/qy1k7uc7fdekG0J2dQplocugFQRCR+mSocugFQRCR+mSocIiISPxUOERGJRIVDREQiUeEQEZFIVDhERCQSFQ4REYlEhUNERCIxd086Q8GZ2e+B34YPRwN/SDBOV9KaC9KbLa25IL3Z0poL0pstrbkg/mx/5u5H93RQJgtHLjN7xd0rks7RUVpzQXqzpTUXpDdbWnNBerOlNRekJ5suVYmISCQqHCIiEslgKBxLkg7QhbTmgvRmS2suSG+2tOaC9GZLay5ISbbM93GIiEhhDYYWh4iIFFCmC4eZTTezt8xsi5ktSjoPgJk9ZGY7zWxz0lk6MrPjzWyNmf3GzN4ws+uTzgRgZsVm9rKZvR7m+l7SmXKZ2RAze9XMnk46Sy4z22Zmm8zsNTN7Jek8LcxspJktM7M3zazezM5MOhOAmZ0U/qxavv5oZl9POheAmf19+Lu/2cweM7PiRPNk9VKVmQ0B3gbOBRqAdcAsd/9Nwrk+DzQBS919YpJZOjKzY4Fj3X2DmY0A1gN/k4KfmQGHu3uTmRUBvwKud/cXk8zVwsz+AagAjnD3C5PO08LMtgEV7p6qexLM7EfA8+5eZWaHAsPdfXfSuXKFnx/bgdPd/bc9HR9zluMIfudPdvePzOwJYJW7P5xUpiy3OE4Dtrj7Vnf/E1ADXJxwJtx9LfBh0jk64+7/4e4bwu09QD1wXLKpwANN4cOi8CsVf/GY2VjgAqAq6SwDgZmVAp8HHgRw9z+lrWiEzgbeTbpo5BgKDDOzocBw4IMkw2S5cBwHvJ/zuIEUfAgOFGZWDkwBXko2SSC8HPQasBN41t1TkQu4E/hH4JOkg3TCgdVmtt7MFiQdJjQO+D3ww/DyXpWZHZ50qE5cDjyWdAgAd98O/AvwHvAfQKO7r04yU5YLh/SSmZUAPwG+7u5/TDoPgLsfcPfJwFjgNDNL/DKfmV0I7HT39Uln6cLn3P0U4Hzgv4WXSZM2FDgFuN/dpwB7gVT0P7YIL59dBDyZdBYAMzuS4GrJOGAMcLiZzU0yU5YLx3bg+JzHY8N90o2wD+EnwKPu/tOk83QUXtZYA0xPOgtwFnBR2JdQA/yVmT2SbKQ24V+quPtO4CmCy7dJawAaclqMywgKSZqcD2xw9x1JBwmdA/y7u//e3fcDPwU+m2SgLBeOdcCJZjYu/AvicmB5wplSLeyEfhCod/c7ks7TwsyONrOR4fYwggEPbyabCtz92+4+1t3LCX6//s3dE/1LsIWZHR4OcCC8FPTXQOIj+dz9d8D7ZnZSuOtsINHBF52YRUouU4XeA84ws+Hh/9GzCfofEzM0yRePk7s3m9l1wDPAEOAhd38j4ViY2WNAJTDazBqAm9z9wWRTtToLuALYFPYnAPx3d1+VYCaAY4EfhSNdDgGecPdUDX1NoTLgqeBzhqFAtbv/ItlIrRYCj4Z/0G0Frkw4T6uwyJ4LXJN0lhbu/pKZLQM2AM3AqyR8B3lmh+OKiEg8snypSkREYqDCISIikahwiIhIJCocIiISiQqHiIhEosIhIiKRqHBI6phZU89Hdfv8ZWZ2Qm/OZWYVZnZ3uD3PzO7pLqOZjQnH2Geamf2Fmb1gZh+b2Tdz9h9qZmvDyfdkkFDhkEwxs78Ehrj71t48391fcfevRTj+A3ef2ZvX6otCflCbWbmZ1fVw2IfA1wgm22sVzjz9S+CyQuWR9FPhkNSywG3h4jWbzOyycP8hZnZfuBDQs2a2ysxaPrznAP+vw3n+T7gIzi/N7OhwX52ZVYTbo8P5pjCzys4WZAqnrnkhzPG/cvaXW7goV9hC+amZ/cLM3jGz/51z3FVm9rYFC1L9a1ctmfDYGWb2Ujh7bK2ZlYX7bzazH5vZr4EfhzMG32Zm68xso5ldEx5XEr7XDWHePi8n4O473X0dsL+Tb/+M4Ocug4QKh6TZF4HJwGcIJnq7zYLFpr4IlAMnE0yRkruC3FkEC1C1OBx4xd3/EngOuKmXWe4imNF1EsHU1l2ZTPDX9yTgMgtWVRwDLAbOCPP9RQ+v9SvgjHD22BqCadtbnAyc4+6zgKsIptg+FTgVuNrMxgH7gEvCmXGnAbeHcxzFZXP4+jJI6LqkpNnngMfc/QCww8yeI/iA+hzwpLt/AvzOzNbkPOdYgvUeWnwCPB5uP0Iws2hvnAVcGm7/GPjnLo77pbs3ApjZb4A/A0YDz7n7h+H+J4E/7+a1xgKPh0XyUODfc7633N0/Crf/Gvh0TmurFDiRYAbafwqnUf+EYB2aMuB3uS9iZk8RTNV9KPCpnPnJ7nL3H3aTrx13P2BmfzKzEeECYJJxKhySNR8B3a3H3DI5WzNtLe5812/OZ2K3j3O2D9C7/2M/AO5w9+VmVgncnPO9vTnbBix092dyn2xm84Cjganuvj+8DHfQe3T3S8Ljy4GH3b2yF1lbHEbQ0pFBQJeqJM2eJ7jcMyTsm/g88DLwa+DSsK+jjGC24Rb1wPicx4cALX+Rzya4DASwDZgabufTuf1rgqnTIfr1/HXAfzGzI8NO7Ut7OL6UtrVj/rab454BrrVgDRXM7M/D2V1LCRaY2m9m0whaPbExs1HAH8K1ImQQUOGQNHsK2Ai8Dvwb8I/heg4/Ibgc8xuCy08bgMbwOStpX0j2EqwYuBn4K+B/hPv/heBD91WCS0k9uZ5gFb1NRFyCOFxQ6Z9oK3rbcvJ25mbgSTNbD/yhm+OqCH4GG8L3938JWjiPAhVh1i9TgLVLzOw/hcsA/ANwo5k1mNkR4benEfzcZZDQtOoyIJlZibs3hX/tvgyc5e6/s2ChpzXh4wPJpmyTk3coQUF8yN2fSjpXIZjZT4FF7v520lmkf6iPQwaqpy1YFfBQ4H+GLRHc/SMzu4mgVfBekgE7uNnMziHoa1hNMIR1wLNgMaafqWgMLmpxiCTEzL4D/NcOu5909+8nkUckXyocIiISiTrHRUQkEhUOERGJRIVDREQiUeEQEZFIVDhERCSS/w97rFZpkBZaiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean-log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0, 0, 0, 0, 0, 0, 0, 0, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666, 0.16666666666666666]\n"
     ]
    }
   ],
   "source": [
    "idxs = [12, 23, 32, 33, 34, 36]\n",
    "models = list(range(1,35)) + [36]\n",
    "print([1/len(idxs) if i in idxs else 0 for i in models])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "idxs = [36]\n",
    "models = list(range(1,35)) + [36]\n",
    "print([1/len(idxs) if i in idxs else 0 for i in models])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
