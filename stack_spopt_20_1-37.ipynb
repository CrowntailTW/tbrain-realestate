{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '20'\n",
    "models = '1-37'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = False\n",
    "add_intercept = True\n",
    "is_cv_on_opt = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n",
      "32 model-32-lgb-remove_outlier_01-cv.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-kfold.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-one.csv\n",
      "33 model-33-lgb-remove_outlier_03-cv.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-kfold.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-one.csv\n",
      "34 model-34-lgb-remove_outlier_01-cv.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-kfold.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-one.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-cv.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-test-kfold.csv\n",
      "35 model-35-lgb-remove_outlier_03-2-test-one.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-kfold.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "37 model-37-lgb-remove_outlier_05-cv.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-kfold.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "37\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n",
      "model-32-lgb-remove_outlier_01-cv.csv\n",
      "model-33-lgb-remove_outlier_03-cv.csv\n",
      "model-34-lgb-remove_outlier_01-cv.csv\n",
      "model-35-lgb-remove_outlier_03-2-cv.csv\n",
      "model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "model-37-lgb-remove_outlier_05-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n",
      "No. 31 file: model-32-lgb-remove_outlier_01-test-one.csv\n",
      "No. 32 file: model-33-lgb-remove_outlier_03-test-one.csv\n",
      "No. 33 file: model-34-lgb-remove_outlier_01-test-one.csv\n",
      "No. 34 file: model-35-lgb-remove_outlier_03-2-test-one.csv\n",
      "No. 35 file: model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "No. 36 file: model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_35</th>\n",
       "      <th>log_parea_pred_35</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.336691</td>\n",
       "      <td>12.107588</td>\n",
       "      <td>6.245441e+05</td>\n",
       "      <td>13.344779</td>\n",
       "      <td>12.115676</td>\n",
       "      <td>6.319899e+05</td>\n",
       "      <td>13.356630</td>\n",
       "      <td>12.127527</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.942103</td>\n",
       "      <td>13.545536</td>\n",
       "      <td>3.042045e+06</td>\n",
       "      <td>14.928041</td>\n",
       "      <td>13.531473</td>\n",
       "      <td>3.142342e+06</td>\n",
       "      <td>14.960479</td>\n",
       "      <td>13.563912</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.098990</td>\n",
       "      <td>14.379035</td>\n",
       "      <td>9.818275e+06</td>\n",
       "      <td>16.099756</td>\n",
       "      <td>14.379801</td>\n",
       "      <td>9.946933e+06</td>\n",
       "      <td>16.112775</td>\n",
       "      <td>14.392820</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.352854</td>\n",
       "      <td>13.745507</td>\n",
       "      <td>1.264691e+07</td>\n",
       "      <td>16.352924</td>\n",
       "      <td>13.745577</td>\n",
       "      <td>1.295773e+07</td>\n",
       "      <td>16.377203</td>\n",
       "      <td>13.769857</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.749632</td>\n",
       "      <td>12.204607</td>\n",
       "      <td>9.305770e+05</td>\n",
       "      <td>13.743561</td>\n",
       "      <td>12.198536</td>\n",
       "      <td>9.859947e+05</td>\n",
       "      <td>13.801407</td>\n",
       "      <td>12.256382</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 116 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "           ...            log_pred_35  log_parea_pred_35       pred_36  \\\n",
       "0          ...              13.336691          12.107588  6.245441e+05   \n",
       "1          ...              14.942103          13.545536  3.042045e+06   \n",
       "2          ...              16.098990          14.379035  9.818275e+06   \n",
       "3          ...              16.352854          13.745507  1.264691e+07   \n",
       "4          ...              13.749632          12.204607  9.305770e+05   \n",
       "\n",
       "   log_pred_36  log_parea_pred_36       pred_37  log_pred_37  \\\n",
       "0    13.344779          12.115676  6.319899e+05    13.356630   \n",
       "1    14.928041          13.531473  3.142342e+06    14.960479   \n",
       "2    16.099756          14.379801  9.946933e+06    16.112775   \n",
       "3    16.352924          13.745577  1.295773e+07    16.377203   \n",
       "4    13.743561          12.198536  9.859947e+05    13.801407   \n",
       "\n",
       "   log_parea_pred_37  log_total_price  log_parea_total_price  \n",
       "0          12.127527        13.381036              12.151933  \n",
       "1          13.563912        15.015913              13.619345  \n",
       "2          14.392820        16.074236              14.354282  \n",
       "3          13.769857        16.469809              13.862462  \n",
       "4          12.256382        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 116 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_35</th>\n",
       "      <th>log_pred_35</th>\n",
       "      <th>log_parea_pred_35</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.124128</td>\n",
       "      <td>1.313244e+07</td>\n",
       "      <td>16.390596</td>\n",
       "      <td>15.161489</td>\n",
       "      <td>1.298618e+07</td>\n",
       "      <td>16.379396</td>\n",
       "      <td>15.150290</td>\n",
       "      <td>1.304845e+07</td>\n",
       "      <td>16.384180</td>\n",
       "      <td>15.155073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.129532</td>\n",
       "      <td>3.896216e+06</td>\n",
       "      <td>15.175517</td>\n",
       "      <td>13.130898</td>\n",
       "      <td>3.897411e+06</td>\n",
       "      <td>15.175823</td>\n",
       "      <td>13.131204</td>\n",
       "      <td>3.897545e+06</td>\n",
       "      <td>15.175858</td>\n",
       "      <td>13.131239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.694473</td>\n",
       "      <td>1.078764e+07</td>\n",
       "      <td>16.193911</td>\n",
       "      <td>13.694891</td>\n",
       "      <td>1.049745e+07</td>\n",
       "      <td>16.166643</td>\n",
       "      <td>13.667623</td>\n",
       "      <td>1.035078e+07</td>\n",
       "      <td>16.152573</td>\n",
       "      <td>13.653552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.808651</td>\n",
       "      <td>6.102227e+06</td>\n",
       "      <td>15.624164</td>\n",
       "      <td>14.812232</td>\n",
       "      <td>6.139949e+06</td>\n",
       "      <td>15.630327</td>\n",
       "      <td>14.818395</td>\n",
       "      <td>6.120593e+06</td>\n",
       "      <td>15.627170</td>\n",
       "      <td>14.815237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.143297</td>\n",
       "      <td>1.104233e+06</td>\n",
       "      <td>13.914662</td>\n",
       "      <td>12.154401</td>\n",
       "      <td>1.106728e+06</td>\n",
       "      <td>13.916919</td>\n",
       "      <td>12.156657</td>\n",
       "      <td>1.098338e+06</td>\n",
       "      <td>13.909310</td>\n",
       "      <td>12.149048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3        ...          log_parea_pred_34       pred_35  \\\n",
       "0   16.544464        ...                  15.124128  1.313244e+07   \n",
       "1   15.196062        ...                  13.129532  3.896216e+06   \n",
       "2   16.199646        ...                  13.694473  1.078764e+07   \n",
       "3   15.609807        ...                  14.808651  6.102227e+06   \n",
       "4   13.842395        ...                  12.143297  1.104233e+06   \n",
       "\n",
       "   log_pred_35  log_parea_pred_35       pred_36  log_pred_36  \\\n",
       "0    16.390596          15.161489  1.298618e+07    16.379396   \n",
       "1    15.175517          13.130898  3.897411e+06    15.175823   \n",
       "2    16.193911          13.694891  1.049745e+07    16.166643   \n",
       "3    15.624164          14.812232  6.139949e+06    15.630327   \n",
       "4    13.914662          12.154401  1.106728e+06    13.916919   \n",
       "\n",
       "   log_parea_pred_36       pred_37  log_pred_37  log_parea_pred_37  \n",
       "0          15.150290  1.304845e+07    16.384180          15.155073  \n",
       "1          13.131204  3.897545e+06    15.175858          13.131239  \n",
       "2          13.667623  1.035078e+07    16.152573          13.653552  \n",
       "3          14.818395  6.120593e+06    15.627170          14.815237  \n",
       "4          12.156657  1.098338e+06    13.909310          12.149048  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n",
      "31 model-32 5930.875106\n",
      "32 model-33 5976.875715\n",
      "33 model-34 5942.875172\n",
      "34 model-35 5982.876110\n",
      "35 model-36 5989.876236\n",
      "36 model-37 5980.875836\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, cv, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv[cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "       (np.random.randn(len_x)+1)/len_x,\n",
    "      ]\n",
    "#bounds = tuple([(0, 1) for i in range(len_x-1)] + [(-2, 2)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV\n",
    "not run yet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "if is_cv_on_opt:\n",
    "    cv = cv.reset_index(drop=True)\n",
    "    #cv = cv.head(100)\n",
    "\n",
    "    score_list = []\n",
    "\n",
    "    kf = KFold(shuffle= True)\n",
    "    for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "        best_score = {}\n",
    "        best_coeffs = {}\n",
    "\n",
    "        cv_fold_train = cv.loc[idx_train].reset_index(drop=True)\n",
    "        cv_fold_val = cv.loc[idx_train].reset_index(drop=True)\n",
    "\n",
    "        for metric in ['mape']:\n",
    "        #for metric in ['mape', 'mae', 'mse']:\n",
    "            best_score[metric] = 0\n",
    "            best_coeffs[metric] = []\n",
    "            for x0 in x0s:\n",
    "                print('Optimizing with init x0: {}'.format(x0))\n",
    "                print()\n",
    "                minimize(objective, x0, args=(cv_fold_train, metric, best_score, best_coeffs, \n",
    "                                              True), \n",
    "                         tol=1e-4) #, bounds=bounds\n",
    "\n",
    "        val_pred_final = cv_fold_val[cols_opt].dot(best_coeffs['mape'])\n",
    "        if is_per_area:\n",
    "            val_pred_final = np.expm1(val_pred_final) * cv_fold_val['building_area']\n",
    "        else:\n",
    "            val_pred_final = np.expm1(val_pred_final)\n",
    "        score = cal_score(cv_fold_val['total_price'], val_pred_final)\n",
    "\n",
    "        score_list.append(score)\n",
    "\n",
    "    print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421, 0.02631578947368421]\n",
      "\n",
      "find better score:\n",
      "score:  367.6803498212385\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.68034996618684\n",
      "coeffs:  [0.0263158  0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.6803499661876\n",
      "coeffs:  [0.02631579 0.02631579 0.0263158  0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.68034996619\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.0263158  0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.68034996619593\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.0263158  0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.6803499661994\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.0263158  0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  367.680349966233\n",
      "coeffs:  [0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.0263158  0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579 0.02631579\n",
      " 0.02631579 0.02631579]\n",
      "\n",
      "find better score:\n",
      "score:  5495.858531845514\n",
      "coeffs:  [0.02707058 0.02707045 0.02707058 0.0270706  0.02707063 0.02707058\n",
      " 0.02707036 0.02707064 0.02707058 0.02707058 0.02707082 0.02707061\n",
      " 0.02707057 0.02707059 0.02707059 0.02707059 0.02707058 0.02707059\n",
      " 0.02707058 0.02707058 0.02707063 0.02707063 0.02707059 0.0270706\n",
      " 0.02707058 0.02707058 0.02707058 0.02707058 0.02707058 0.02707057\n",
      " 0.02707056 0.02707064 0.02707065 0.02707064 0.02707065 0.02707066\n",
      " 0.02707066 0.02636448]\n",
      "\n",
      "find better score:\n",
      "score:  5939.8761539707975\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975615\n",
      "coeffs:  [0.02677121 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975642\n",
      "coeffs:  [0.02677119 0.02687975 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975651\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701748 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.87615397567\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751048 0.02723986 0.02755181 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975673\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755183 0.02758619\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975676\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758621\n",
      " 0.02767884 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5939.876153975683\n",
      "coeffs:  [0.02677119 0.02687973 0.02685151 0.02679798 0.02716469 0.02680714\n",
      " 0.02680791 0.02701747 0.02679089 0.0268317  0.02536316 0.02688737\n",
      " 0.02682574 0.02684713 0.02684043 0.02685533 0.0268565  0.02687687\n",
      " 0.02686184 0.02686055 0.02715508 0.02716314 0.02703229 0.02714646\n",
      " 0.02689763 0.02682483 0.02689722 0.02687731 0.02688784 0.02704443\n",
      " 0.02697421 0.02723408 0.02751046 0.02723986 0.02755181 0.02758619\n",
      " 0.02767885 0.02640302]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446218\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5953.876378446652\n",
      "coeffs:  [0.02584294 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446677\n",
      "coeffs:  [0.02584292 0.02778858 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446685\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838633 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446705\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016948 0.02845962 0.03048129 0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446709\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.0304813  0.030698\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446712\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.03069801\n",
      " 0.03125305 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876378446718\n",
      "coeffs:  [0.02584292 0.02778857 0.02628356 0.02582221 0.02795874 0.02605319\n",
      " 0.02762282 0.02838631 0.02593487 0.02607665 0.01478988 0.02762921\n",
      " 0.02738965 0.02615534 0.02607324 0.02623052 0.02627067 0.02643245\n",
      " 0.02622192 0.02617039 0.02784124 0.02787584 0.02724794 0.0279388\n",
      " 0.02644679 0.02601384 0.0264233  0.02635487 0.02645499 0.02750807\n",
      " 0.02731165 0.0284114  0.03016947 0.02845962 0.03048129 0.030698\n",
      " 0.03125307 0.02061285]\n",
      "\n",
      "find better score:\n",
      "score:  5969.876782177848\n",
      "coeffs:  [ 0.02359939  0.02978435  0.02494444  0.02359217  0.029869    0.02425651\n",
      "  0.02935131  0.03152764  0.02387352  0.02424475 -0.00955534  0.02933163\n",
      "  0.02862449  0.02448354  0.02421677  0.02472584  0.02486306  0.02537198\n",
      "  0.02466835  0.02448316  0.0295341   0.02962589  0.02772054  0.02973184\n",
      "  0.02533438  0.02407139  0.02529771  0.02508268  0.02541688  0.02861416\n",
      "  0.02809085  0.03116851  0.03648643  0.03131311  0.03743961  0.03809014\n",
      "  0.03976673  0.00702936]\n",
      "\n",
      "find better score:\n",
      "score:  5986.877415550869\n",
      "coeffs:  [ 0.01852869  0.0338353   0.02193903  0.01904452  0.03425382  0.02019467\n",
      "  0.03240167  0.03837313  0.01923389  0.02003963 -0.0620494   0.03257986\n",
      "  0.03116548  0.02064119  0.01997539  0.02126648  0.02160339  0.02287841\n",
      "  0.02104675  0.02053085  0.03340944  0.03363679  0.02869346  0.03363534\n",
      "  0.02265847  0.01958882  0.02283528  0.02206616  0.02299341  0.03100716\n",
      "  0.02997986  0.03736042  0.05077895  0.03772999  0.05320521  0.05485768\n",
      "  0.05914511 -0.02243105]\n",
      "\n",
      "find better score:\n",
      "score:  6003.877874348466\n",
      "coeffs:  [ 0.0111084   0.03824941  0.01758595  0.01314284  0.04040578  0.01422962\n",
      "  0.03530463  0.0475137   0.01237324  0.01386783 -0.13081928  0.0359218\n",
      "  0.03398117  0.01501291  0.01373806  0.01616756  0.01677063  0.01915141\n",
      "  0.01568707  0.01462539  0.03873776  0.0391608   0.03006187  0.03903536\n",
      "  0.01858474  0.01306481  0.01963358  0.01751403  0.01942511  0.03449171\n",
      "  0.03257761  0.04621145  0.07146882  0.04695186  0.07600107  0.07911164\n",
      "  0.08741438 -0.06094568]\n",
      "\n",
      "find better score:\n",
      "score:  6008.878672295027\n",
      "coeffs:  [-0.02705901  0.01313179 -0.0011199   0.01861253  0.05920057 -0.01500258\n",
      "  0.01088792  0.06232541 -0.0226103  -0.02015427 -0.11827113  0.01559969\n",
      "  0.02445475 -0.0157642  -0.02040638 -0.01392786 -0.01259389 -0.00591465\n",
      " -0.01888453 -0.02521425  0.05283299  0.05458364  0.03236331  0.05266137\n",
      " -0.01368401 -0.02415441  0.02073929 -0.01498182 -0.0022343   0.04628478\n",
      "  0.04111407  0.07212303  0.15382658  0.07586674  0.16875671  0.17906828\n",
      "  0.22138832 -0.07111607]\n",
      "\n",
      "find better score:\n",
      "score:  6008.878688600378\n",
      "coeffs:  [-0.02675041  0.01556648 -0.00055497  0.0185962   0.05878114 -0.01460269\n",
      "  0.0141969   0.06404092 -0.02228116 -0.0200012  -0.11799082  0.01796581\n",
      "  0.02638574 -0.01556203 -0.02024512 -0.01382472 -0.01249522 -0.00589116\n",
      " -0.01928574 -0.02547766  0.05240394  0.05416543  0.03276992  0.0527938\n",
      " -0.01398388 -0.02464405  0.02080212 -0.01507507 -0.00213283  0.04633324\n",
      "  0.04142154  0.07041393  0.15129927  0.07421122  0.16635983  0.17675177\n",
      "  0.21933313 -0.06977953]\n",
      "\n",
      "find better score:\n",
      "score:  6013.878708392301\n",
      "coeffs:  [-2.75192211e-02  1.96730713e-02  8.44361552e-05  1.84179284e-02\n",
      "  5.87062021e-02 -1.47737678e-02  2.00832429e-02  6.81043002e-02\n",
      " -2.28761385e-02 -2.09311465e-02 -1.19388310e-01  2.20808194e-02\n",
      "  2.98630153e-02 -1.62348319e-02 -2.11710511e-02 -1.46960360e-02\n",
      " -1.33333583e-02 -6.70907223e-03 -2.15300015e-02 -2.76177198e-02\n",
      "  5.21065858e-02  5.39573700e-02  3.40031296e-02  5.39731828e-02\n",
      " -1.58509683e-02 -2.72499921e-02  2.10764264e-02 -1.64795762e-02\n",
      " -2.65265752e-03  4.71393774e-02  4.27050041e-02  6.78419812e-02\n",
      "  1.49279249e-01  7.18911264e-02  1.65099521e-01  1.75990632e-01\n",
      "  2.20639823e-01 -6.82613863e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6013.878717293393\n",
      "coeffs:  [-0.0288765   0.0203051   0.00027381  0.01874734  0.05921351 -0.01546012\n",
      "  0.02195153  0.07009334 -0.02401646 -0.02227996 -0.11784424  0.02312154\n",
      "  0.03076869 -0.01730668 -0.02251179 -0.01591056 -0.01450703 -0.00777201\n",
      " -0.02386755 -0.03002926  0.05233638  0.05429703  0.03502793  0.05524006\n",
      " -0.01787564 -0.02990302  0.02164602 -0.01815704 -0.00337462  0.04811069\n",
      "  0.04389571  0.06680917  0.15010214  0.07113026  0.16673086  0.1781608\n",
      "  0.22528708 -0.066416  ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.878925770807\n",
      "coeffs:  [-0.03552763  0.00917939  0.06736518  0.02054359  0.05493067  0.00976608\n",
      "  0.02889848  0.07746085 -0.02012167 -0.02075594 -0.12901498  0.0235058\n",
      "  0.00885118 -0.00170586 -0.01961456 -0.01132127 -0.00912544 -0.00506296\n",
      " -0.08977382 -0.09076824  0.03971038  0.04702605  0.08412093  0.13336498\n",
      " -0.06390574 -0.11505836  0.08437041 -0.04015477  0.01738153  0.08238969\n",
      "  0.08814415 -0.00767345  0.09783487  0.01043188  0.1494702   0.18467914\n",
      "  0.34362286 -0.06406659]\n",
      "\n",
      "find better score:\n",
      "score:  6015.878946962547\n",
      "coeffs:  [-0.03902979  0.01005466  0.08425276  0.01935633  0.05114412  0.01519703\n",
      "  0.02479793  0.08062879 -0.0205537  -0.02023844 -0.12379884  0.02449679\n",
      "  0.00606519  0.00271889 -0.01875122 -0.00977357 -0.00749789 -0.00431181\n",
      " -0.1073336  -0.10717228  0.03352603  0.0423614   0.08915931  0.15233491\n",
      " -0.07609881 -0.13796323  0.10184848 -0.04590738  0.02293805  0.0848151\n",
      "  0.09227127 -0.02355336  0.08822446 -0.00166338  0.14927692  0.19105832\n",
      "  0.38104833 -0.072051  ]\n",
      "\n",
      "find better score:\n",
      "score:  6015.878952554457\n",
      "coeffs:  [-0.04039358  0.0091377   0.08584587  0.01942806  0.05218989  0.01515232\n",
      "  0.02423995  0.08102235 -0.02147434 -0.02098567 -0.12254706  0.02381219\n",
      "  0.00534988  0.00253041 -0.01947236 -0.01031091 -0.00799924 -0.00481333\n",
      " -0.1103445  -0.11014481  0.03413526  0.04318991  0.08969476  0.15481262\n",
      " -0.07838455 -0.14170777  0.1039352  -0.04739046  0.02303988  0.08529063\n",
      "  0.09286368 -0.02501907  0.08857181 -0.00259533  0.1510318   0.19379664\n",
      "  0.38832177 -0.07058649]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6015.878952554461\n",
      "coeffs:  [-0.04039358  0.0091377   0.08584587  0.01942806  0.05218989  0.01515232\n",
      "  0.02423995  0.08102235 -0.02147434 -0.02098567 -0.12254706  0.02381219\n",
      "  0.00534988  0.00253041 -0.01947236 -0.01031091 -0.00799924 -0.00481333\n",
      " -0.1103445  -0.11014481  0.03413526  0.04318991  0.08969476  0.15481262\n",
      " -0.07838455 -0.14170777  0.1039352  -0.04739046  0.02303988  0.08529063\n",
      "  0.09286368 -0.02501907  0.08857181 -0.00259533  0.1510318   0.19379664\n",
      "  0.38832177 -0.07058647]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114768253\n",
      "coeffs:  [-1.51727406e-01  1.94160642e-02  1.66093882e-01  1.22431355e-02\n",
      "  7.09877611e-02  8.46464774e-03  2.01003120e-02  7.32611514e-02\n",
      " -1.06590939e-01  5.92225953e-03 -1.33408395e-01  1.13567786e-02\n",
      "  1.64050230e-02  8.58776118e-02  2.50341113e-04  4.77276579e-02\n",
      "  5.54993707e-02  3.65278933e-02 -2.15941947e-01 -2.02905411e-01\n",
      "  2.60089270e-02  6.39040899e-02  2.81545969e-02  1.97295458e-01\n",
      " -1.19111725e-01 -3.20043062e-01  2.24936324e-01 -1.22362992e-03\n",
      "  8.66735976e-02  9.14497954e-02  6.66702574e-02 -9.51934289e-03\n",
      " -1.04140818e-01  5.55732315e-02  7.90201702e-02  2.21716451e-01\n",
      "  5.95966221e-01 -5.64855257e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6015.8791147686725\n",
      "coeffs:  [-1.51727392e-01  1.94160642e-02  1.66093882e-01  1.22431355e-02\n",
      "  7.09877611e-02  8.46464774e-03  2.01003120e-02  7.32611514e-02\n",
      " -1.06590939e-01  5.92225953e-03 -1.33408395e-01  1.13567786e-02\n",
      "  1.64050230e-02  8.58776118e-02  2.50341113e-04  4.77276579e-02\n",
      "  5.54993707e-02  3.65278933e-02 -2.15941947e-01 -2.02905411e-01\n",
      "  2.60089270e-02  6.39040899e-02  2.81545969e-02  1.97295458e-01\n",
      " -1.19111725e-01 -3.20043062e-01  2.24936324e-01 -1.22362992e-03\n",
      "  8.66735976e-02  9.14497954e-02  6.66702574e-02 -9.51934289e-03\n",
      " -1.04140818e-01  5.55732315e-02  7.90201702e-02  2.21716451e-01\n",
      "  5.95966221e-01 -5.64855257e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114768673\n",
      "coeffs:  [-1.51727406e-01  1.94160791e-02  1.66093882e-01  1.22431355e-02\n",
      "  7.09877611e-02  8.46464774e-03  2.01003120e-02  7.32611514e-02\n",
      " -1.06590939e-01  5.92225953e-03 -1.33408395e-01  1.13567786e-02\n",
      "  1.64050230e-02  8.58776118e-02  2.50341113e-04  4.77276579e-02\n",
      "  5.54993707e-02  3.65278933e-02 -2.15941947e-01 -2.02905411e-01\n",
      "  2.60089270e-02  6.39040899e-02  2.81545969e-02  1.97295458e-01\n",
      " -1.19111725e-01 -3.20043062e-01  2.24936324e-01 -1.22362992e-03\n",
      "  8.66735976e-02  9.14497954e-02  6.66702574e-02 -9.51934289e-03\n",
      " -1.04140818e-01  5.55732315e-02  7.90201702e-02  2.21716451e-01\n",
      "  5.95966221e-01 -5.64855257e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6015.879114768675\n",
      "coeffs:  [-1.51727406e-01  1.94160642e-02  1.66093882e-01  1.22431355e-02\n",
      "  7.09877611e-02  8.46464774e-03  2.01003269e-02  7.32611514e-02\n",
      " -1.06590939e-01  5.92225953e-03 -1.33408395e-01  1.13567786e-02\n",
      "  1.64050230e-02  8.58776118e-02  2.50341113e-04  4.77276579e-02\n",
      "  5.54993707e-02  3.65278933e-02 -2.15941947e-01 -2.02905411e-01\n",
      "  2.60089270e-02  6.39040899e-02  2.81545969e-02  1.97295458e-01\n",
      " -1.19111725e-01 -3.20043062e-01  2.24936324e-01 -1.22362992e-03\n",
      "  8.66735976e-02  9.14497954e-02  6.66702574e-02 -9.51934289e-03\n",
      " -1.04140818e-01  5.55732315e-02  7.90201702e-02  2.21716451e-01\n",
      "  5.95966221e-01 -5.64855257e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.87911605752\n",
      "coeffs:  [-1.54224072e-01  2.01865787e-02  1.68183927e-01  1.36836008e-02\n",
      "  6.94971739e-02  8.76896985e-03  1.89217570e-02  7.42019582e-02\n",
      " -1.08733549e-01  5.91765165e-03 -1.34319390e-01  1.24552099e-02\n",
      "  1.49114456e-02  8.86320433e-02 -4.63225758e-04  4.96535668e-02\n",
      "  5.81107203e-02  3.77180588e-02 -2.18262794e-01 -2.04617719e-01\n",
      "  2.37030037e-02  6.32695346e-02  2.55908292e-02  1.95090114e-01\n",
      " -1.18564914e-01 -3.25370615e-01  2.23975676e-01  3.23728257e-03\n",
      "  8.68474450e-02  9.48428369e-02  6.58426303e-02 -6.05258768e-03\n",
      " -1.11226420e-01  6.08658208e-02  7.75390474e-02  2.25635856e-01\n",
      "  5.97263616e-01 -5.35918931e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116057713\n",
      "coeffs:  [-1.54224057e-01  2.01865787e-02  1.68183927e-01  1.36836008e-02\n",
      "  6.94971739e-02  8.76896985e-03  1.89217570e-02  7.42019582e-02\n",
      " -1.08733549e-01  5.91765165e-03 -1.34319390e-01  1.24552099e-02\n",
      "  1.49114456e-02  8.86320433e-02 -4.63225758e-04  4.96535668e-02\n",
      "  5.81107203e-02  3.77180588e-02 -2.18262794e-01 -2.04617719e-01\n",
      "  2.37030037e-02  6.32695346e-02  2.55908292e-02  1.95090114e-01\n",
      " -1.18564914e-01 -3.25370615e-01  2.23975676e-01  3.23728257e-03\n",
      "  8.68474450e-02  9.48428369e-02  6.58426303e-02 -6.05258768e-03\n",
      " -1.11226420e-01  6.08658208e-02  7.75390474e-02  2.25635856e-01\n",
      "  5.97263616e-01 -5.35918931e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116057714\n",
      "coeffs:  [-1.54224072e-01  2.01865936e-02  1.68183927e-01  1.36836008e-02\n",
      "  6.94971739e-02  8.76896985e-03  1.89217570e-02  7.42019582e-02\n",
      " -1.08733549e-01  5.91765165e-03 -1.34319390e-01  1.24552099e-02\n",
      "  1.49114456e-02  8.86320433e-02 -4.63225758e-04  4.96535668e-02\n",
      "  5.81107203e-02  3.77180588e-02 -2.18262794e-01 -2.04617719e-01\n",
      "  2.37030037e-02  6.32695346e-02  2.55908292e-02  1.95090114e-01\n",
      " -1.18564914e-01 -3.25370615e-01  2.23975676e-01  3.23728257e-03\n",
      "  8.68474450e-02  9.48428369e-02  6.58426303e-02 -6.05258768e-03\n",
      " -1.11226420e-01  6.08658208e-02  7.75390474e-02  2.25635856e-01\n",
      "  5.97263616e-01 -5.35918931e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116057717\n",
      "coeffs:  [-1.54224072e-01  2.01865787e-02  1.68183927e-01  1.36836008e-02\n",
      "  6.94971739e-02  8.76896985e-03  1.89217719e-02  7.42019582e-02\n",
      " -1.08733549e-01  5.91765165e-03 -1.34319390e-01  1.24552099e-02\n",
      "  1.49114456e-02  8.86320433e-02 -4.63225758e-04  4.96535668e-02\n",
      "  5.81107203e-02  3.77180588e-02 -2.18262794e-01 -2.04617719e-01\n",
      "  2.37030037e-02  6.32695346e-02  2.55908292e-02  1.95090114e-01\n",
      " -1.18564914e-01 -3.25370615e-01  2.23975676e-01  3.23728257e-03\n",
      "  8.68474450e-02  9.48428369e-02  6.58426303e-02 -6.05258768e-03\n",
      " -1.11226420e-01  6.08658208e-02  7.75390474e-02  2.25635856e-01\n",
      "  5.97263616e-01 -5.35918931e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116803209\n",
      "coeffs:  [-0.15688527  0.02085129  0.16877277  0.01585186  0.06842056  0.00837059\n",
      "  0.01915124  0.07503344 -0.11126046  0.00567659 -0.13557453  0.0135306\n",
      "  0.01358655  0.09088853 -0.00146414  0.05130427  0.06045299  0.03872562\n",
      " -0.21947565 -0.20534267  0.02188721  0.06304905  0.02317877  0.19144434\n",
      " -0.11728749 -0.32922784  0.22175955  0.00800719  0.08656946  0.09861573\n",
      "  0.06483908 -0.00135655 -0.11778053  0.0671371   0.07601158  0.22910008\n",
      "  0.59602441 -0.05153311]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116803212\n",
      "coeffs:  [-0.15688525  0.02085129  0.16877277  0.01585186  0.06842056  0.00837059\n",
      "  0.01915124  0.07503344 -0.11126046  0.00567659 -0.13557453  0.0135306\n",
      "  0.01358655  0.09088853 -0.00146414  0.05130427  0.06045299  0.03872562\n",
      " -0.21947565 -0.20534267  0.02188721  0.06304905  0.02317877  0.19144434\n",
      " -0.11728749 -0.32922784  0.22175955  0.00800719  0.08656946  0.09861573\n",
      "  0.06483908 -0.00135655 -0.11778053  0.0671371   0.07601158  0.22910008\n",
      "  0.59602441 -0.05153311]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879116803214\n",
      "coeffs:  [-0.15688527  0.02085129  0.16877277  0.01585186  0.06842056  0.00837059\n",
      "  0.01915125  0.07503344 -0.11126046  0.00567659 -0.13557453  0.0135306\n",
      "  0.01358655  0.09088853 -0.00146414  0.05130427  0.06045299  0.03872562\n",
      " -0.21947565 -0.20534267  0.02188721  0.06304905  0.02317877  0.19144434\n",
      " -0.11728749 -0.32922784  0.22175955  0.00800719  0.08656946  0.09861573\n",
      "  0.06483908 -0.00135655 -0.11778053  0.0671371   0.07601158  0.22910008\n",
      "  0.59602441 -0.05153311]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879117278118\n",
      "coeffs:  [-1.57326647e-01  2.05224709e-02  1.68568746e-01  1.57531772e-02\n",
      "  6.77357144e-02  8.16870198e-03  2.03382815e-02  7.50631882e-02\n",
      " -1.11720328e-01  5.48211312e-03 -1.36563746e-01  1.34821217e-02\n",
      "  1.35502123e-02  9.10887300e-02 -1.78500093e-03  5.14411379e-02\n",
      "  6.07162689e-02  3.87661286e-02 -2.19455792e-01 -2.05268052e-01\n",
      "  2.11748207e-02  6.25730573e-02  2.31099046e-02  1.90769373e-01\n",
      " -1.16918429e-01 -3.29591898e-01  2.21104901e-01  8.88313794e-03\n",
      "  8.64135111e-02  9.95804280e-02  6.57958701e-02 -3.44713045e-04\n",
      " -1.18455364e-01  6.83793368e-02  7.60815187e-02  2.29949249e-01\n",
      "  5.95559633e-01 -5.20809977e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879117910069\n",
      "coeffs:  [-1.56861975e-01  2.02460415e-02  1.67696082e-01  1.52201065e-02\n",
      "  6.73490434e-02  7.96294830e-03  2.16635445e-02  7.52802374e-02\n",
      " -1.11448165e-01  4.97513377e-03 -1.36874844e-01  1.35821174e-02\n",
      "  1.39886086e-02  9.03907437e-02 -2.31465126e-03  5.09008481e-02\n",
      "  6.02043219e-02  3.82919718e-02 -2.18760363e-01 -2.04651927e-01\n",
      "  2.09787870e-02  6.22904678e-02  2.34259828e-02  1.90079241e-01\n",
      " -1.16521490e-01 -3.28580077e-01  2.19798805e-01  8.92374372e-03\n",
      "  8.57634229e-02  9.99011978e-02  6.70233881e-02  2.88041165e-05\n",
      " -1.17160100e-01  6.85808046e-02  7.68945501e-02  2.30478952e-01\n",
      "  5.93980172e-01 -5.37014875e-02]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6017.87911846364\n",
      "coeffs:  [-0.15594097  0.01978381  0.16735542  0.01395941  0.06598044  0.00832443\n",
      "  0.02393625  0.07568114 -0.11078375  0.00411858 -0.13760693  0.01398214\n",
      "  0.01417109  0.09005386 -0.00342788  0.0505507   0.06015071  0.03778607\n",
      " -0.21819256 -0.20397334  0.01976911  0.06143488  0.02261751  0.18838874\n",
      " -0.11555723 -0.32837233  0.21694415  0.01046745  0.08457923  0.10082986\n",
      "  0.06894428  0.00119914 -0.11671135  0.0700363   0.07815092  0.23292905\n",
      "  0.59129819 -0.0557097 ]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.03206245  0.0199973  -0.04117752  0.03039895  0.00836026  0.03778314\n",
      "  0.01951033  0.05158747  0.01315085  0.03755608  0.01078335  0.0442163\n",
      "  0.0908866  -0.00145298  0.03832433  0.10124978  0.02843549  0.03076341\n",
      "  0.05701315 -0.01962636  0.03636216  0.03777586  0.05975149  0.05391777\n",
      " -0.01274151  0.02862113  0.08152808  0.02511458 -0.00476812 -0.01384127\n",
      "  0.02804793  0.04489583  0.01091868  0.03464894  0.06526206  0.01160644\n",
      "  0.03533179  0.0300767 ]\n",
      "\n",
      "Optimizing with init x0: [ 0.03764095  0.07582049  0.01209379  0.02797948  0.02081602  0.05844757\n",
      "  0.02312848  0.01438145  0.03199854  0.03816686  0.04026339  0.04553989\n",
      " -0.00605318  0.04588256  0.02897576  0.03646688 -0.02709023 -0.01548698\n",
      " -0.01237261 -0.01262105  0.06780084  0.01257971  0.0377764   0.06256364\n",
      " -0.03144404 -0.01075378  0.03944653 -0.00209645  0.02778062  0.01813559\n",
      "  0.01692554  0.02385888  0.01628304  0.0564728  -0.02729895  0.01436914\n",
      "  0.01615534  0.02640039]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879155364989\n",
      "coeffs:  [-0.18714075  0.01704012  0.19946702 -0.00406785  0.07164477  0.03209035\n",
      "  0.02510903  0.06540547 -0.1092895  -0.04174455 -0.12761399  0.01701964\n",
      "  0.01686847  0.15042815 -0.08021321  0.08854278  0.09045515  0.0219391\n",
      " -0.26497512 -0.22797091  0.00565868  0.08414395 -0.0468313   0.17579683\n",
      " -0.07263776 -0.47170156  0.20418557  0.19409808  0.09330033  0.15634949\n",
      "  0.06450898 -0.03563625 -0.2838085   0.12329658  0.05389558  0.42785251\n",
      "  0.57741007 -0.05588241]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879156760692\n",
      "coeffs:  [-0.19010237  0.02054843  0.19552666 -0.00074396  0.07092758  0.02909365\n",
      "  0.0231664   0.06694838 -0.11170344 -0.04251103 -0.12712205  0.0147835\n",
      "  0.01614051  0.14968972 -0.08082338  0.08733201  0.08896393  0.02014273\n",
      " -0.26451512 -0.22803646  0.00472363  0.082943   -0.04271326  0.17869829\n",
      " -0.07275686 -0.47060149  0.20883048  0.19297953  0.09453082  0.15705357\n",
      "  0.06795653 -0.03864078 -0.28128728  0.12052255  0.05403791  0.42670525\n",
      "  0.58209845 -0.05458416]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879156760714\n",
      "coeffs:  [-0.19010236  0.02054843  0.19552666 -0.00074396  0.07092758  0.02909365\n",
      "  0.0231664   0.06694838 -0.11170344 -0.04251103 -0.12712205  0.0147835\n",
      "  0.01614051  0.14968972 -0.08082338  0.08733201  0.08896393  0.02014273\n",
      " -0.26451512 -0.22803646  0.00472363  0.082943   -0.04271326  0.17869829\n",
      " -0.07275686 -0.47060149  0.20883048  0.19297953  0.09453082  0.15705357\n",
      "  0.06795653 -0.03864078 -0.28128728  0.12052255  0.05403791  0.42670525\n",
      "  0.58209845 -0.05458416]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879156760715\n",
      "coeffs:  [-0.19010237  0.02054843  0.19552666 -0.00074396  0.07092758  0.02909365\n",
      "  0.0231664   0.06694839 -0.11170344 -0.04251103 -0.12712205  0.0147835\n",
      "  0.01614051  0.14968972 -0.08082338  0.08733201  0.08896393  0.02014273\n",
      " -0.26451512 -0.22803646  0.00472363  0.082943   -0.04271326  0.17869829\n",
      " -0.07275686 -0.47060149  0.20883048  0.19297953  0.09453082  0.15705357\n",
      "  0.06795653 -0.03864078 -0.28128728  0.12052255  0.05403791  0.42670525\n",
      "  0.58209845 -0.05458416]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879161572507\n",
      "coeffs:  [-0.18219733  0.0151479   0.18207631  0.00492869  0.0716502   0.02810168\n",
      "  0.02578594  0.07941042 -0.10025127 -0.05257447 -0.12730686  0.01421036\n",
      "  0.00971069  0.15534811 -0.0967257   0.08156713  0.09240317  0.0053895\n",
      " -0.25982698 -0.22594907  0.00132774  0.08888652 -0.04329581  0.16721405\n",
      " -0.05940092 -0.47439149  0.21218131  0.21489427  0.08485717  0.14996139\n",
      "  0.07691389 -0.04493249 -0.28169047  0.12576463  0.04867071  0.43798995\n",
      "  0.57700494 -0.05554034]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163317631\n",
      "coeffs:  [-0.17872936  0.01493523  0.17706536  0.00334265  0.07297387  0.02617535\n",
      "  0.02491041  0.08091427 -0.09165794 -0.06105818 -0.1270461   0.01812759\n",
      "  0.0052263   0.1663423  -0.11176375  0.07884273  0.1008721  -0.00766558\n",
      " -0.26158947 -0.23083648 -0.00410222  0.09465535 -0.03452698  0.15919434\n",
      " -0.0490954  -0.48864384  0.22264344  0.23802419  0.07713609  0.14900065\n",
      "  0.07494438 -0.05202387 -0.29052083  0.13359259  0.0372147   0.44809937\n",
      "  0.5878853  -0.05574865]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163317651\n",
      "coeffs:  [-0.17872934  0.01493523  0.17706536  0.00334265  0.07297387  0.02617535\n",
      "  0.02491041  0.08091427 -0.09165794 -0.06105818 -0.1270461   0.01812759\n",
      "  0.0052263   0.1663423  -0.11176375  0.07884273  0.1008721  -0.00766558\n",
      " -0.26158947 -0.23083648 -0.00410222  0.09465535 -0.03452698  0.15919434\n",
      " -0.0490954  -0.48864384  0.22264344  0.23802419  0.07713609  0.14900065\n",
      "  0.07494438 -0.05202387 -0.29052083  0.13359259  0.0372147   0.44809937\n",
      "  0.5878853  -0.05574865]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163317652\n",
      "coeffs:  [-0.17872936  0.01493525  0.17706536  0.00334265  0.07297387  0.02617535\n",
      "  0.02491041  0.08091427 -0.09165794 -0.06105818 -0.1270461   0.01812759\n",
      "  0.0052263   0.1663423  -0.11176375  0.07884273  0.1008721  -0.00766558\n",
      " -0.26158947 -0.23083648 -0.00410222  0.09465535 -0.03452698  0.15919434\n",
      " -0.0490954  -0.48864384  0.22264344  0.23802419  0.07713609  0.14900065\n",
      "  0.07494438 -0.05202387 -0.29052083  0.13359259  0.0372147   0.44809937\n",
      "  0.5878853  -0.05574865]\n",
      "\n",
      "find better score:\n",
      "score:  6017.8791633176525\n",
      "coeffs:  [-0.17872936  0.01493523  0.17706536  0.00334265  0.07297387  0.02617535\n",
      "  0.02491041  0.08091427 -0.09165794 -0.06105818 -0.1270461   0.01812759\n",
      "  0.00522632  0.1663423  -0.11176375  0.07884273  0.1008721  -0.00766558\n",
      " -0.26158947 -0.23083648 -0.00410222  0.09465535 -0.03452698  0.15919434\n",
      " -0.0490954  -0.48864384  0.22264344  0.23802419  0.07713609  0.14900065\n",
      "  0.07494438 -0.05202387 -0.29052083  0.13359259  0.0372147   0.44809937\n",
      "  0.5878853  -0.05574865]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163594415\n",
      "coeffs:  [-0.17681619  0.01809198  0.17583691  0.00342254  0.07288194  0.02611489\n",
      "  0.02334622  0.0808951  -0.08865329 -0.06288963 -0.12745252  0.01811753\n",
      "  0.00406839  0.16961889 -0.11537208  0.07815981  0.10320261 -0.01140544\n",
      " -0.26167521 -0.23216298 -0.00597549  0.09541092 -0.03292325  0.15746359\n",
      " -0.04652516 -0.49159181  0.22561371  0.24331126  0.07417081  0.14654652\n",
      "  0.07629487 -0.05473455 -0.29110596  0.13490332  0.03369771  0.44933822\n",
      "  0.5916388  -0.05581563]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163697212\n",
      "coeffs:  [-0.17577438  0.01830893  0.17556819  0.003854    0.07283728  0.02646998\n",
      "  0.02326012  0.08074636 -0.08807797 -0.06241596 -0.12754682  0.01781187\n",
      "  0.00446765  0.16915969 -0.11471913  0.07801641  0.10270396 -0.01138734\n",
      " -0.26091059 -0.23160755 -0.00565083  0.09501524 -0.03306277  0.15761831\n",
      " -0.04676755 -0.48982818  0.22486948  0.24188831  0.07372313  0.14541436\n",
      "  0.0759996  -0.05484714 -0.2889851   0.1341821   0.03396124  0.44792\n",
      "  0.59064737 -0.05577644]\n",
      "\n",
      "find better score:\n",
      "score:  6017.879163850169\n",
      "coeffs:  [-0.1742438   0.01812104  0.17509937  0.00366849  0.07282937  0.02690933\n",
      "  0.0234198   0.08037341 -0.08694028 -0.06225823 -0.1273989   0.0178412\n",
      "  0.00519154  0.16917029 -0.11467265  0.07779678  0.10261512 -0.01186499\n",
      " -0.26005145 -0.23108637 -0.00552619  0.0948617  -0.03309126  0.15740438\n",
      " -0.04645857 -0.48843406  0.22403869  0.24149861  0.07276082  0.144039\n",
      "  0.07573344 -0.05525391 -0.2870832   0.13375564  0.03376434  0.44690622\n",
      "  0.5894138  -0.0555187 ]\n",
      "\n",
      "find better score:\n",
      "score:  6018.879164096757\n",
      "coeffs:  [-0.1722091   0.01772693  0.17464818  0.00344131  0.07271881  0.02738289\n",
      "  0.02352599  0.07978855 -0.08509078 -0.06246778 -0.1270788   0.01799018\n",
      "  0.00638535  0.1702387  -0.11550128  0.07753666  0.10335306 -0.01323262\n",
      " -0.25938572 -0.23118111 -0.00612955  0.09468244 -0.03226665  0.15709025\n",
      " -0.04561229 -0.48803334  0.22404493  0.24239883  0.07096287  0.14219575\n",
      "  0.07499272 -0.05654753 -0.28530952  0.13360927  0.03243088  0.446051\n",
      "  0.58971355 -0.05570288]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879164451789\n",
      "coeffs:  [-0.16931888  0.01727374  0.17319401  0.00307051  0.07251105  0.02762034\n",
      "  0.02366492  0.07845406 -0.08194901 -0.06373582 -0.12677849  0.01830108\n",
      "  0.00844288  0.17318379 -0.11842271  0.0771027   0.10562724 -0.01643589\n",
      " -0.25853924 -0.23165564 -0.00790287  0.09495545 -0.03028838  0.15632165\n",
      " -0.04289122 -0.48917383  0.2250188   0.24689982  0.06776504  0.13977191\n",
      "  0.07368447 -0.0592693  -0.2842922   0.13430008  0.02921933  0.44636723\n",
      "  0.59077443 -0.05580161]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [ 0.04696991  0.0726654  -0.0037472   0.03324695  0.06264473  0.0574538\n",
      " -0.00584598 -0.0356132   0.01129999  0.03312522  0.04930452  0.02481808\n",
      "  0.07634587  0.04007094  0.04640396 -0.01060296  0.00456679 -0.04019333\n",
      "  0.01436483  0.04424326  0.02236822  0.0207549   0.05483898  0.00553601\n",
      "  0.03522607  0.00199768  0.02653702  0.0439277   0.01442375  0.03133552\n",
      "  0.05896734 -0.01413588  0.03415324  0.03428579  0.06461465 -0.00210916\n",
      "  0.03113105  0.03640414]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879165896728\n",
      "coeffs:  [-0.1645741   0.01805534  0.16776693  0.00476725  0.07507703  0.02424319\n",
      "  0.0239286   0.0751776  -0.07658001 -0.07042773 -0.12640272  0.01253403\n",
      "  0.01378516  0.18612445 -0.1314574   0.06737587  0.13325722 -0.02646575\n",
      " -0.26410808 -0.23659054 -0.01989168  0.1052953  -0.02461951  0.15464867\n",
      " -0.02661761 -0.50724973  0.22847468  0.26604612  0.05030127  0.13924638\n",
      "  0.07423851 -0.0823621  -0.29444444  0.14551098  0.04529802  0.44064847\n",
      "  0.60293092 -0.05707232]\n",
      "\n",
      "find better score:\n",
      "score:  6019.8791658967575\n",
      "coeffs:  [-0.16457409  0.01805534  0.16776693  0.00476725  0.07507703  0.02424319\n",
      "  0.0239286   0.0751776  -0.07658001 -0.07042773 -0.12640272  0.01253403\n",
      "  0.01378516  0.18612445 -0.1314574   0.06737587  0.13325722 -0.02646575\n",
      " -0.26410808 -0.23659054 -0.01989168  0.1052953  -0.02461951  0.15464867\n",
      " -0.02661761 -0.50724973  0.22847468  0.26604612  0.05030127  0.13924638\n",
      "  0.07423851 -0.0823621  -0.29444444  0.14551098  0.04529802  0.44064847\n",
      "  0.60293092 -0.05707232]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879165896758\n",
      "coeffs:  [-0.1645741   0.01805534  0.16776693  0.00476725  0.07507703  0.02424319\n",
      "  0.0239286   0.0751776  -0.07658001 -0.07042773 -0.12640272  0.01253403\n",
      "  0.01378516  0.18612446 -0.1314574   0.06737587  0.13325722 -0.02646575\n",
      " -0.26410808 -0.23659054 -0.01989168  0.1052953  -0.02461951  0.15464867\n",
      " -0.02661761 -0.50724973  0.22847468  0.26604612  0.05030127  0.13924638\n",
      "  0.07423851 -0.0823621  -0.29444444  0.14551098  0.04529802  0.44064847\n",
      "  0.60293092 -0.05707232]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879166078471\n",
      "coeffs:  [-0.16481056  0.01804436  0.16880051  0.00505259  0.07546624  0.0243452\n",
      "  0.02396418  0.07516588 -0.07773977 -0.06934449 -0.12587895  0.01214388\n",
      "  0.01402873  0.18550258 -0.12980072  0.06746775  0.13280424 -0.02547992\n",
      " -0.26432686 -0.23710763 -0.01918782  0.10497826 -0.02455054  0.15880194\n",
      " -0.02818421 -0.50604104  0.22791517  0.2624738   0.05016343  0.13829659\n",
      "  0.0745297  -0.08223667 -0.29229045  0.14454645  0.04499928  0.4369959\n",
      "  0.60343316 -0.05704599]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879166078512\n",
      "coeffs:  [-0.16481054  0.01804436  0.16880051  0.00505259  0.07546624  0.0243452\n",
      "  0.02396418  0.07516588 -0.07773977 -0.06934449 -0.12587895  0.01214388\n",
      "  0.01402873  0.18550258 -0.12980072  0.06746775  0.13280424 -0.02547992\n",
      " -0.26432686 -0.23710763 -0.01918782  0.10497826 -0.02455054  0.15880194\n",
      " -0.02818421 -0.50604104  0.22791517  0.2624738   0.05016343  0.13829659\n",
      "  0.0745297  -0.08223667 -0.29229045  0.14454645  0.04499928  0.4369959\n",
      "  0.60343316 -0.05704599]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879166078513\n",
      "coeffs:  [-0.16481056  0.01804436  0.16880051  0.00505259  0.07546624  0.0243452\n",
      "  0.02396418  0.07516588 -0.07773977 -0.06934449 -0.12587895  0.01214388\n",
      "  0.01402873  0.18550258 -0.12980072  0.06746775  0.13280424 -0.02547992\n",
      " -0.26432686 -0.23710763 -0.01918782  0.10497826 -0.02455054  0.15880195\n",
      " -0.02818421 -0.50604104  0.22791517  0.2624738   0.05016343  0.13829659\n",
      "  0.0745297  -0.08223667 -0.29229045  0.14454645  0.04499928  0.4369959\n",
      "  0.60343316 -0.05704599]\n",
      "\n",
      "find better score:\n",
      "score:  6019.879166326234\n",
      "coeffs:  [-0.165419    0.01756053  0.17000269  0.00534348  0.07585781  0.0243026\n",
      "  0.02420011  0.07508949 -0.0791309  -0.06845709 -0.12563334  0.0120945\n",
      "  0.01440669  0.18559446 -0.12877238  0.06798797  0.13309058 -0.02441532\n",
      " -0.26474786 -0.23803852 -0.01879283  0.10480381 -0.02491189  0.16117242\n",
      " -0.02939648 -0.50577534  0.22666528  0.26020998  0.04936269  0.13789588\n",
      "  0.07465227 -0.08059891 -0.29136318  0.14571623  0.04405061  0.43436821\n",
      "  0.60396009 -0.05693701]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv, metric, best_score, best_coeffs, True), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 6019.879166326234}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-0.165419  ,  0.01756053,  0.17000269,  0.00534348,  0.07585781,\n",
       "         0.0243026 ,  0.02420011,  0.07508949, -0.0791309 , -0.06845709,\n",
       "        -0.12563334,  0.0120945 ,  0.01440669,  0.18559446, -0.12877238,\n",
       "         0.06798797,  0.13309058, -0.02441532, -0.26474786, -0.23803852,\n",
       "        -0.01879283,  0.10480381, -0.02491189,  0.16117242, -0.02939648,\n",
       "        -0.50577534,  0.22666528,  0.26020998,  0.04936269,  0.13789588,\n",
       "         0.07465227, -0.08059891, -0.29136318,  0.14571623,  0.04405061,\n",
       "         0.43436821,  0.60396009, -0.05693701])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prices = np.sort(df_train['total_price'].unique())\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return array[(np.fabs(array - value)).argmin()]\n",
    "\n",
    "def correct_prices(sq):\n",
    "    return [find_nearest(unique_prices, x) for x in sq]\n",
    "\n",
    "test_pred_final['total_price'] = correct_prices(test_pred_final['total_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
