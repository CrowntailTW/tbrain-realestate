{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape, cal_score_smooth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '19'\n",
    "models = '1-34,36-37'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = False\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 36, 37]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-kfold.csv\n",
      "28 model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "29 model-29-lgb-building_age-fillna-cv.csv\n",
      "29 model-29-lgb-building_age-fillna-test-kfold.csv\n",
      "29 model-29-lgb-building_age-fillna-test-one.csv\n",
      "30 model-30-lgb-binary-2-cv.csv\n",
      "30 model-30-lgb-binary-2-test-kfold.csv\n",
      "30 model-30-lgb-binary-2-test-one.csv\n",
      "31 model-31-lgb-3_groups-cv.csv\n",
      "31 model-31-lgb-3_groups-test-kfold.csv\n",
      "31 model-31-lgb-3_groups-test-one.csv\n",
      "32 model-32-lgb-remove_outlier_01-cv.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-kfold.csv\n",
      "32 model-32-lgb-remove_outlier_01-test-one.csv\n",
      "33 model-33-lgb-remove_outlier_03-cv.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-kfold.csv\n",
      "33 model-33-lgb-remove_outlier_03-test-one.csv\n",
      "34 model-34-lgb-remove_outlier_01-cv.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-kfold.csv\n",
      "34 model-34-lgb-remove_outlier_01-test-one.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-kfold.csv\n",
      "36 model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "37 model-37-lgb-remove_outlier_05-cv.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-kfold.csv\n",
      "37 model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "36\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n",
      "model-28-lgb-search-bins-lr-0.0005-255-cv.csv\n",
      "model-29-lgb-building_age-fillna-cv.csv\n",
      "model-30-lgb-binary-2-cv.csv\n",
      "model-31-lgb-3_groups-cv.csv\n",
      "model-32-lgb-remove_outlier_01-cv.csv\n",
      "model-33-lgb-remove_outlier_03-cv.csv\n",
      "model-34-lgb-remove_outlier_01-cv.csv\n",
      "model-36-lgb-remove_outlier_03-0.001-2-cv.csv\n",
      "model-37-lgb-remove_outlier_05-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n",
      "No. 27 file: model-28-lgb-search-bins-lr-0.0005-255-test-one.csv\n",
      "No. 28 file: model-29-lgb-building_age-fillna-test-one.csv\n",
      "No. 29 file: model-30-lgb-binary-2-test-one.csv\n",
      "No. 30 file: model-31-lgb-3_groups-test-one.csv\n",
      "No. 31 file: model-32-lgb-remove_outlier_01-test-one.csv\n",
      "No. 32 file: model-33-lgb-remove_outlier_03-test-one.csv\n",
      "No. 33 file: model-34-lgb-remove_outlier_01-test-one.csv\n",
      "No. 34 file: model-36-lgb-remove_outlier_03-0.001-2-test-one.csv\n",
      "No. 35 file: model-37-lgb-remove_outlier_05-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.360546</td>\n",
       "      <td>12.131443</td>\n",
       "      <td>6.245441e+05</td>\n",
       "      <td>13.344779</td>\n",
       "      <td>12.115676</td>\n",
       "      <td>6.319899e+05</td>\n",
       "      <td>13.356630</td>\n",
       "      <td>12.127527</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.934792</td>\n",
       "      <td>13.538225</td>\n",
       "      <td>3.042045e+06</td>\n",
       "      <td>14.928041</td>\n",
       "      <td>13.531473</td>\n",
       "      <td>3.142342e+06</td>\n",
       "      <td>14.960479</td>\n",
       "      <td>13.563912</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.111430</td>\n",
       "      <td>14.391475</td>\n",
       "      <td>9.818275e+06</td>\n",
       "      <td>16.099756</td>\n",
       "      <td>14.379801</td>\n",
       "      <td>9.946933e+06</td>\n",
       "      <td>16.112775</td>\n",
       "      <td>14.392820</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.360720</td>\n",
       "      <td>13.753373</td>\n",
       "      <td>1.264691e+07</td>\n",
       "      <td>16.352924</td>\n",
       "      <td>13.745577</td>\n",
       "      <td>1.295773e+07</td>\n",
       "      <td>16.377203</td>\n",
       "      <td>13.769857</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.833961</td>\n",
       "      <td>12.288935</td>\n",
       "      <td>9.305770e+05</td>\n",
       "      <td>13.743561</td>\n",
       "      <td>12.198536</td>\n",
       "      <td>9.859947e+05</td>\n",
       "      <td>13.801407</td>\n",
       "      <td>12.256382</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 113 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "           ...            log_pred_34  log_parea_pred_34       pred_36  \\\n",
       "0          ...              13.360546          12.131443  6.245441e+05   \n",
       "1          ...              14.934792          13.538225  3.042045e+06   \n",
       "2          ...              16.111430          14.391475  9.818275e+06   \n",
       "3          ...              16.360720          13.753373  1.264691e+07   \n",
       "4          ...              13.833961          12.288935  9.305770e+05   \n",
       "\n",
       "   log_pred_36  log_parea_pred_36       pred_37  log_pred_37  \\\n",
       "0    13.344779          12.115676  6.319899e+05    13.356630   \n",
       "1    14.928041          13.531473  3.142342e+06    14.960479   \n",
       "2    16.099756          14.379801  9.946933e+06    16.112775   \n",
       "3    16.352924          13.745577  1.295773e+07    16.377203   \n",
       "4    13.743561          12.198536  9.859947e+05    13.801407   \n",
       "\n",
       "   log_parea_pred_37  log_total_price  log_parea_total_price  \n",
       "0          12.127527        13.381036              12.151933  \n",
       "1          13.563912        15.015913              13.619345  \n",
       "2          14.392820        16.074236              14.354282  \n",
       "3          13.769857        16.469809              13.862462  \n",
       "4          12.256382        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 113 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_33</th>\n",
       "      <th>pred_34</th>\n",
       "      <th>log_pred_34</th>\n",
       "      <th>log_parea_pred_34</th>\n",
       "      <th>pred_36</th>\n",
       "      <th>log_pred_36</th>\n",
       "      <th>log_parea_pred_36</th>\n",
       "      <th>pred_37</th>\n",
       "      <th>log_pred_37</th>\n",
       "      <th>log_parea_pred_37</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.177853</td>\n",
       "      <td>1.265085e+07</td>\n",
       "      <td>16.353235</td>\n",
       "      <td>15.124128</td>\n",
       "      <td>1.298618e+07</td>\n",
       "      <td>16.379396</td>\n",
       "      <td>15.150290</td>\n",
       "      <td>1.304845e+07</td>\n",
       "      <td>16.384180</td>\n",
       "      <td>15.155073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.129452</td>\n",
       "      <td>3.890897e+06</td>\n",
       "      <td>15.174151</td>\n",
       "      <td>13.129532</td>\n",
       "      <td>3.897411e+06</td>\n",
       "      <td>15.175823</td>\n",
       "      <td>13.131204</td>\n",
       "      <td>3.897545e+06</td>\n",
       "      <td>15.175858</td>\n",
       "      <td>13.131239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.676769</td>\n",
       "      <td>1.078313e+07</td>\n",
       "      <td>16.193493</td>\n",
       "      <td>13.694473</td>\n",
       "      <td>1.049745e+07</td>\n",
       "      <td>16.166643</td>\n",
       "      <td>13.667623</td>\n",
       "      <td>1.035078e+07</td>\n",
       "      <td>16.152573</td>\n",
       "      <td>13.653552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.815015</td>\n",
       "      <td>6.080412e+06</td>\n",
       "      <td>15.620583</td>\n",
       "      <td>14.808651</td>\n",
       "      <td>6.139949e+06</td>\n",
       "      <td>15.630327</td>\n",
       "      <td>14.818395</td>\n",
       "      <td>6.120593e+06</td>\n",
       "      <td>15.627170</td>\n",
       "      <td>14.815237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.159895</td>\n",
       "      <td>1.092040e+06</td>\n",
       "      <td>13.903559</td>\n",
       "      <td>12.143297</td>\n",
       "      <td>1.106728e+06</td>\n",
       "      <td>13.916919</td>\n",
       "      <td>12.156657</td>\n",
       "      <td>1.098338e+06</td>\n",
       "      <td>13.909310</td>\n",
       "      <td>12.149048</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 110 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3        ...          log_parea_pred_33       pred_34  \\\n",
       "0   16.544464        ...                  15.177853  1.265085e+07   \n",
       "1   15.196062        ...                  13.129452  3.890897e+06   \n",
       "2   16.199646        ...                  13.676769  1.078313e+07   \n",
       "3   15.609807        ...                  14.815015  6.080412e+06   \n",
       "4   13.842395        ...                  12.159895  1.092040e+06   \n",
       "\n",
       "   log_pred_34  log_parea_pred_34       pred_36  log_pred_36  \\\n",
       "0    16.353235          15.124128  1.298618e+07    16.379396   \n",
       "1    15.174151          13.129532  3.897411e+06    15.175823   \n",
       "2    16.193493          13.694473  1.049745e+07    16.166643   \n",
       "3    15.620583          14.808651  6.139949e+06    15.630327   \n",
       "4    13.903559          12.143297  1.106728e+06    13.916919   \n",
       "\n",
       "   log_parea_pred_36       pred_37  log_pred_37  log_parea_pred_37  \n",
       "0          15.150290  1.304845e+07    16.384180          15.155073  \n",
       "1          13.131204  3.897545e+06    15.175858          13.131239  \n",
       "2          13.667623  1.035078e+07    16.152573          13.653552  \n",
       "3          14.818395  6.120593e+06    15.627170          14.815237  \n",
       "4          12.156657  1.098338e+06    13.909310          12.149048  \n",
       "\n",
       "[5 rows x 110 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n",
      "27 model-28 5901.874202\n",
      "28 model-29 5884.873848\n",
      "29 model-30 5864.872101\n",
      "30 model-31 5783.868923\n",
      "31 model-32 5930.875106\n",
      "32 model-33 5976.875715\n",
      "33 model-34 5942.875172\n",
      "34 model-36 5989.876236\n",
      "35 model-37 5980.875836\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, cv, metric, best_score, best_coeffs, verbose):\n",
    "    cv_pred_final = cv.loc[:, cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        if verbose:\n",
    "            print('find better score:')\n",
    "            print('score: ', score)\n",
    "            print('coeffs: ', x)\n",
    "            print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'smooth':\n",
    "        return cal_score_smooth(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [[1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CV\n",
    "(not run yet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/sklearn/model_selection/_split.py:431: FutureWarning: The default value of n_split will change from 3 to 5 in version 0.22. Specify it explicitly to silence this warning.\n",
      "  warnings.warn(NSPLIT_WARNING, FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776]\n",
      "\n",
      "find better score:\n",
      "score:  316.6676953052345\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  316.6676954487517\n",
      "coeffs:  [0.02777779 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  316.66769544875206\n",
      "coeffs:  [0.02777778 0.02777778 0.02777779 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  316.6676954487521\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777779 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  316.66769544875865\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777779 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  316.6676954488025\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777779 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  695.6273668152159\n",
      "coeffs:  [0.02905268 0.02905156 0.02905256 0.02905281 0.02905262 0.02905265\n",
      " 0.0290512  0.02905185 0.02905264 0.02905265 0.0290547  0.02905238\n",
      " 0.02905191 0.02905262 0.02905266 0.0290526  0.02905264 0.0290526\n",
      " 0.0290526  0.02905257 0.02905264 0.02905262 0.02905254 0.0290525\n",
      " 0.02905257 0.02905265 0.02905247 0.02905257 0.02905253 0.02905246\n",
      " 0.0290524  0.02905234 0.02905193 0.02905234 0.02905192 0.02786219]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938314343244\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938315792717\n",
      "coeffs:  [0.02814099 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938315792744\n",
      "coeffs:  [0.02814098 0.02814066 0.02814096 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938315792871\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814098 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938315792876\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814098 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.7938315792983\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.0281409  0.02814076 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.793831579311\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814078 0.02814088 0.02814076 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  1607.793831579313\n",
      "coeffs:  [0.02814098 0.02814066 0.02814094 0.02814102 0.02814096 0.02814097\n",
      " 0.02814056 0.02814074 0.02814097 0.02814097 0.02814156 0.02814089\n",
      " 0.02814076 0.02814096 0.02814097 0.02814096 0.02814097 0.02814096\n",
      " 0.02814096 0.02814095 0.02814097 0.02814096 0.02814094 0.02814093\n",
      " 0.02814095 0.02814097 0.02814092 0.02814095 0.02814093 0.02814092\n",
      " 0.0281409  0.02814088 0.02814076 0.02814088 0.02814078 0.02780182]\n",
      "\n",
      "find better score:\n",
      "score:  3024.8055141549507\n",
      "coeffs:  [0.02875564 0.02875479 0.02875555 0.02875574 0.0287556  0.02875562\n",
      " 0.02875451 0.028755   0.02875561 0.02875562 0.0287572  0.02875542\n",
      " 0.02875506 0.0287556  0.02875563 0.02875558 0.02875561 0.02875558\n",
      " 0.02875558 0.02875556 0.02875561 0.0287556  0.02875554 0.02875551\n",
      " 0.02875556 0.02875562 0.02875548 0.02875556 0.02875553 0.02875548\n",
      " 0.02875543 0.02875538 0.02875507 0.02875538 0.02875506 0.02784252]\n",
      "\n",
      "find better score:\n",
      "score:  4772.859387503844\n",
      "coeffs:  [0.02836166 0.02836115 0.02836161 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836132 0.02836151 0.02836132 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  4772.859387598906\n",
      "coeffs:  [0.02836168 0.02836115 0.02836161 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836132 0.02836151 0.02836132 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  4772.85938759891\n",
      "coeffs:  [0.02836166 0.02836115 0.02836162 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836132 0.02836151 0.02836132 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  4772.859387598933\n",
      "coeffs:  [0.02836166 0.02836115 0.02836161 0.02836172 0.02836165 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836132 0.02836151 0.02836132 0.02781644]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  4772.859387598942\n",
      "coeffs:  [0.02836166 0.02836115 0.02836161 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836152 0.02836132 0.02836151 0.02836132 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  4772.859387598962\n",
      "coeffs:  [0.02836166 0.02836115 0.02836161 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836133 0.02836151 0.02836132 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  4772.859387598966\n",
      "coeffs:  [0.02836166 0.02836115 0.02836161 0.02836172 0.02836164 0.02836165\n",
      " 0.02836099 0.02836128 0.02836165 0.02836165 0.02836259 0.02836153\n",
      " 0.02836131 0.02836164 0.02836165 0.02836163 0.02836164 0.02836163\n",
      " 0.02836163 0.02836161 0.02836165 0.02836164 0.0283616  0.02836158\n",
      " 0.02836161 0.02836165 0.02836157 0.02836162 0.02836159 0.02836156\n",
      " 0.02836154 0.02836151 0.02836132 0.02836151 0.02836133 0.02781644]\n",
      "\n",
      "find better score:\n",
      "score:  5897.873170797381\n",
      "coeffs:  [0.02855313 0.02855245 0.02855305 0.02855321 0.02855309 0.02855311\n",
      " 0.02855223 0.02855262 0.0285531  0.02855311 0.02855436 0.02855295\n",
      " 0.02855266 0.02855309 0.02855312 0.02855308 0.0285531  0.02855308\n",
      " 0.02855308 0.02855306 0.0285531  0.02855309 0.02855305 0.02855302\n",
      " 0.02855306 0.02855311 0.028553   0.02855306 0.02855304 0.02855299\n",
      " 0.02855296 0.02855292 0.02855267 0.02855292 0.02855267 0.02782911]\n",
      "\n",
      "find better score:\n",
      "score:  5967.877028005386\n",
      "coeffs:  [0.02851332 0.02851268 0.02851325 0.02851339 0.02851328 0.0285133\n",
      " 0.02851247 0.02851284 0.0285133  0.0285133  0.02851449 0.02851315\n",
      " 0.02851288 0.02851329 0.02851331 0.02851327 0.02851329 0.02851327\n",
      " 0.02851327 0.02851326 0.0285133  0.02851329 0.02851324 0.02851322\n",
      " 0.02851326 0.0285133  0.0285132  0.02851326 0.02851323 0.02851319\n",
      " 0.02851316 0.02851312 0.02851289 0.02851312 0.02851288 0.02782648]\n",
      "\n",
      "find better score:\n",
      "score:  5972.876699845728\n",
      "coeffs:  [ 0.02369359  0.03672832  0.02425289  0.02372369  0.02918528  0.02441083\n",
      "  0.03417773  0.04199338  0.02395806  0.02470577 -0.00946472  0.03604364\n",
      "  0.03755379  0.02428876  0.02479801  0.02532976  0.02604642  0.02609817\n",
      "  0.02596342  0.0253928   0.02730151  0.02727479  0.0335754   0.03090797\n",
      "  0.02601379  0.02634973  0.02728995  0.02531884  0.02525859  0.03472398\n",
      "  0.03190556  0.0345939   0.04150659  0.03465324  0.0443201   0.00667982]\n",
      "\n",
      "find better score:\n",
      "score:  5993.877518982104\n",
      "coeffs:  [ 0.01539425  0.03995019  0.01647415  0.01885539  0.0298452   0.01758232\n",
      "  0.02838462  0.05773518  0.01628424  0.01922744 -0.05676392  0.04309153\n",
      "  0.04546786  0.01765402  0.01964369  0.02066955  0.02296202  0.02276379\n",
      "  0.02291536  0.02068395  0.02443053  0.02423223  0.04489474  0.03561038\n",
      "  0.02249632  0.02478198  0.02693044  0.02030255  0.01979375  0.04815994\n",
      "  0.03938605  0.04683437  0.06433571  0.04690217  0.07247834 -0.00325471]\n",
      "\n",
      "find better score:\n",
      "score:  6015.878815357781\n",
      "coeffs:  [-0.02732741 -0.03631302 -0.02091135 -0.00160773  0.08012928 -0.01760105\n",
      "  0.03954039  0.07647664 -0.02299085 -0.01156773 -0.04973825  0.0005041\n",
      "  0.04808083 -0.019886   -0.00982191 -0.00683013 -0.00029426  0.00382167\n",
      " -0.00278273 -0.01624518  0.04918995  0.04796837  0.04658167  0.03615642\n",
      " -0.00931042  0.0092439   0.04964622 -0.02029758 -0.01372283  0.06982297\n",
      "  0.0680128   0.11059736  0.20464731  0.11122698  0.24133406 -0.08899309]\n",
      "\n",
      "find better score:\n",
      "score:  6020.878874054579\n",
      "coeffs:  [-0.03649183 -0.02980009 -0.02831744 -0.00452607  0.0850684  -0.02493018\n",
      "  0.05343888  0.09113993 -0.03234589 -0.01904078 -0.03891902  0.00574901\n",
      "  0.06390688 -0.02918186 -0.01733258 -0.0141005  -0.00644061 -0.00213772\n",
      " -0.0125393  -0.02832715  0.04878515  0.04710942  0.04163542  0.03172976\n",
      " -0.02119668  0.00189494  0.0551059  -0.03301581 -0.02333092  0.0689866\n",
      "  0.06912299  0.11682073  0.23248216  0.11777499  0.27644221 -0.08165634]\n",
      "\n",
      "find better score:\n",
      "score:  6022.879067842204\n",
      "coeffs:  [-0.03574447 -0.02562093 -0.02305626 -0.0094413   0.07894082 -0.02075345\n",
      "  0.04207614  0.08833083 -0.03445508 -0.01633413 -0.05823578 -0.00413655\n",
      "  0.06722221 -0.03043595 -0.01575949 -0.01274768 -0.00283971 -0.00094815\n",
      " -0.02228358 -0.04005433  0.03735006  0.03430201  0.04101167  0.02897434\n",
      " -0.03484206 -0.00494503  0.07662382 -0.04469744 -0.02864093  0.07196959\n",
      "  0.07088977  0.11520755  0.27131896  0.11728434  0.32771856 -0.05092731]\n",
      "\n",
      "find better score:\n",
      "score:  6032.879253893594\n",
      "coeffs:  [-1.44487795e-02  1.20558594e-02  9.74455653e-03 -4.13396286e-02\n",
      "  6.19480537e-02  7.60676202e-03  6.44958613e-02  5.45869077e-02\n",
      " -2.97164023e-02 -4.31982282e-05 -7.09862558e-02 -2.38004458e-02\n",
      "  5.83846455e-02 -2.48532486e-02 -2.36165587e-03  2.20151720e-04\n",
      "  1.67418642e-02  6.06790067e-03 -5.12530926e-02 -6.91155666e-02\n",
      "  1.32505385e-02  4.27554342e-03  4.30592819e-02  3.13066306e-02\n",
      " -7.42620551e-02 -2.74865005e-02  1.31267227e-01 -6.97107882e-02\n",
      " -3.47736169e-02  7.05891298e-02  6.16550284e-02  7.89964388e-02\n",
      "  3.21331577e-01  8.43952943e-02  4.05890892e-01 -5.98105579e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6039.879574188493\n",
      "coeffs:  [-0.00250808  0.02749957  0.03865837 -0.05503725  0.08123862  0.03066168\n",
      "  0.02358589  0.06086035 -0.03544157  0.01407162 -0.07819906 -0.01093294\n",
      "  0.06647689 -0.02134631  0.00966163  0.01401699  0.03819039  0.01401428\n",
      " -0.0832977  -0.09817534  0.02246337  0.01096831  0.05448383  0.03664515\n",
      " -0.11786881 -0.05174763  0.17250636 -0.09516186 -0.04156261  0.07415621\n",
      "  0.05501844  0.01944748  0.34553144  0.02846965  0.45701129 -0.07152233]\n",
      "\n",
      "find better score:\n",
      "score:  6039.879651546683\n",
      "coeffs:  [-0.00730297  0.00153514  0.04720213 -0.05663172  0.083733    0.03689183\n",
      "  0.04240347  0.07093545 -0.05301539  0.02243542 -0.09054635 -0.00387156\n",
      "  0.06401698 -0.02185596  0.01644436  0.02416047  0.05582727  0.01949726\n",
      " -0.09923695 -0.11112504  0.01941972  0.00726946  0.06992907  0.05237411\n",
      " -0.14352142 -0.06193398  0.19845074 -0.10580706 -0.04243465  0.08636761\n",
      "  0.07045118 -0.0162007   0.35320015 -0.0051836   0.47950003 -0.05686752]\n",
      "\n",
      "find better score:\n",
      "score:  6041.879585107611\n",
      "coeffs:  [-0.01753489  0.00128849  0.04618388 -0.05276238  0.07327617  0.03544831\n",
      "  0.03663062  0.08099582 -0.06883027  0.02774977 -0.08603654 -0.0056357\n",
      "  0.06437989 -0.02337624  0.01998916  0.03124151  0.06914226  0.02295459\n",
      " -0.10364645 -0.11396576  0.00605493 -0.0057794   0.07167307  0.06405984\n",
      " -0.1554569  -0.06273659  0.21563718 -0.10751571 -0.04046141  0.09159674\n",
      "  0.08039725 -0.0291561   0.36127904 -0.01713247  0.49351899 -0.05831721]\n",
      "\n",
      "find better score:\n",
      "score:  6042.879460517594\n",
      "coeffs:  [-0.0746171   0.01893204  0.07185753 -0.07844853  0.10455203  0.06358877\n",
      "  0.03850653  0.0760805  -0.12339109  0.05472334 -0.0936008  -0.02406144\n",
      "  0.05964873 -0.31289351 -0.05557504  0.15555787  0.47573788 -0.04849653\n",
      " -0.07714383 -0.08646699 -0.045727    0.00201097 -0.02092491  0.06780845\n",
      " -0.47577823  0.08902546  0.28699878 -0.08929533 -0.00098738  0.18312043\n",
      "  0.05985283 -0.0342874   0.30246289 -0.03491098  0.5685832  -0.04170373]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "find better score:\n",
      "score:  6047.87941888606\n",
      "coeffs:  [-0.11318891  0.02928149  0.01417211 -0.07807213  0.09188701  0.11996812\n",
      "  0.04043877  0.06822031 -0.09092625  0.08011234 -0.09767094 -0.02241355\n",
      "  0.05912913 -0.39242456  0.11337002  0.17199378  0.18496268  0.1639997\n",
      " -0.00979511  0.16133809  0.05573469 -0.06831103 -0.00264365  0.0742215\n",
      " -0.76310663  0.0538268   0.30554133 -0.08042261 -0.06664451  0.12614471\n",
      "  0.08535604 -0.13720119  0.32159725  0.08808653  0.51729482 -0.06379054]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.5296192548569031, -0.9371895353230894, -0.937782584245267, 1.5051239908388594, 0.2682545889816639, -0.39513019292116663, 2.1560102662949943, -0.5300149607758173, -0.11841795479293817, 0.6991482453445154, -0.3971180916176833, 0.37286582385556805, 0.13391331805604773, -1.9326251679873185, -0.24907812605901813, -0.2716424211126901, -1.8998021279247215, 1.365622108378165, -1.086939526750787, -0.9598221340588567, -0.7083807506098937, 0.21266001611492552, 0.8025648990432044, -0.16037162248885828, 1.2713160985178509, -2.406032723460554, 0.7754076992366479, 0.18801960053065064, -1.5337913123936417, 0.4017279998915864, 0.16850958447984776, -1.7180723072432242, 0.0219262271160703, -1.64892186807067, -0.35597841400212404, 1.615729922206366]\n",
      "\n",
      "Optimizing with init x0: [-0.6560746872140686, -1.4173482932309656, 1.4794494243477476, 0.25591375080612583, 0.7038560308999772, -0.5565574074534013, 0.5100507029745771, -0.2240835057924097, 1.0328947357163731, -0.008306746392539123, -1.0858969241226193, -2.1207517976822623, 1.364414329275553, 0.4015151070764874, -0.9467542825185143, -0.11154726318185514, -0.4998855757058944, 1.7548870911465977, -0.08360714053642626, -0.06128584503729062, 1.3210019040263408, 0.8313144564480371, -0.628292871357325, -0.3501719398613541, 0.6572554112968994, -0.907765961049757, 2.2729699327217032, -0.09385002893027099, -0.9530668800313302, -0.7162776612773664, -0.45734275042271655, -1.2700350387494155, -0.5336701025982332, 2.6462560326202667, 0.49391812898615867, -0.5613339166047955]\n",
      "\n",
      "Optimizing with init x0: [-0.8644040483406713, -0.8669116937180812, 1.693736693854256, -1.5674186258275007, -0.5454646784055298, -1.7629005037795766, -0.895468309291871, -0.30808098942640877, 0.29568795685247073, 1.6243878492773247, 0.0018291811617487698, 0.7190074791083579, 1.1520700040085974, 0.9820085881037531, -1.5576013874422114, -0.08086651559742739, -0.20849516037487592, -0.07281482384483809, -0.02153637675618588, -0.11836434863383825, 0.0004258517890321917, 1.6847162195856853, -1.6235001560096134, 0.5243051270580185, 1.2641530061107218, 0.05250135150160492, 2.113053918114015, 1.0135217509673264, -0.21493488389305365, -0.7887268355068469, 1.250857344954365, 0.36521343515501814, -1.0926689365013171, -0.7307134993181232, 0.6103576394705963, -2.4421305388542516]\n",
      "\n",
      "Optimizing with init x0: [0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776]\n",
      "\n",
      "find better score:\n",
      "score:  313.6670824682582\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.66708261144146\n",
      "coeffs:  [0.02777779 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.66708261144174\n",
      "coeffs:  [0.02777778 0.02777778 0.02777779 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.66708261144294\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777779 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.66708261145214\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777779 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.6670826114588\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777779 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  313.66708261148824\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777779 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  713.629001829972\n",
      "coeffs:  [0.02904776 0.02904702 0.02904767 0.02904805 0.02904781 0.02904774\n",
      " 0.02904622 0.02904768 0.0290476  0.02904774 0.02904932 0.02904768\n",
      " 0.02904743 0.02904771 0.02904774 0.02904771 0.02904774 0.02904771\n",
      " 0.02904771 0.02904768 0.02904786 0.02904781 0.02904766 0.02904766\n",
      " 0.02904766 0.02904772 0.0290475  0.02904767 0.02904756 0.02904756\n",
      " 0.02904763 0.02904759 0.02904711 0.0290476  0.02904705 0.0278618 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.7918802568336\n",
      "coeffs:  [0.02813779 0.02813758 0.02813776 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.02813759 0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.7918804016085\n",
      "coeffs:  [0.02813781 0.02813758 0.02813776 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.02813759 0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.791880401612\n",
      "coeffs:  [0.02813779 0.02813758 0.02813778 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.02813759 0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.791880401629\n",
      "coeffs:  [0.02813779 0.02813758 0.02813776 0.02813787 0.02813782 0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.02813759 0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.7918804016417\n",
      "coeffs:  [0.02813779 0.02813758 0.02813776 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813778 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.02813759 0.0278016 ]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  1582.7918804016447\n",
      "coeffs:  [0.02813779 0.02813758 0.02813776 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813762 0.02813775 0.02813759 0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  1582.7918804016476\n",
      "coeffs:  [0.02813779 0.02813758 0.02813776 0.02813787 0.0281378  0.02813778\n",
      " 0.02813735 0.02813777 0.02813774 0.02813778 0.02813823 0.02813777\n",
      " 0.0281377  0.02813778 0.02813778 0.02813777 0.02813778 0.02813777\n",
      " 0.02813778 0.02813777 0.02813782 0.0281378  0.02813776 0.02813776\n",
      " 0.02813776 0.02813778 0.02813771 0.02813776 0.02813773 0.02813773\n",
      " 0.02813775 0.02813774 0.02813761 0.02813775 0.0281376  0.0278016 ]\n",
      "\n",
      "find better score:\n",
      "score:  3083.806378783867\n",
      "coeffs:  [0.02875051 0.02874994 0.02875044 0.02875073 0.02875055 0.02875049\n",
      " 0.02874933 0.02875045 0.02875039 0.02875049 0.0287517  0.02875045\n",
      " 0.02875026 0.02875047 0.02875049 0.02875047 0.02875049 0.02875047\n",
      " 0.02875047 0.02875044 0.02875058 0.02875055 0.02875043 0.02875043\n",
      " 0.02875043 0.02875048 0.02875031 0.02875044 0.02875035 0.02875036\n",
      " 0.0287504  0.02875038 0.02875001 0.02875039 0.02874996 0.02784213]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608583521\n",
      "coeffs:  [0.02835368 0.02835334 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681176\n",
      "coeffs:  [0.02835369 0.02835334 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681186\n",
      "coeffs:  [0.02835368 0.02835335 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681202\n",
      "coeffs:  [0.02835368 0.02835334 0.02835363 0.02835381 0.02835371 0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681216\n",
      "coeffs:  [0.02835368 0.02835334 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835366 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681228\n",
      "coeffs:  [0.02835368 0.02835334 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.0283534  0.0283536  0.02835335 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  4636.856608681233\n",
      "coeffs:  [0.02835368 0.02835334 0.02835363 0.02835381 0.0283537  0.02835366\n",
      " 0.02835298 0.02835364 0.0283536  0.02835367 0.02835438 0.02835364\n",
      " 0.02835353 0.02835365 0.02835366 0.02835365 0.02835367 0.02835365\n",
      " 0.02835365 0.02835364 0.02835372 0.0283537  0.02835363 0.02835363\n",
      " 0.02835363 0.02835366 0.02835356 0.02835363 0.02835358 0.02835358\n",
      " 0.02835361 0.0283536  0.02835338 0.0283536  0.02835337 0.02781588]\n",
      "\n",
      "find better score:\n",
      "score:  5910.872771224034\n",
      "coeffs:  [0.02854762 0.02854717 0.02854756 0.02854779 0.02854765 0.0285476\n",
      " 0.02854668 0.02854757 0.02854752 0.0285476  0.02854856 0.02854757\n",
      " 0.02854742 0.02854759 0.0285476  0.02854758 0.0285476  0.02854758\n",
      " 0.02854759 0.02854757 0.02854768 0.02854765 0.02854756 0.02854756\n",
      " 0.02854756 0.02854759 0.02854746 0.02854756 0.02854749 0.0285475\n",
      " 0.02854753 0.02854752 0.02854722 0.02854752 0.02854719 0.02782871]\n",
      "\n",
      "find better score:\n",
      "score:  5960.875901724788\n",
      "coeffs:  [0.0285127  0.02851227 0.02851265 0.02851287 0.02851273 0.02851269\n",
      " 0.02851181 0.02851266 0.02851261 0.02851269 0.0285136  0.02851265\n",
      " 0.02851251 0.02851267 0.02851269 0.02851267 0.02851269 0.02851267\n",
      " 0.02851267 0.02851265 0.02851276 0.02851273 0.02851264 0.02851264\n",
      " 0.02851264 0.02851268 0.02851255 0.02851265 0.02851258 0.02851258\n",
      " 0.02851262 0.0285126  0.02851232 0.02851261 0.02851229 0.0278264 ]\n",
      "\n",
      "find better score:\n",
      "score:  5966.875783495894\n",
      "coeffs:  [0.026802   0.03179273 0.02743597 0.02719494 0.02835052 0.0272997\n",
      " 0.03105699 0.03351816 0.02735048 0.02723589 0.00921347 0.03191817\n",
      " 0.03173309 0.02723093 0.02728753 0.0275139  0.02758713 0.02787973\n",
      " 0.02766317 0.02753075 0.02803388 0.0279516  0.02978994 0.02986259\n",
      " 0.02779801 0.02780044 0.02877582 0.02776329 0.02792003 0.0303649\n",
      " 0.03096257 0.03014553 0.03364435 0.0301851  0.03457021 0.01439249]\n",
      "\n",
      "find better score:\n",
      "score:  5982.876296423291\n",
      "coeffs:  [ 0.02281868  0.03263131  0.02452655  0.02925542  0.02940518  0.02476322\n",
      "  0.02215212  0.04224585  0.02403281  0.02472207 -0.02117884  0.03627919\n",
      "  0.0350082   0.02450308  0.02490381  0.02557174  0.02610722  0.02703372\n",
      "  0.02643846  0.02550698  0.02861368  0.02795256  0.03303418  0.03357716\n",
      "  0.02627288  0.02732258  0.0297262   0.02626843  0.026048    0.0344953\n",
      "  0.03809193  0.03482214  0.04434792  0.03496209  0.04726502  0.00792181]\n",
      "\n",
      "find better score:\n",
      "score:  5996.877084531567\n",
      "coeffs:  [ 0.00468602  0.02041171  0.00599066  0.04389295  0.03794112  0.01242311\n",
      "  0.06519569  0.06211165  0.01104851  0.00424001 -0.02541692  0.03039052\n",
      "  0.04310299  0.00386504  0.00506727  0.00851569  0.00896797  0.01421809\n",
      "  0.00885345  0.00294907  0.03191822  0.02855455  0.02858632  0.03817462\n",
      "  0.00541747  0.01742489  0.04816338  0.00424133  0.01076206  0.03740958\n",
      "  0.05597838  0.05213861  0.10371566  0.05208429  0.11868751 -0.02742709]\n",
      "\n",
      "find better score:\n",
      "score:  6018.877501018916\n",
      "coeffs:  [-0.01471212 -0.0328029  -0.01557014  0.06911748  0.05999392  0.00318319\n",
      "  0.04119716  0.05957987  0.00563456 -0.02225166 -0.04953085 -0.02366769\n",
      "  0.01952084 -0.02166625 -0.01978535 -0.01137119 -0.01244524 -0.00075887\n",
      " -0.01823768 -0.0333601   0.04334795  0.03495923  0.02529718  0.04841469\n",
      " -0.02822546  0.00652368  0.10043028 -0.03061692 -0.00872717  0.05178245\n",
      "  0.08507946  0.09328563  0.23497527  0.09296642  0.27309789 -0.07349511]\n",
      "\n",
      "find better score:\n",
      "score:  6021.87767462714\n",
      "coeffs:  [-2.83144694e-02  3.10767066e-03 -2.57891486e-02  6.98177909e-02\n",
      "  6.24251745e-02 -3.03996093e-04 -1.25020515e-02  9.82729393e-02\n",
      "  9.63583313e-03 -4.60189309e-02 -6.95174092e-02 -1.03815661e-02\n",
      "  5.54937811e-02 -4.25880672e-02 -4.07668705e-02 -3.02134553e-02\n",
      " -3.39580608e-02 -1.92445722e-02 -5.65872628e-02 -7.90611075e-02\n",
      "  3.57727301e-02  2.06707168e-02  1.57911310e-02  4.42691176e-02\n",
      " -7.37651917e-02 -1.37924577e-02  1.53640069e-01 -7.39912793e-02\n",
      " -3.07014571e-02  5.68917796e-02  8.94164898e-02  1.09692656e-01\n",
      "  3.45788506e-01  1.08923866e-01  4.10043181e-01 -3.48436386e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6036.878044557998\n",
      "coeffs:  [-0.00074689  0.0212752   0.01396054  0.03606807  0.04723047  0.04123628\n",
      "  0.04020174  0.06000739  0.06032472 -0.03485084 -0.14115944 -0.00238108\n",
      "  0.04004581 -0.02453561 -0.02368137 -0.01542144 -0.02041052 -0.01377952\n",
      " -0.09166369 -0.11565231  0.01084696 -0.01738915  0.00576172  0.04648227\n",
      " -0.11268209 -0.03065844  0.21955823 -0.10182193 -0.02792537  0.04601808\n",
      "  0.07053869  0.074231    0.38620901  0.07428713  0.48054734 -0.00364543]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6036.87839911947\n",
      "coeffs:  [-0.06766324 -0.03886579  0.02389715 -0.04313299  0.0924571   0.03336228\n",
      "  0.04052155  0.06844715  0.03062635 -0.02026075 -0.12388892  0.06146488\n",
      "  0.03059333  0.00888292  0.01980006  0.0183511   0.03100325  0.00088144\n",
      " -0.1578485  -0.17259135  0.04878201 -0.01797549  0.07676916  0.08297944\n",
      " -0.1862173  -0.0541503   0.28852166 -0.11100297  0.00967702  0.11740517\n",
      "  0.17176895 -0.03871072  0.32612174 -0.02829974  0.47967146 -0.02614481]\n",
      "\n",
      "find better score:\n",
      "score:  6042.878476152836\n",
      "coeffs:  [-0.0166557   0.00845916  0.03688234 -0.00887603  0.07296252  0.05668365\n",
      "  0.03277522  0.05968722  0.0691604  -0.02259758 -0.13658995  0.03439611\n",
      "  0.03662461 -0.00126161  0.00401335  0.00662339  0.00870323 -0.00439898\n",
      " -0.13403938 -0.15388776  0.02872991 -0.02124391  0.03514495  0.0610369\n",
      " -0.15964343 -0.04755943  0.27383421 -0.11541295 -0.00886308  0.07357497\n",
      "  0.10426927 -0.00828502  0.35480931 -0.00283511  0.48651836 -0.04710601]\n",
      "\n",
      "find better score:\n",
      "score:  6044.878527624517\n",
      "coeffs:  [-0.07859406  0.0128919   0.02630846  0.02130969  0.08800221  0.03381747\n",
      "  0.03435052  0.06799505  0.02346338 -0.02124416 -0.11747865  0.01109733\n",
      "  0.04112853  0.01160187  0.02578266  0.02570848  0.04573266  0.01005236\n",
      " -0.1575869  -0.17383784  0.04257462 -0.03105523  0.03536445  0.08263494\n",
      " -0.19000581 -0.04385146  0.28718806 -0.09805029  0.01126832  0.10414461\n",
      "  0.06974007 -0.01224019  0.32927253  0.00170526  0.48376381 -0.05034981]\n",
      "\n",
      "find better score:\n",
      "score:  6046.878476227509\n",
      "coeffs:  [-0.08809482  0.00908487  0.02051944  0.02155013  0.08194012  0.06815036\n",
      "  0.02514856  0.06941158  0.05838188 -0.16840362 -0.12347604 -0.00247368\n",
      "  0.06912613 -0.03720853  0.09775803  0.02740937  0.24383176 -0.01001368\n",
      " -0.35502728 -0.3035392   0.18323497 -0.18499692 -0.04219859  0.09419604\n",
      " -0.42372327  0.22463367  0.32752653  0.15315236  0.01364751  0.16266998\n",
      "  0.07686444 -0.03877854  0.17407562  0.0277942   0.5509342  -0.05250361]\n",
      "\n",
      "find better score:\n",
      "score:  6050.878474894914\n",
      "coeffs:  [-0.08956177  0.00917325  0.02204516  0.01707816  0.08152836  0.0665752\n",
      "  0.02465745  0.06796494  0.05996038 -0.17527768 -0.12221368  0.00415696\n",
      "  0.06370643 -0.03980874  0.10371711  0.02555135  0.25221294 -0.01405323\n",
      " -0.36743206 -0.3100077   0.19057074 -0.19358842 -0.0382702   0.0935024\n",
      " -0.43349336  0.2398526   0.32807534  0.16854553  0.01273786  0.16238549\n",
      "  0.07524559 -0.03947532  0.17266624  0.02971253  0.55471084 -0.05317644]\n",
      "\n",
      "find better score:\n",
      "score:  6050.878492129573\n",
      "coeffs:  [-9.33757297e-02  8.99813932e-03  4.85636765e-02  1.59993683e-02\n",
      "  8.32687202e-02  3.42596623e-02  2.32461672e-02  6.13082829e-02\n",
      "  4.35687131e-02 -1.99133208e-01 -1.21662279e-01  2.02311968e-02\n",
      "  5.74159996e-02 -6.09723504e-02  1.87921876e-01  3.82689474e-04\n",
      "  2.75720733e-01 -6.40496725e-02 -4.94026601e-01 -3.73328749e-01\n",
      "  2.30043654e-01 -2.24449080e-01 -1.23934958e-02  1.05333486e-01\n",
      " -4.18366373e-01  3.50197000e-01  3.18909870e-01  2.85533074e-01\n",
      " -1.94656666e-03  1.20399897e-01  7.03806099e-02 -5.33094925e-02\n",
      "  2.27470619e-01  3.55162470e-02  5.15612905e-01 -5.50297201e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6050.878495714934\n",
      "coeffs:  [-0.0946092   0.01034868  0.03793225  0.01485486  0.08387639  0.0455369\n",
      "  0.02362158  0.06047891  0.04475146 -0.19578207 -0.12169586  0.020217\n",
      "  0.05618416 -0.09357698  0.22567581  0.01473074  0.24957054 -0.05884878\n",
      " -0.5794294  -0.41484568  0.21043028 -0.20400145 -0.01472497  0.10238917\n",
      " -0.33856195  0.39014387  0.31895848  0.28419928  0.00099125  0.12679102\n",
      "  0.0700981  -0.05263208  0.22029497  0.03811243  0.52177615 -0.0548234 ]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.5296192548569031, -0.9371895353230894, -0.937782584245267, 1.5051239908388594, 0.2682545889816639, -0.39513019292116663, 2.1560102662949943, -0.5300149607758173, -0.11841795479293817, 0.6991482453445154, -0.3971180916176833, 0.37286582385556805, 0.13391331805604773, -1.9326251679873185, -0.24907812605901813, -0.2716424211126901, -1.8998021279247215, 1.365622108378165, -1.086939526750787, -0.9598221340588567, -0.7083807506098937, 0.21266001611492552, 0.8025648990432044, -0.16037162248885828, 1.2713160985178509, -2.406032723460554, 0.7754076992366479, 0.18801960053065064, -1.5337913123936417, 0.4017279998915864, 0.16850958447984776, -1.7180723072432242, 0.0219262271160703, -1.64892186807067, -0.35597841400212404, 1.615729922206366]\n",
      "\n",
      "Optimizing with init x0: [-0.6560746872140686, -1.4173482932309656, 1.4794494243477476, 0.25591375080612583, 0.7038560308999772, -0.5565574074534013, 0.5100507029745771, -0.2240835057924097, 1.0328947357163731, -0.008306746392539123, -1.0858969241226193, -2.1207517976822623, 1.364414329275553, 0.4015151070764874, -0.9467542825185143, -0.11154726318185514, -0.4998855757058944, 1.7548870911465977, -0.08360714053642626, -0.06128584503729062, 1.3210019040263408, 0.8313144564480371, -0.628292871357325, -0.3501719398613541, 0.6572554112968994, -0.907765961049757, 2.2729699327217032, -0.09385002893027099, -0.9530668800313302, -0.7162776612773664, -0.45734275042271655, -1.2700350387494155, -0.5336701025982332, 2.6462560326202667, 0.49391812898615867, -0.5613339166047955]\n",
      "\n",
      "Optimizing with init x0: [-0.8644040483406713, -0.8669116937180812, 1.693736693854256, -1.5674186258275007, -0.5454646784055298, -1.7629005037795766, -0.895468309291871, -0.30808098942640877, 0.29568795685247073, 1.6243878492773247, 0.0018291811617487698, 0.7190074791083579, 1.1520700040085974, 0.9820085881037531, -1.5576013874422114, -0.08086651559742739, -0.20849516037487592, -0.07281482384483809, -0.02153637675618588, -0.11836434863383825, 0.0004258517890321917, 1.6847162195856853, -1.6235001560096134, 0.5243051270580185, 1.2641530061107218, 0.05250135150160492, 2.113053918114015, 1.0135217509673264, -0.21493488389305365, -0.7887268355068469, 1.250857344954365, 0.36521343515501814, -1.0926689365013171, -0.7307134993181232, 0.6103576394705963, -2.4421305388542516]\n",
      "\n",
      "Optimizing with init x0: [0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776, 0.027777777777777776]\n",
      "\n",
      "find better score:\n",
      "score:  328.6664628568694\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  328.66646299990947\n",
      "coeffs:  [0.02777779 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  328.66646299991004\n",
      "coeffs:  [0.02777778 0.02777778 0.02777779 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  328.666462999917\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777779 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  328.66646299992345\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777779 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  328.6664629999635\n",
      "coeffs:  [0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777779 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778\n",
      " 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778 0.02777778]\n",
      "\n",
      "find better score:\n",
      "score:  681.6225838643962\n",
      "coeffs:  [0.02905484 0.02905409 0.0290548  0.02905528 0.02905486 0.02905478\n",
      " 0.02905312 0.02905472 0.02905483 0.02905481 0.02905696 0.02905492\n",
      " 0.02905472 0.0290548  0.02905482 0.02905478 0.02905483 0.0290548\n",
      " 0.02905477 0.02905476 0.02905485 0.02905483 0.02905478 0.02905459\n",
      " 0.02905471 0.02905481 0.0290546  0.02905474 0.02905467 0.02905468\n",
      " 0.02905454 0.02905457 0.02905408 0.02905458 0.02905403 0.02786232]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949960550704\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961984757\n",
      "coeffs:  [0.02814996 0.02814973 0.02814994 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961984773\n",
      "coeffs:  [0.02814995 0.02814973 0.02814995 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961984784\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815009 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961984887\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815008 0.02814997 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961985069\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814993 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814971 0.02780242]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  1667.7949961985112\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814974 0.02814987 0.02814971 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  1667.7949961985141\n",
      "coeffs:  [0.02814995 0.02814973 0.02814994 0.02815008 0.02814995 0.02814993\n",
      " 0.02814945 0.02814991 0.02814994 0.02814994 0.02815057 0.02814997\n",
      " 0.02814991 0.02814994 0.02814994 0.02814993 0.02814994 0.02814993\n",
      " 0.02814992 0.02814992 0.02814995 0.02814994 0.02814993 0.02814987\n",
      " 0.02814991 0.02814994 0.02814988 0.02814992 0.0281499  0.0281499\n",
      " 0.02814986 0.02814987 0.02814973 0.02814987 0.02814973 0.02780242]\n",
      "\n",
      "find better score:\n",
      "score:  2816.7953651015832\n",
      "coeffs:  [0.02877091 0.02877032 0.02877087 0.02877125 0.02877092 0.02877086\n",
      " 0.02876957 0.02877081 0.0287709  0.02877088 0.02877255 0.02877096\n",
      " 0.02877081 0.02877087 0.02877088 0.02877086 0.0287709  0.02877087\n",
      " 0.02877085 0.02877084 0.02877091 0.02877089 0.02877086 0.02877071\n",
      " 0.0287708  0.02877088 0.02877071 0.02877083 0.02877077 0.02877078\n",
      " 0.02877067 0.02877069 0.02877031 0.0287707  0.02877028 0.02784352]\n",
      "\n",
      "find better score:\n",
      "score:  5132.86224634021\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422105\n",
      "coeffs:  [0.02838666 0.02838628 0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422108\n",
      "coeffs:  [0.02838664 0.0283863  0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422109\n",
      "coeffs:  [0.02838664 0.02838628 0.02838664 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422112\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838687 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422127\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838685 0.02838667 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422141\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.0283866  0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422161\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838629 0.02838652 0.02838625 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5132.862246422166\n",
      "coeffs:  [0.02838664 0.02838628 0.02838662 0.02838685 0.02838665 0.02838661\n",
      " 0.02838582 0.02838658 0.02838664 0.02838663 0.02838765 0.02838668\n",
      " 0.02838658 0.02838662 0.02838663 0.02838661 0.02838664 0.02838662\n",
      " 0.0283866  0.0283866  0.02838664 0.02838663 0.02838661 0.02838652\n",
      " 0.02838658 0.02838663 0.02838652 0.02838659 0.02838656 0.02838656\n",
      " 0.0283865  0.02838651 0.02838628 0.02838652 0.02838627 0.02781808]\n",
      "\n",
      "find better score:\n",
      "score:  5824.868288368743\n",
      "coeffs:  [0.0285664  0.02856594 0.02856637 0.02856667 0.02856641 0.02856636\n",
      " 0.02856534 0.02856632 0.02856639 0.02856638 0.02856771 0.02856644\n",
      " 0.02856632 0.02856637 0.02856638 0.02856636 0.02856639 0.02856637\n",
      " 0.02856635 0.02856635 0.0285664  0.02856639 0.02856636 0.02856624\n",
      " 0.02856632 0.02856638 0.02856625 0.02856634 0.02856629 0.0285663\n",
      " 0.02856621 0.02856623 0.02856593 0.02856624 0.0285659  0.02782998]\n",
      "\n",
      "find better score:\n",
      "score:  5940.8743769134735\n",
      "coeffs:  [0.02851526 0.02851483 0.02851524 0.02851552 0.02851527 0.02851523\n",
      " 0.02851427 0.02851519 0.02851526 0.02851525 0.02851649 0.02851531\n",
      " 0.02851519 0.02851524 0.02851525 0.02851523 0.02851526 0.02851524\n",
      " 0.02851522 0.02851522 0.02851527 0.02851525 0.02851523 0.02851512\n",
      " 0.02851519 0.02851525 0.02851512 0.0285152  0.02851516 0.02851517\n",
      " 0.02851509 0.02851511 0.02851482 0.02851511 0.0285148  0.0278266 ]\n",
      "\n",
      "find better score:\n",
      "score:  5942.874200023846\n",
      "coeffs:  [0.02631852 0.03054261 0.02677947 0.02637384 0.02821663 0.02671481\n",
      " 0.03088856 0.03379101 0.02651729 0.02662595 0.01042035 0.02880447\n",
      " 0.03079096 0.0266228  0.02660686 0.02701584 0.02722724 0.02751574\n",
      " 0.02800367 0.02743276 0.02741907 0.02726677 0.03020965 0.03106549\n",
      " 0.02805726 0.02819986 0.02870898 0.02763289 0.02723194 0.0311692\n",
      " 0.03012366 0.03257164 0.03624666 0.03270117 0.0375575  0.01206295]\n",
      "\n",
      "find better score:\n",
      "score:  5954.874656693824\n",
      "coeffs:  [ 0.02177525  0.02991452  0.02281713  0.02626788  0.02630399  0.02279348\n",
      "  0.02315325  0.04277007  0.02278531  0.02289006 -0.00812075  0.02863984\n",
      "  0.03392898  0.02280943  0.02287328  0.02398757  0.02491961  0.02565118\n",
      "  0.02737256  0.02534159  0.023461    0.02271721  0.03447983  0.03594857\n",
      "  0.02702841  0.02861615  0.0293561   0.02573862  0.02399621  0.03718964\n",
      "  0.03374864  0.04129759  0.05089838  0.04166498  0.05495646  0.00197805]\n",
      "\n",
      "find better score:\n",
      "score:  5970.8749990742035\n",
      "coeffs:  [ 0.00628721  0.03437902  0.00698947  0.02708754  0.0221796   0.00803102\n",
      "  0.04968644  0.07265584  0.00856272  0.00503266 -0.0013664   0.03370014\n",
      "  0.04839795  0.00527194  0.0057938   0.00971578  0.01207974  0.01441091\n",
      "  0.01674861  0.00941889  0.00827341  0.00539795  0.03389525  0.04359455\n",
      "  0.01434468  0.02302195  0.03282848  0.01021165  0.00619778  0.04379739\n",
      "  0.03923055  0.06279754  0.10203577  0.06355607  0.11652735 -0.01128684]\n",
      "\n",
      "find better score:\n",
      "score:  5990.875507042472\n",
      "coeffs:  [-0.00782852 -0.00703771 -0.00953481  0.02609077  0.04002568 -0.0063261\n",
      "  0.06575173  0.07140671 -0.00398211 -0.01639121  0.00735092 -0.00704204\n",
      "  0.02292629 -0.01545589 -0.01356081 -0.00478237 -0.00042182  0.00366278\n",
      "  0.00352401 -0.01234924  0.00186256 -0.00397095  0.03097855  0.06086059\n",
      " -0.00162004  0.01910046  0.04852158 -0.01028228 -0.01915344  0.0539935\n",
      "  0.05115306  0.10004342  0.19909031  0.10125959  0.23366855 -0.02328569]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5992.876054761915\n",
      "coeffs:  [ 0.00237776  0.06908767  0.00724482 -0.00299515  0.14690868  0.00724921\n",
      "  0.03758432  0.09643066  0.01638221 -0.03911983 -0.10174127 -0.01633991\n",
      "  0.01239314 -0.0331325  -0.03097867 -0.0165311  -0.00250283 -0.01036239\n",
      " -0.05014687 -0.07689048  0.02873163  0.01166795 -0.0230086   0.06238244\n",
      " -0.06046433 -0.007651    0.08260714 -0.06300086 -0.07947559  0.01846938\n",
      "  0.07063867  0.09337039  0.32529622  0.09624613  0.42529611  0.06042836]\n",
      "\n",
      "find better score:\n",
      "score:  5993.8760838294575\n",
      "coeffs:  [-0.0033572   0.02631249 -0.00218373  0.01334835  0.08685065 -0.00037882\n",
      "  0.05341171  0.08236959  0.00493941 -0.02634852 -0.04044189 -0.0111154\n",
      "  0.01831176 -0.02319993 -0.0211915  -0.00992943 -0.0013335  -0.00248158\n",
      " -0.01998897 -0.04062447  0.01363378  0.00288038  0.00732702  0.06152731\n",
      " -0.02739946  0.00738076  0.06345431 -0.03337806 -0.04558031  0.03843054\n",
      "  0.05968962  0.09712     0.25438056  0.09906321  0.31761974  0.01338907]\n",
      "\n",
      "find better score:\n",
      "score:  6000.8763727951\n",
      "coeffs:  [ 0.01904245  0.05964719  0.02264169  0.0006474   0.09518723  0.02292912\n",
      "  0.02592098  0.08319929  0.02800949 -0.02090941 -0.05712559 -0.01559698\n",
      "  0.00396823 -0.01422892 -0.01292468 -0.00104096  0.01562275  0.00153464\n",
      " -0.0440667  -0.06933124 -0.0239202  -0.04399074 -0.00830182  0.06967492\n",
      " -0.05361847  0.0009838   0.10866599 -0.04974763 -0.05821324  0.02795433\n",
      "  0.07108649  0.06465726  0.28989958  0.06773158  0.39588155 -0.03074205]\n",
      "\n",
      "find better score:\n",
      "score:  6000.876538110953\n",
      "coeffs:  [ 0.02466231  0.04422778  0.02850707 -0.00603816  0.1120794   0.02829598\n",
      "  0.05536045  0.08469452  0.02845245 -0.01855683 -0.07885121 -0.01652315\n",
      "  0.00077663 -0.01024931 -0.00936913  0.00267531  0.02501892  0.00211659\n",
      " -0.05576907 -0.08154474 -0.03097593 -0.05556524  0.00466151  0.08120775\n",
      " -0.06642126 -0.00097443  0.13233836 -0.0544719  -0.05962145  0.03912575\n",
      "  0.0743758   0.03623154  0.28717511  0.04048529  0.41496287 -0.04161259]\n",
      "\n",
      "find better score:\n",
      "score:  6017.876676475643\n",
      "coeffs:  [ 1.26268320e-02  1.02758401e-02  2.07214972e-02 -6.42728363e-03\n",
      "  1.44533314e-01  1.78282009e-02  2.54676403e-02  1.13812735e-01\n",
      "  1.55655611e-03 -2.12711632e-02 -8.39370547e-02 -9.62970246e-03\n",
      "  2.70987508e-02 -1.13088170e-02 -1.02454568e-02  2.23142851e-03\n",
      "  3.77536004e-02 -4.87550178e-03 -7.49651622e-02 -1.02390950e-01\n",
      " -3.95989119e-02 -7.10077824e-02  4.49134796e-02  1.10231727e-01\n",
      " -8.86208344e-02 -2.94475845e-04  1.79118751e-01 -5.90314862e-02\n",
      " -5.78284316e-02  7.53858948e-02  7.92334119e-02 -3.72278786e-03\n",
      "  2.86418601e-01  4.01664078e-03  4.54578861e-01 -4.44847854e-02]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.5296192548569031, -0.9371895353230894, -0.937782584245267, 1.5051239908388594, 0.2682545889816639, -0.39513019292116663, 2.1560102662949943, -0.5300149607758173, -0.11841795479293817, 0.6991482453445154, -0.3971180916176833, 0.37286582385556805, 0.13391331805604773, -1.9326251679873185, -0.24907812605901813, -0.2716424211126901, -1.8998021279247215, 1.365622108378165, -1.086939526750787, -0.9598221340588567, -0.7083807506098937, 0.21266001611492552, 0.8025648990432044, -0.16037162248885828, 1.2713160985178509, -2.406032723460554, 0.7754076992366479, 0.18801960053065064, -1.5337913123936417, 0.4017279998915864, 0.16850958447984776, -1.7180723072432242, 0.0219262271160703, -1.64892186807067, -0.35597841400212404, 1.615729922206366]\n",
      "\n",
      "Optimizing with init x0: [-0.6560746872140686, -1.4173482932309656, 1.4794494243477476, 0.25591375080612583, 0.7038560308999772, -0.5565574074534013, 0.5100507029745771, -0.2240835057924097, 1.0328947357163731, -0.008306746392539123, -1.0858969241226193, -2.1207517976822623, 1.364414329275553, 0.4015151070764874, -0.9467542825185143, -0.11154726318185514, -0.4998855757058944, 1.7548870911465977, -0.08360714053642626, -0.06128584503729062, 1.3210019040263408, 0.8313144564480371, -0.628292871357325, -0.3501719398613541, 0.6572554112968994, -0.907765961049757, 2.2729699327217032, -0.09385002893027099, -0.9530668800313302, -0.7162776612773664, -0.45734275042271655, -1.2700350387494155, -0.5336701025982332, 2.6462560326202667, 0.49391812898615867, -0.5613339166047955]\n",
      "\n",
      "Optimizing with init x0: [-0.8644040483406713, -0.8669116937180812, 1.693736693854256, -1.5674186258275007, -0.5454646784055298, -1.7629005037795766, -0.895468309291871, -0.30808098942640877, 0.29568795685247073, 1.6243878492773247, 0.0018291811617487698, 0.7190074791083579, 1.1520700040085974, 0.9820085881037531, -1.5576013874422114, -0.08086651559742739, -0.20849516037487592, -0.07281482384483809, -0.02153637675618588, -0.11836434863383825, 0.0004258517890321917, 1.6847162195856853, -1.6235001560096134, 0.5243051270580185, 1.2641530061107218, 0.05250135150160492, 2.113053918114015, 1.0135217509673264, -0.21493488389305365, -0.7887268355068469, 1.250857344954365, 0.36521343515501814, -1.0926689365013171, -0.7307134993181232, 0.6103576394705963, -2.4421305388542516]\n",
      "\n",
      "CV score ?: 6021.544701053256; [5996.875216461185, 6006.877881353618, 6060.881005344965]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "cv = cv.reset_index(drop=True)\n",
    "#cv = cv.head(100)\n",
    "\n",
    "score_list = []\n",
    "\n",
    "kf = KFold(shuffle= True)\n",
    "for idx_train, idx_val in kf.split(cv):\n",
    "\n",
    "    best_score = {}\n",
    "    best_coeffs = {}\n",
    "    cv_train = cv.loc[idx_train].reset_index(drop=True)    \n",
    "    cv_val = cv.loc[idx_val].reset_index(drop=True)    \n",
    "\n",
    "    for metric in ['smooth']:\n",
    "    #for metric in ['mape', 'mae', 'mse']:\n",
    "        best_score[metric] = 0\n",
    "        best_coeffs[metric] = []\n",
    "        for x0 in x0s:\n",
    "            print('Optimizing with init x0: {}'.format(x0))\n",
    "            print()\n",
    "            minimize(objective, x0, args=(cv_train, metric, best_score, best_coeffs, True), \n",
    "                     tol=1e-4)\n",
    "    \n",
    "    val_pred_final = cv_val.loc[:, cols_opt].dot(best_coeffs['smooth'])\n",
    "    if is_per_area:\n",
    "        val_pred_final = np.expm1(val_pred_final) * cv_val['building_area']\n",
    "    else:\n",
    "        val_pred_final = np.expm1(val_pred_final)\n",
    "    score = cal_score(cv_val['total_price'], val_pred_final)\n",
    "    \n",
    "    score_list.append(score)\n",
    "\n",
    "print('CV score ?: {}; {}'.format(np.mean(score_list), score_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703, 0.02702702702702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387541056735\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.6738755546903\n",
      "coeffs:  [0.02702704 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469065\n",
      "coeffs:  [0.02702703 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469264\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702704 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555469867\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.67387555470145\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702704 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  340.673875554738\n",
      "coeffs:  [0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702704 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703 0.02702703\n",
      " 0.02702703]\n",
      "\n",
      "find better score:\n",
      "score:  522.5809388284329\n",
      "coeffs:  [0.02830779 0.02830702 0.02830772 0.02830803 0.02830776 0.02830776\n",
      " 0.02830626 0.02830745 0.02830771 0.02830775 0.02830971 0.02830769\n",
      " 0.02830742 0.02830773 0.02830775 0.02830773 0.02830776 0.02830773\n",
      " 0.02830772 0.0283077  0.02830778 0.02830776 0.02830771 0.02830765\n",
      " 0.02830768 0.02830775 0.02830755 0.0283077  0.02830762 0.02830761\n",
      " 0.0283076  0.02830757 0.02830716 0.02830758 0.02830711 0.02830697\n",
      " 0.02711176]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979585209\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979709006\n",
      "coeffs:  [0.02749135 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.8359797090097\n",
      "coeffs:  [0.02749134 0.02749105 0.02749132 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979709026\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749134 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979709032\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749122 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979709034\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749127 0.02749111 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.83597970905\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749112 0.02749126 0.02749109 0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.8359797090543\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.0274911  0.02749103\n",
      " 0.02705774]\n",
      "\n",
      "find better score:\n",
      "score:  3082.835979709061\n",
      "coeffs:  [0.02749134 0.02749105 0.02749131 0.02749142 0.02749132 0.02749132\n",
      " 0.02749078 0.02749121 0.0274913  0.02749132 0.02749203 0.0274913\n",
      " 0.0274912  0.02749131 0.02749132 0.02749131 0.02749132 0.02749131\n",
      " 0.02749131 0.0274913  0.02749133 0.02749132 0.0274913  0.02749128\n",
      " 0.02749129 0.02749132 0.02749125 0.0274913  0.02749127 0.02749127\n",
      " 0.02749126 0.02749125 0.02749111 0.02749126 0.02749109 0.02749105\n",
      " 0.02705774]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5819.874426562521\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.874426597038\n",
      "coeffs:  [0.02767384 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.8744265970545\n",
      "coeffs:  [0.02767382 0.02767345 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.874426597062\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767382 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.874426597072\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767366 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.874426597094\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.02767352 0.02767372 0.02767348 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.8744265971\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767349 0.0276734\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5819.874426597107\n",
      "coeffs:  [0.02767382 0.02767343 0.02767379 0.02767394 0.02767381 0.02767381\n",
      " 0.02767305 0.02767365 0.02767378 0.0276738  0.02767479 0.02767377\n",
      " 0.02767363 0.02767379 0.0276738  0.02767379 0.0276738  0.02767379\n",
      " 0.02767379 0.02767378 0.02767382 0.0276738  0.02767378 0.02767375\n",
      " 0.02767377 0.0276738  0.0276737  0.02767377 0.02767374 0.02767373\n",
      " 0.02767372 0.02767371 0.0276735  0.02767372 0.02767348 0.02767342\n",
      " 0.02706982]\n",
      "\n",
      "find better score:\n",
      "score:  5940.87605415982\n",
      "coeffs:  [0.02770869 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770833 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054162936\n",
      "coeffs:  [0.02770871 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770833 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054162963\n",
      "coeffs:  [0.02770869 0.0277083  0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770833 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054162971\n",
      "coeffs:  [0.02770869 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770852 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770833 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054162993\n",
      "coeffs:  [0.02770869 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770837 0.02770858 0.02770833 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054163\n",
      "coeffs:  [0.02770869 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770835 0.02770825\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5940.876054163006\n",
      "coeffs:  [0.02770869 0.02770828 0.02770866 0.02770882 0.02770868 0.02770868\n",
      " 0.02770788 0.02770851 0.02770865 0.02770867 0.02770971 0.02770864\n",
      " 0.02770849 0.02770866 0.02770867 0.02770866 0.02770867 0.02770866\n",
      " 0.02770866 0.02770865 0.02770869 0.02770867 0.02770865 0.02770862\n",
      " 0.02770863 0.02770867 0.02770856 0.02770864 0.0277086  0.0277086\n",
      " 0.02770859 0.02770858 0.02770836 0.02770858 0.02770833 0.02770827\n",
      " 0.02707212]\n",
      "\n",
      "find better score:\n",
      "score:  5960.875940906153\n",
      "coeffs:  [0.02772119 0.02772077 0.02772115 0.02772132 0.02772117 0.02772117\n",
      " 0.02772036 0.027721   0.02772114 0.02772116 0.02772223 0.02772113\n",
      " 0.02772099 0.02772115 0.02772117 0.02772115 0.02772117 0.02772116\n",
      " 0.02772115 0.02772114 0.02772118 0.02772117 0.02772114 0.02772111\n",
      " 0.02772113 0.02772117 0.02772106 0.02772114 0.0277211  0.02772109\n",
      " 0.02772108 0.02772107 0.02772085 0.02772107 0.02772082 0.02772074\n",
      " 0.02707295]\n",
      "\n",
      "find better score:\n",
      "score:  5974.875905674017\n",
      "coeffs:  [ 0.02068077  0.03387414  0.02194612  0.02405594  0.02674972  0.02202233\n",
      "  0.02627498  0.0431836   0.02153001  0.0220358  -0.01905864  0.03392963\n",
      "  0.0360827   0.02180888  0.02219631  0.02303925  0.02379971  0.02438032\n",
      "  0.02458903  0.02336562  0.02457852  0.02413343  0.03296649  0.03235592\n",
      "  0.0244682   0.02545816  0.02719903  0.02375659  0.02324251  0.03479081\n",
      "  0.03402391  0.03590371  0.0457613   0.03608959  0.0494511   0.04939034\n",
      "  0.00301136]\n",
      "\n",
      "find better score:\n",
      "score:  5988.876508070219\n",
      "coeffs:  [ 0.00584794  0.02711579  0.00789788  0.02456156  0.03855087  0.00957681\n",
      "  0.05846023  0.06180843  0.00882049  0.00587987 -0.01226515  0.03306584\n",
      "  0.04592578  0.00557065  0.00676693  0.00936596  0.01082065  0.0129097\n",
      "  0.01078057  0.00570756  0.02739059  0.02570094  0.028675    0.03346074\n",
      "  0.0089363   0.01628159  0.03245765  0.00610348  0.00797036  0.0360258\n",
      "  0.03840926  0.04566493  0.08052491  0.04583543  0.09389868  0.0966429\n",
      " -0.0153339 ]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  6010.877197853795\n",
      "coeffs:  [-0.00933461 -0.02197229 -0.00725128  0.02351482  0.06599009 -0.00174739\n",
      "  0.0662644   0.05620947 -0.00221402 -0.01327564 -0.01159589 -0.0118477\n",
      "  0.02526846 -0.01341481 -0.01089919 -0.00575708 -0.00357147 -0.0003146\n",
      " -0.00928374 -0.02034106  0.03666956  0.03299503  0.02189823  0.03727274\n",
      " -0.01394065  0.00536537  0.05422351 -0.01993302 -0.01224783  0.04012203\n",
      "  0.05120486  0.06770538  0.15455895  0.06795483  0.18721598  0.19813321\n",
      " -0.05482642]\n",
      "\n",
      "find better score:\n",
      "score:  6023.877521916309\n",
      "coeffs:  [-0.00344963  0.02580841  0.00411028  0.00139227  0.07259131  0.00993321\n",
      "  0.00307635  0.0834301   0.00935574 -0.02590438 -0.04302406 -0.00770181\n",
      "  0.05948654 -0.02295633 -0.02060708 -0.0159376  -0.0123862  -0.01663967\n",
      " -0.05851587 -0.07303702  0.00807785 -0.00194616  0.00580287  0.02535272\n",
      " -0.06862088 -0.02407445  0.11338234 -0.06911248 -0.03681984  0.02990351\n",
      "  0.07137194  0.04553101  0.22825239  0.04673649  0.30840049  0.34849565\n",
      "  0.0041853 ]\n",
      "\n",
      "find better score:\n",
      "score:  6033.87817164538\n",
      "coeffs:  [ 0.02468727  0.03880763  0.0398729  -0.01371119  0.07951523  0.04375085\n",
      "  0.04749371  0.06523833  0.03694821 -0.01656724 -0.11368265 -0.01331878\n",
      "  0.05129387 -0.00990472 -0.0074583  -0.00371535  0.00290122 -0.01176316\n",
      " -0.09274336 -0.10620822 -0.01544326 -0.03337702  0.01641287  0.03069338\n",
      " -0.1056086  -0.04205254  0.17198061 -0.09565263 -0.03873255  0.03463567\n",
      "  0.08550622 -0.01943839  0.21956753 -0.01647025  0.34606966  0.42069322\n",
      " -0.00590837]\n",
      "\n",
      "find better score:\n",
      "score:  6035.878384534764\n",
      "coeffs:  [ 0.02138204  0.03911952  0.04462976 -0.01398296  0.09365183  0.04627472\n",
      "  0.01763746  0.08044168  0.03131736 -0.01544663 -0.10406353 -0.00229982\n",
      "  0.05532592 -0.00711821 -0.0031672   0.00158742  0.01116739 -0.00824207\n",
      " -0.10219993 -0.11432197 -0.01511865 -0.03582247  0.03482471  0.04391422\n",
      " -0.11698666 -0.04533114  0.19354821 -0.09915981 -0.03305268  0.05042393\n",
      "  0.08159484 -0.05115989  0.19325091 -0.04617239  0.34038843  0.436546\n",
      " -0.05644135]\n",
      "\n",
      "find better score:\n",
      "score:  6035.878565144022\n",
      "coeffs:  [-0.03663746 -0.00558814  0.05234679 -0.00242329  0.13565653  0.0271532\n",
      "  0.03236155  0.08460785 -0.0470431  -0.02315086 -0.10694381 -0.01629455\n",
      "  0.05987824 -0.01614878  0.01896457  0.02861913  0.09262869  0.00932727\n",
      " -0.1349504  -0.12401214 -0.02018271 -0.0605421   0.03819012  0.09524453\n",
      " -0.17381618 -0.02896339  0.23652049 -0.05621358 -0.00186816  0.07079291\n",
      "  0.0937457  -0.07073108  0.02107819 -0.0438219   0.31626194  0.55868313\n",
      " -0.04636873]\n",
      "\n",
      "find better score:\n",
      "score:  6042.878607038693\n",
      "coeffs:  [-4.88186936e-02  2.21841906e-02  6.63475143e-02  2.91689669e-02\n",
      "  1.57795908e-01  3.68964686e-02  2.88054265e-02  6.12203324e-02\n",
      " -4.70723056e-02 -5.59285248e-02 -1.12825037e-01  1.42153171e-02\n",
      "  2.57005182e-02 -5.46504058e-02  2.25655286e-02  3.45057504e-02\n",
      "  1.65922628e-01 -7.15294813e-03 -1.79294253e-01 -1.43451810e-01\n",
      " -1.52426816e-02 -8.34007416e-02  3.40803092e-02  9.07880101e-02\n",
      " -2.54743822e-01  9.02667266e-04  2.57189450e-01 -1.78528118e-02\n",
      "  2.68918488e-03  8.21631297e-02  6.54907269e-02 -5.56141792e-02\n",
      " -1.24526310e-01  5.93575149e-04  3.66153524e-01  6.38168342e-01\n",
      " -4.99756139e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6042.878613462154\n",
      "coeffs:  [-0.0524882   0.024106    0.06353172  0.02458144  0.15892975  0.03537759\n",
      "  0.02847065  0.0618586  -0.04806016 -0.05831084 -0.11361453  0.01170258\n",
      "  0.02715652 -0.05744165  0.02318001  0.03506049  0.17207544 -0.00876993\n",
      " -0.18101347 -0.14285931 -0.01417624 -0.08457739  0.0331981   0.09134879\n",
      " -0.25925776  0.00552893  0.260057   -0.01296558  0.00468303  0.08175179\n",
      "  0.0686295  -0.05456703 -0.13486364  0.0042355   0.37018686  0.64024982\n",
      " -0.04939041]\n",
      "\n",
      "find better score:\n",
      "score:  6043.878616774792\n",
      "coeffs:  [-0.05893764  0.02595797  0.05540198  0.0041691   0.15448776  0.03696148\n",
      "  0.0290735   0.06653927 -0.042405   -0.07624254 -0.10967498 -0.00507248\n",
      "  0.03594532 -0.08021686  0.02930659  0.03799136  0.21657838 -0.02449366\n",
      " -0.19906868 -0.14253815 -0.00482383 -0.09169916  0.04067805  0.0933233\n",
      " -0.29800591  0.03442043  0.25596014  0.02151329  0.00434354  0.0807269\n",
      "  0.09194469 -0.05858699 -0.187267    0.02437996  0.41326998  0.62873361\n",
      " -0.04538924]\n",
      "\n",
      "find better score:\n",
      "score:  6044.878616990787\n",
      "coeffs:  [-7.10031081e-02  1.58000676e-02  4.58131637e-02 -2.26612566e-02\n",
      "  1.54422387e-01  3.79200776e-02  2.86088842e-02  7.09558794e-02\n",
      " -3.68344011e-02 -9.46389426e-02 -1.09875661e-01  2.31694196e-04\n",
      "  4.25648843e-02 -1.07193297e-01  4.57065515e-02  4.85340585e-02\n",
      "  2.88490132e-01 -4.23758004e-02 -2.23239799e-01 -1.41151977e-01\n",
      "  7.53696643e-03 -1.04736889e-01  3.74191404e-02  8.71066725e-02\n",
      " -3.52524788e-01  7.99236061e-02  2.54805220e-01  7.22079557e-02\n",
      "  6.63525956e-03  6.89317065e-02  8.28849879e-02 -6.53311002e-02\n",
      " -2.58606332e-01  5.32836428e-02  4.71551907e-01  6.31421910e-01\n",
      " -4.41483536e-02]\n",
      "\n",
      "find better score:\n",
      "score:  6045.878611707158\n",
      "coeffs:  [-0.07282228  0.02008308  0.0461741  -0.01621523  0.1543704   0.03827972\n",
      "  0.0289753   0.07379103 -0.03568927 -0.10061197 -0.11126392 -0.01409478\n",
      "  0.04882354 -0.11581199  0.04832547  0.04948328  0.30430165 -0.04827248\n",
      " -0.22997581 -0.14246238  0.01075926 -0.10807611  0.0421199   0.08794625\n",
      " -0.36641364  0.09045333  0.25343184  0.08300721  0.00494831  0.0720425\n",
      "  0.07503543 -0.06917991 -0.27192212  0.05899939  0.48334423  0.63058597\n",
      " -0.04233351]\n",
      "\n",
      "find better score:\n",
      "score:  6047.878608407742\n",
      "coeffs:  [-0.06852522  0.02044844  0.05243643 -0.00795022  0.1505716   0.03850048\n",
      "  0.02807027  0.06789352 -0.0343771  -0.10617874 -0.11028637 -0.01050397\n",
      "  0.04814026 -0.1249931   0.04837941  0.04597025  0.30899182 -0.0572742\n",
      " -0.23194227 -0.14329002  0.01388835 -0.10917628  0.04380777  0.09515867\n",
      " -0.37133217  0.09955958  0.24996465  0.08888498 -0.00076342  0.07446093\n",
      "  0.07598748 -0.07873479 -0.26064656  0.05841662  0.48397695  0.62498558\n",
      " -0.04303115]\n",
      "\n",
      "find better score:\n",
      "score:  6049.878578385548\n",
      "coeffs:  [-0.06887029  0.01712952  0.05583676 -0.00222688  0.1448646   0.0241899\n",
      "  0.02787887  0.06669912 -0.02725706 -0.13427289 -0.11039605 -0.00356558\n",
      "  0.04472079 -0.17873285  0.08146721  0.0451009   0.39914956 -0.11224774\n",
      " -0.26307343 -0.14881589  0.03666546 -0.12780421  0.0429362   0.10105086\n",
      " -0.43583827  0.18341544  0.24328671  0.15726689 -0.01706588  0.06885901\n",
      "  0.07173699 -0.12725102 -0.26339283  0.08962183  0.50157092  0.61993796\n",
      " -0.04384394]\n",
      "\n",
      "find better score:\n",
      "score:  6049.878578799615\n",
      "coeffs:  [-0.06219317  0.01790947  0.05853813 -0.00199072  0.14620302  0.01156249\n",
      "  0.02818429  0.07043297 -0.03028075 -0.12962932 -0.11211081 -0.00394595\n",
      "  0.04189226 -0.22668962  0.15027712  0.03077493  0.41287068 -0.12652589\n",
      " -0.33951873 -0.21401543  0.03772799 -0.1269483   0.04610118  0.09909437\n",
      " -0.39693402  0.24386791  0.24451758  0.18943361 -0.01445903  0.06835839\n",
      "  0.07169308 -0.1985156  -0.22819591  0.16079182  0.46609422  0.61816004\n",
      " -0.04321311]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:155: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/linesearch.py:391: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  alpha1 = min(1.0, 1.01*2*(phi0 - old_phi0)/derphi0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [-0.5110538151163169, -0.779137004052016, -0.5245302523817306, -1.1059505691350153, 0.5772175548489449, -0.3637734129281973, -0.1312112325993625, -0.31152692206811544, -0.43432074211750976, 0.0932704656230493, 1.4013895176194635, 0.41747807990123115, 0.5229160105745478, 2.406032710215061, 0.013925868647892805, 0.7783662708654133, -0.04378145193332958, -0.3005441744026727, 0.5039142510451475, 0.12192632015568851, 0.365678263655977, -0.7125800689100064, 2.595275937692595, -0.9038271655463739, -0.8403568734545275, 0.19240272941754952, 0.5671992220101669, 1.038251789749634, 0.20054562015223534, 1.05483101743814, -0.7283547014969391, 0.8310036404356429, 0.5483362676755528, 1.0426639387294836, -0.14011907443967725, -0.8234573774667291, 1.5201690945769544]\n",
      "\n",
      "find better score:\n",
      "score:  6050.878567989163\n",
      "coeffs:  [-0.05895754  0.01873386  0.05347019 -0.00120608  0.14629173  0.01539391\n",
      "  0.02811907  0.06914767 -0.02869167 -0.13783333 -0.11178092 -0.00431743\n",
      "  0.04164938 -0.23846654  0.16510956  0.01184705  0.40731065 -0.10718031\n",
      " -0.34983805 -0.1526613   0.05421626 -0.14411474  0.04332266  0.0990424\n",
      " -0.39636906  0.23875528  0.24257175  0.15150372 -0.01138854  0.06881788\n",
      "  0.07320174 -0.19542414 -0.2313475   0.15590604  0.46625188  0.62145557\n",
      " -0.04331352]\n",
      "\n",
      "Optimizing with init x0: [-2.352292833950361, -1.0065266554296426, -0.6076622739110855, 0.7916946794974262, 0.9438049907650199, 1.4529344424582749, -0.8301089066495393, 2.0740166337735295, -1.1968668144760475, -1.2453705367481638, -0.7282061516637048, -1.5917316298274586, -0.7973381247065154, 0.3590256165487591, -2.003094400644479, 1.2494470875761308, 1.5281111727979146, 1.3022929168001283, -0.5959244048985546, -1.7364201603657885, -0.3501492343003583, -0.5312796464642704, -0.6761023802408641, 1.021930765068223, -0.11575417164348534, -0.3496827335706494, -0.2039407589595481, -0.21527965382207775, 0.34797208537308594, 0.12390465921358758, 1.94970530919679, -0.811213229333908, 0.5231061589576997, -0.7273162606354187, -1.3673145612653321, 0.6388287254449037, -0.27353700234766304]\n",
      "\n",
      "Optimizing with init x0: [0.6029641878789267, 2.369089406354681, -0.7953493716064193, -0.7984815456559176, 0.7755426784826989, -0.3048926132381826, -0.4424724121871848, -0.145033125445872, 1.1096943957241132, 0.7354901761120904, -0.00723776636018815, 0.40181986290180643, 0.5782706482111475, -0.39748113122979833, 0.9232881164310729, -0.6187652220353417, 0.3640357219325378, -0.09295183801903391, 1.675349829780437, 0.07615930788443445, 1.1848588840091043, 1.9783119328903582, -0.08491854307755908, 0.4104642870597039, -0.5927421812132567, 0.045992949224993245, -1.8624868524156049, -0.3543018574711251, -0.3516047769700133, 1.3127763299654807, 2.1194686245919137, -0.33586736813700274, 0.9892856473381035, 0.8639705222873679, -0.40783817534876154, -1.1817723422398585, -0.8937224558290591]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/scipy/optimize/optimize.py:663: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "for metric in ['smooth']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(cv, metric, best_score, best_coeffs, True), \n",
    "                 tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'smooth': 6050.878567989163}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'smooth': array([-0.05895754,  0.01873386,  0.05347019, -0.00120608,  0.14629173,\n",
       "         0.01539391,  0.02811907,  0.06914767, -0.02869167, -0.13783333,\n",
       "        -0.11178092, -0.00431743,  0.04164938, -0.23846654,  0.16510956,\n",
       "         0.01184705,  0.40731065, -0.10718031, -0.34983805, -0.1526613 ,\n",
       "         0.05421626, -0.14411474,  0.04332266,  0.0990424 , -0.39636906,\n",
       "         0.23875528,  0.24257175,  0.15150372, -0.01138854,  0.06881788,\n",
       "         0.07320174, -0.19542414, -0.2313475 ,  0.15590604,  0.46625188,\n",
       "         0.62145557, -0.04331352])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['smooth'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_prices = np.sort(df_train['total_price'].unique())\n",
    "\n",
    "def find_nearest(array, value):\n",
    "    return array[(np.fabs(array - value)).argmin()]\n",
    "\n",
    "def correct_prices(sq):\n",
    "    return [find_nearest(unique_prices, x) for x in sq]\n",
    "\n",
    "test_pred_final['total_price'] = correct_prices(test_pred_final['total_price'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}_smoothobj.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/matplotlib/axes/_axes.py:6571: UserWarning: The 'normed' kwarg is deprecated, and has been replaced by the 'density' kwarg.\n",
      "  warnings.warn(\"The 'normed' kwarg is deprecated, and has been \"\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAELCAYAAADOeWEXAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvIxREBQAAHtJJREFUeJzt3X10VfWd7/H3V4gGDAYFzRWxE1w4Dg60IPGp9vaGUUesomPlVnmwgyNi7ZXamdYpvZVq770dnevoVevTZaK1VGNUWntBaMV0iNguHxBUwMYHZKgGp9DiIiUssQS/94+9k5yEPJydnJ29s/N5rZXFPjv77PM5WeF889u/3/79zN0RERHJ1yFJBxARkYFFhUNERCJR4RARkUhUOEREJBIVDhERiUSFQ0REIlHhEBGRSFQ4REQkEhUOERGJZGjSAeIwevRoLy8vB2Dv3r0cfvjhyQbqRFpzQXqzpTUXpDdbWnNBerOlNRfEn239+vV/cPejezzQ3TP3NXXqVG+xZs0aT6O05nJPb7a05nJPb7a05nJPb7a05nKPPxvwiufxGatLVSIiEokKh4iIRKLCISIikWSyc1xEJKr9+/fT0NBAaWkp9fX1ScfpVKGyFRcXM3bsWIqKinr1fBUOERGgoaGBESNGMGrUKI444oik43Rqz549jBgxok/ncHd27dpFQ0MD48aN69U5dKlKRATYt28fo0aNwsySjhIrM2PUqFHs27ev1+dIfYvDzA4H7gP+BNS5+6MJRxKRjMp60WjR1/eZSIvDzB4ys51mtrnD/ulm9paZbTGzReHuLwLL3P1q4KJ+DysiIu0k1eJ4GLgHWNqyw8yGAPcC5wINwDozWw6MBTaFhx3o35gZVn1Z2/bsx5PLIZJS5YtWFvR82269oNvv7969m+rqar761a9GOu8XvvAFqqurGTlyZF/iRZJI4XD3tWZW3mH3acAWd98KYGY1wMUERWQs8Brqk+mT3P8I2z6dYBAROcju3bu57777Dioczc3NDB3a9Uf1qlWr4o52EAvuMu9/YeF42t0nho9nAtPdfX74+ArgdOBbBK2TfcCvuurjMLMFwAKAsrKyqTU1NQA0NTVRUlIS63vpjSRybdre2Lo9adiutm8cdUK74/Qziy6t2dKaC9KXrbS0lPHjx3PgwAGGDBnCpO+vLej5N33n891+f968eaxatYoTTzyRoUOHUlxczMiRI3n77bd59dVXmTVrFg0NDXz88cdce+21XHnllQBMnDiR5557jqamJi699FLOPPNMXnrpJY499lhqamoYNmxYp6+3ZcsWGhsb2+2bNm3aenev6Om9pL5z3N33AlfmcdwSYAlARUWFV1ZWAlBXV0fLdpokkWteuxbHM23fqGx/qUo/s+jSmi2tuSB92err6xkxYkRBhrx2pqdz3n777bz11lts3LiRuro6LrjgAjZv3tw6ZHbp0qUUFRUxdOhQTj31VObMmdM6CqylAL/77rs8/vjjTJ48mS996UusXr2auXPndvp6xcXFTJkypVfvJU2XfrYDx+c8Hhvuy5uZzTCzJR2rqIjIQHPaaae1u8/i7rvv5rOf/SxnnHEG77//Pu+8885Bzxk3bhyTJ08GYOrUqWzbti2WbGkqHOuAE81snJkdClwOLI9yAndf4e4LSktLYwkoItJfcqdPr6uro7a2ltraWl5//XWmTJnS6X0Yhx12WOv2kCFDaG5ujiVbUsNxHwNeAE4yswYzu8rdm4HrgGeAeuAJd38jiXyDWfmilWza3ljwESUi0r2Wy2SdaWxs5Mgjj2T48OG8+eabvPjii/2crr2kRlXN6mL/KqDXQwTMbAYwY/z48b09hYgI0PPw2UIbNWoUZ511FhMnTmTYsGGUlZW1fm/69Ok88MADVFRUMGHCBM4444x+zdZR6jvHo3D3FcCKioqKq5POkgm610OkX1VXV3e6/7DDDuPnP/95px33Lf0Yo0ePZvPmtnuqv/nNb8aWM019HCIiMgBkqnBoVJWISPx0qWoQqSq6rXW7NmdK/3PyeG67u877+dqviKRLpgqHHCz3A7+qizVbahdX5jy6odNjcosO1UvbtnP6PlRcRAYHFY6Ma/eBXyC19Ttat/NprYhItqiPQ0REIslUi0N9HKHcYbQRVRXdxkc2m6qiaqCsx+Mj59GwXhko+vD/qFM9/O73dlp1gDvvvJMFCxYwfPjw3qaLJFOFYzBLasr0fPpHRKRnXU2rno8777yTuXPnqnBIdqhPRKRnixYt4t1332Xy5Mmce+65HHPMMTzxxBN8/PHHXHLJJXzve99j7969XH755TQ0NHDgwAEWL17Mjh07+OCDD5g2bRqjR49mzZo1sWfNVOHQlCOFlfuBn4/2HfEaVSUSxa233srmzZt57bXXWL16NcuWLePll1/G3bnoootYu3Yt7733HmPGjGHlyuAKQ2NjI6Wlpdxxxx2sWbOG0aNH90vWTHWOa3ZcEcmC1atXs3r1aqZMmcIpp5zCm2++yTvvvMPJJ5/Ms88+y7e+9S2ef/55kvqsy1SLQ9Kjfd+HiETh7nz729/mmmuuabd/z549bNiwgVWrVnHjjTdy9tln893vfrff86lwDGDqmBbJjtxp1c877zwWL17MnDlzKCkpYfv27RQVFbF7924+9alPMXfuXEaOHElVVVW75/bXpSoVDulfGporA0U//37mTqt+/vnnM3v2bM4880wASkpKeOSRR3jjjTeYOXMmhxxyCEVFRdx///0ALFiwgOnTpzNmzBh1jkelzvH00wgrka51nFb9+uuvb/f4mGOO4ZJLLjnoeQsXLmThwoWxZsulznEREYkkUy0OGWB02UpkQFLhkHRQEZEUcPekI/SLvr5PFQ5JTLv+jgkFmhdLpJeKi4vZtWsXhx56aNJRYuXu7Nq1i+Li4l6fQ4VDUkGd5pK0sWPH0tDQwO7du/v0oRqnffv2FSRbcXExY8eO7fXzVTgyKOpUISICRUVFjBs3jrq6OqZMmZJ0nE6lJVumRlVpPQ4RkfhlqsUxKNbj6GKNgDhW+hMR6UymWhwiIhI/FQ4REYlEhUNERCJR4RARkUhUOEREJBIVDhERiSRTw3GzqnzRytbtbZ9OMEgScocfj7k2uRwi0ipThUPrcWRP7l3w9d5IZXJRRCSUqcIxKG4AHAS6W6+8Xevr1gv6IY2IdKQ+DhERiSRTLY4BTetRiMgAocIhA0a57aCqKGdN5uqlwb8qtCL9SpeqREQkErU4BhittSEiSVOLQ0REIlHhEBGRSFQ4UqK2fkfrV+69CiIiaaPCISIikahzPC4592WUb/xy67budo6H7igX6T+pLxxmdgLwHaDU3WcmnUfSo2WE2Xxd2hPpV7EWDjN7CLgQ2OnuE3P2TwfuAoYAVe5+a1fncPetwFVmtizOrKlVfRlVRRqCKyLpEXeL42HgHmBpyw4zGwLcC5wLNADrzGw5QRG5pcPz/87dd8acUTKkqug23VEuErNYC4e7rzWz8g67TwO2hC0JzKwGuNjdbyFonYhEUlV0W88HaS4wkYIxd4/3BYLC8XTLpSozmwlMd/f54eMrgNPd/bounj8K+D5BC6UqLDCdHbcAWABQVlY2taamBoCmpiZKSkoK+Zby8+HW1s1NH41q3Z50XClwcK49H7zdur3Ny1qP48Ot7NnXHHPY9j4pPopD9n3Yr6+Zj3xzjSju4e+ho04oUKI2if2e9SCtuSC92dKaC+LPNm3atPXuXtHTcanvHHf3XcBX8jhuCbAEoKKiwisrKwGoq6ujZbtfVd/fujlvU86oqjlBlo65ahff3Lo9Aai0srbv9fM0Ix9NmM2w+uqeD+xn+ebKLbPnTDj45zh//w0FH3mV2O9ZD9KaC9KbLa25ID3ZkriPYztwfM7jseE+EREZAJJocawDTjSzcQQF43JgdiFOrKVjpSNNCilSeLG2OMzsMeAF4CQzazCzq9y9GbgOeAaoB55w9zcK8XruvsLdF5SWlhbidCIi0om4R1XN6mL/KmBVoV9PLQ4RkfilvnM8CndfAayoqKi4OuksfaVLLCKSVprkUEREIlHhEBGRSDJ1qWog9HG0zOL6jUnNzMuZnK+qKKlEIiLRZKrFoVFVIiLxy1SLYyBomVfpI5sNHJdsGBGRXshU4UjrpaquJuHLa3I+iYUWfhLpPV2qEhGRSDLV4hDJx0EtPa3fIRJJplocIiISv0y1ONLUx6E7v0UkqzJVOLI05YgkQ53mIj3TpSoREYkkUy2OpJXrTnARGQRUOApI92VkR1XRbRptJdIFXaoSEZFIMlU4zGyGmS1pbGxMOooMILX1O6it39HuUmN3+0UGu0xdqtKoKukLXWoUyU+mWhwiIhI/FQ6RHgQd5ZcFXyKiwiEiItGocIiISCSZKhwaVSUiEj+Nquoj3S0uIoNNplocIiISPxUOERGJRIVDJA+6i1ykTab6OET6g9bskMFOLQ4REYkk7xaHmX0G+M/hw+fd/fV4IomISJrl1eIws+uBR4Fjwq9HzGxhnMFERCSd8m1xXAWc7u57Aczsn4EXgB/EFUwkjXJn0J2//4bW/o5vTGqmMqFMIv0t3z4OAw7kPD4Q7ksV3TkuIhK/fAvHD4GXzOxmM7sZeBF4MLZUveTuK9x9QWlpadJRREQyK69LVe5+h5nVAZ8Ld13p7q/GlmoA0eI/IjLYdFs4zOwId/+jmR0FbAu/Wr53lLt/GG88ERFJm55aHNXAhcB6wHP2W/j4hJhyiaRebmuznr9PMIlI/+q2cLj7heG/4/onjoiIpF2+93H8Mp99IiKSfT31cRQDw4HRZnYkbUNwjwCOizmbiIikUE99HNcAXwfGEPRztBSOPwL3xJhLRERSqqc+jruAu8xsobvrLnEREcn7Po4fmNlE4GSgOGf/0riCpVr1ZUknkDTL/f2Y/XhyOURiklfhMLObgEqCwrEKOB/4FTAoC0dt/Y6kI4iIJCbfSQ5nAp8BXnX3K82sDHgkvlhtzOxvgAsIOuQfdPfV/fG6IlGU2w61RGXQyHeuqn3u/gnQbGZHADuB43t6kpk9ZGY7zWxzh/3TzewtM9tiZou6O4e7/8zdrwa+Auh/pqRWy/KyapFK1vXY4jAzAzaa2UjgXwlGVzURTKvek4cJRl+1XtIysyHAvcC5QAOwzsyWA0OAWzo8/+/cfWe4fWP4PBERSVCPhcPd3cxOc/fdwANm9gvgCHffmMdz15pZeYfdpwFb3H0rgJnVABe7+y0E05u0ExauW4Gfu/uGnl5TJG20Rrlkjbl7zweZ/Qi4x93XRX6BoHA87e4Tw8czgenuPj98fAXBIlHXdfH8rwF/C6wDXnP3B7o4bgGwAKCsrGxqTU0NAE1NTZSUlESN3a09H7zd53N8UnwUh+xL5xyRac2W1lxwcLYRxeHfZEedwKbtbevDTDquf6f8j+P3v1DSmi2tuSD+bNOmTVvv7hU9HZdv5/jpwBwz+y2wl3CSQ3f/dB8y5sXd7wbuzuO4JcASgIqKCq+srASgrq6Olu1CqV18c5/P8dGE2Qyrr+57mBikNVtac8HB2SonlIUbjzMvt8Uxp7Jfc8Xx+18oac2W1lyQnmz5Fo7zCvia22nfsT423NdnZjYDmDF+/PhCnE4kPrrXQwawfG8A/G0BX3MdcKKZjSMoGJcDswtxYndfAayoqKi4uhDnE+mtlpFV83NaGyJZke9w3F4xs8cIRl+dZGYNZnaVuzcD1wHPAPXAE+7+Rpw5RESkcPK9VNUr7j6ri/2rCO5ALyhdqhIRiV+shaO/6VKVpM1Ba9JXD8pZeiRjMlU4RAYq3eshA0msfRz9zcxmmNmSxsbGng8WEZFeyVThcPcV7r6gtLR/b7ISERlMdKlKJMV6fQmr5T6R4vMIVkQQKZxMFQ6NqpK0y50595yWu8tFBhhdqhIRkUgyVThERCR+KhwiIhJJpvo4Ci5nIrryjV9u3a4qSiKMZFb1ZVQVtfV91C4Obhqcv/+GpBKllyaHTIVMtTh0H4eISPwyVTjUOS4iEr9MFQ4REYmfCoeIiESiznGRhOTeDCgykGSqxaHOcZH29uxrpnzRynZTl4j0VaZaHHGux3HQugoiMcv9nWs3NLerIam5+7vSl+GsGgoroUy1OEREJH4qHCIiEokKh4iIRKLCISIikWSqcGhUlYhI/DJVODTliIhI/DJVOEREJH6Zuo9DJMtabuKrKtqhZWclUSocIgNQ63QliyuB7tcvb72RsHppzKm6oZsHM0WXqkREJBIVDhERiUSFQ0REIlHhEBGRSNQ5LjJI5K7/oVFZ0heZanHoznERkfhlqsUR53ocIoNN7uJP2269IMEkkjaZanGIiEj8VDhERCSSTF2qEpH2neBMSC6HZJdaHCIiEokKh4iIRKLCISL9prZ+B+WLVrYbsSUDjwqHiIhEosIhIiKRaFSVyADQuqZGIeWukdHpa+5g/v4bop0n6lobhVqnI+p5srQ+SALvRYVDRHqtfNFKqoqC4b9R57/atL2R5jfzf25fXksKK/WXqsxsgpk9YGbLzOzapPOIiAx2sRYOM3vIzHaa2eYO+6eb2VtmtsXMFnV3Dnevd/evAF8Czoozr4iI9CzuFsfDwPTcHWY2BLgXOB84GZhlZieb2SQze7rD1zHhcy4CVgKrYs4rIiI9iLWPw93Xmll5h92nAVvcfSuAmdUAF7v7LcCFXZxnObDczFYC1fElFhkculqbo910JSJdMHeP9wWCwvG0u08MH88Eprv7/PDxFcDp7n5dF8+vBL4IHAZsdPd7uzhuAbAAoKysbGpNTQ0ATU1NlJSU9C78h1tbN/fsa+7dObrwSfFRHLLvw4Kes1DSmi2tuSD5bCOK2/4GzP1dzSdXV88F2OZBUZl0XGm7/w8cdQIQdHCX246284T7DxI+d8++5tZzlg2DYfvyeG6o29fqJFu3ujm+T58ZMes0W9T33o1p06atd/eKno5L/agqd68D6vI4bgmwBKCiosIrKysBqKuro2U7sur7WzcL/ZfYRxNmM6w+nY2ntGZLay5IPltlF62GfHJ19VyA28PhuNvmVLb7/0BlMOxz3qKVVBVVt52nsovhoOFza+t3tJ7zG5OamfBmHs8NdftanWTrVjfH9+kzI2adZov63gsgiVFV24Hjcx6PDff1mVYAFBGJXxKFYx1wopmNM7NDgcuB5YU4sbuvcPcFpaWlhTidiIh0ItZLVWb2GFAJjDazBuAmd3/QzK4DngGGAA+5+xtx5ugtdRTKQBH372ruzXcA81M6SWFt/Y522bTkbTziHlU1q4v9q4hhaK2ZzQBmjB8/vtCnFhGRUOrvHI9Cl6pEROKXqcIhIiLxy1Th0KgqEZH4Zapw6FKViEj8MlU4REQkfqm/c1xEBobcobC5w2A7DuWVgS9TLQ71cYiIxC9ThUN9HCIi8ctU4RARkfipcIiISCSZKhzq4xARiV+mCof6OERE4pepwiEiIvFT4RARkUh0A2AH5Tlz+VcVJRhEpJ/EsZZHeYHW68jnPL25wTD3PZ8TOVW6JPFeMtXiUOe4iEj8MlU41DkuIhK/TBUOERGJnwqHiIhEosIhIiKRqHCIiEgkKhwiIhJJpgqHhuOKiMQvU4VDw3FFROKXqcIhIiLxU+EQEZFIVDhERCQSFQ4REYlEhUNERCJR4RARkUi0HoeIpEo+a3DU1u9gfsQ1P/qy1k7uc7fdekG0J2dQplocugFQRCR+mSocugFQRCR+mSocIiISPxUOERGJRIVDREQiUeEQEZFIVDhERCQSFQ4REYlEhUNERCIxd086Q8GZ2e+B34YPRwN/SDBOV9KaC9KbLa25IL3Z0poL0pstrbkg/mx/5u5H93RQJgtHLjN7xd0rks7RUVpzQXqzpTUXpDdbWnNBerOlNRekJ5suVYmISCQqHCIiEslgKBxLkg7QhbTmgvRmS2suSG+2tOaC9GZLay5ISbbM93GIiEhhDYYWh4iIFFCmC4eZTTezt8xsi5ktSjoPgJk9ZGY7zWxz0lk6MrPjzWyNmf3GzN4ws+uTzgRgZsVm9rKZvR7m+l7SmXKZ2RAze9XMnk46Sy4z22Zmm8zsNTN7Jek8LcxspJktM7M3zazezM5MOhOAmZ0U/qxavv5oZl9POheAmf19+Lu/2cweM7PiRPNk9VKVmQ0B3gbOBRqAdcAsd/9Nwrk+DzQBS919YpJZOjKzY4Fj3X2DmY0A1gN/k4KfmQGHu3uTmRUBvwKud/cXk8zVwsz+AagAjnD3C5PO08LMtgEV7p6qexLM7EfA8+5eZWaHAsPdfXfSuXKFnx/bgdPd/bc9HR9zluMIfudPdvePzOwJYJW7P5xUpiy3OE4Dtrj7Vnf/E1ADXJxwJtx9LfBh0jk64+7/4e4bwu09QD1wXLKpwANN4cOi8CsVf/GY2VjgAqAq6SwDgZmVAp8HHgRw9z+lrWiEzgbeTbpo5BgKDDOzocBw4IMkw2S5cBwHvJ/zuIEUfAgOFGZWDkwBXko2SSC8HPQasBN41t1TkQu4E/hH4JOkg3TCgdVmtt7MFiQdJjQO+D3ww/DyXpWZHZ50qE5cDjyWdAgAd98O/AvwHvAfQKO7r04yU5YLh/SSmZUAPwG+7u5/TDoPgLsfcPfJwFjgNDNL/DKfmV0I7HT39Uln6cLn3P0U4Hzgv4WXSZM2FDgFuN/dpwB7gVT0P7YIL59dBDyZdBYAMzuS4GrJOGAMcLiZzU0yU5YLx3bg+JzHY8N90o2wD+EnwKPu/tOk83QUXtZYA0xPOgtwFnBR2JdQA/yVmT2SbKQ24V+quPtO4CmCy7dJawAaclqMywgKSZqcD2xw9x1JBwmdA/y7u//e3fcDPwU+m2SgLBeOdcCJZjYu/AvicmB5wplSLeyEfhCod/c7ks7TwsyONrOR4fYwggEPbyabCtz92+4+1t3LCX6//s3dE/1LsIWZHR4OcCC8FPTXQOIj+dz9d8D7ZnZSuOtsINHBF52YRUouU4XeA84ws+Hh/9GzCfofEzM0yRePk7s3m9l1wDPAEOAhd38j4ViY2WNAJTDazBqAm9z9wWRTtToLuALYFPYnAPx3d1+VYCaAY4EfhSNdDgGecPdUDX1NoTLgqeBzhqFAtbv/ItlIrRYCj4Z/0G0Frkw4T6uwyJ4LXJN0lhbu/pKZLQM2AM3AqyR8B3lmh+OKiEg8snypSkREYqDCISIikahwiIhIJCocIiISiQqHiIhEosIhIiKRqHBI6phZU89Hdfv8ZWZ2Qm/OZWYVZnZ3uD3PzO7pLqOZjQnH2Geamf2Fmb1gZh+b2Tdz9h9qZmvDyfdkkFDhkEwxs78Ehrj71t48391fcfevRTj+A3ef2ZvX6otCflCbWbmZ1fVw2IfA1wgm22sVzjz9S+CyQuWR9FPhkNSywG3h4jWbzOyycP8hZnZfuBDQs2a2ysxaPrznAP+vw3n+T7gIzi/N7OhwX52ZVYTbo8P5pjCzys4WZAqnrnkhzPG/cvaXW7goV9hC+amZ/cLM3jGz/51z3FVm9rYFC1L9a1ctmfDYGWb2Ujh7bK2ZlYX7bzazH5vZr4EfhzMG32Zm68xso5ldEx5XEr7XDWHePi8n4O473X0dsL+Tb/+M4Ocug4QKh6TZF4HJwGcIJnq7zYLFpr4IlAMnE0yRkruC3FkEC1C1OBx4xd3/EngOuKmXWe4imNF1EsHU1l2ZTPDX9yTgMgtWVRwDLAbOCPP9RQ+v9SvgjHD22BqCadtbnAyc4+6zgKsIptg+FTgVuNrMxgH7gEvCmXGnAbeHcxzFZXP4+jJI6LqkpNnngMfc/QCww8yeI/iA+hzwpLt/AvzOzNbkPOdYgvUeWnwCPB5uP0Iws2hvnAVcGm7/GPjnLo77pbs3ApjZb4A/A0YDz7n7h+H+J4E/7+a1xgKPh0XyUODfc7633N0/Crf/Gvh0TmurFDiRYAbafwqnUf+EYB2aMuB3uS9iZk8RTNV9KPCpnPnJ7nL3H3aTrx13P2BmfzKzEeECYJJxKhySNR8B3a3H3DI5WzNtLe5812/OZ2K3j3O2D9C7/2M/AO5w9+VmVgncnPO9vTnbBix092dyn2xm84Cjganuvj+8DHfQe3T3S8Ljy4GH3b2yF1lbHEbQ0pFBQJeqJM2eJ7jcMyTsm/g88DLwa+DSsK+jjGC24Rb1wPicx4cALX+Rzya4DASwDZgabufTuf1rgqnTIfr1/HXAfzGzI8NO7Ut7OL6UtrVj/rab454BrrVgDRXM7M/D2V1LCRaY2m9m0whaPbExs1HAH8K1ImQQUOGQNHsK2Ai8Dvwb8I/heg4/Ibgc8xuCy08bgMbwOStpX0j2EqwYuBn4K+B/hPv/heBD91WCS0k9uZ5gFb1NRFyCOFxQ6Z9oK3rbcvJ25mbgSTNbD/yhm+OqCH4GG8L3938JWjiPAhVh1i9TgLVLzOw/hcsA/ANwo5k1mNkR4benEfzcZZDQtOoyIJlZibs3hX/tvgyc5e6/s2ChpzXh4wPJpmyTk3coQUF8yN2fSjpXIZjZT4FF7v520lmkf6iPQwaqpy1YFfBQ4H+GLRHc/SMzu4mgVfBekgE7uNnMziHoa1hNMIR1wLNgMaafqWgMLmpxiCTEzL4D/NcOu5909+8nkUckXyocIiISiTrHRUQkEhUOERGJRIVDREQiUeEQEZFIVDhERCSS/w97rFZpkBZaiwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0.05263157894736842, 0, 0.05263157894736842, 0, 0, 0.05263157894736842, 0, 0, 0, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842, 0, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0.05263157894736842, 0, 0.05263157894736842]\n"
     ]
    }
   ],
   "source": [
    "idxs = [3, 5, 8, 12, 13, 15, 16, 17, 18, 20, 22, 23, 24, 25, 26, 27, 28, 29, 31]\n",
    "print([1/len(idxs) if i in idxs else 0 for i in range(1,32)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0.125, 0, 0, 0, 0, 0, 0, 0.125, 0, 0, 0, 0.125, 0, 0, 0, 0, 0, 0, 0.125, 0.125, 0.125, 0, 0.125, 0, 0, 0, 0.125]\n"
     ]
    }
   ],
   "source": [
    "idxs = [5, 12, 16, 23, 24, 25, 27, 31]\n",
    "print([1/len(idxs) if i in idxs else 0 for i in range(1,32)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
