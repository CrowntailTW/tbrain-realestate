{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "IPython.notebook.set_autosave_interval(0)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autosave disabled\n"
     ]
    }
   ],
   "source": [
    "%autosave 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from utilities import cal_score, cal_mape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "stack_idx = '16'\n",
    "models = '1-27'\n",
    "use_test_kfold = set([2, 7, 8, 12, 13])\n",
    "\n",
    "is_per_area = False\n",
    "add_intercept = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read CV predictions and test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_models(exp):\n",
    "    exp_split = exp.split(',')\n",
    "    idx_models = []\n",
    "    for e in exp_split:\n",
    "        if '-' in e:\n",
    "            n0, n1 = e.split('-')\n",
    "            idx_models.extend(list(range(int(n0), int(n1)+1, 1)))\n",
    "        else:\n",
    "            idx_models.append(int(e))\n",
    "    return idx_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27]\n"
     ]
    }
   ],
   "source": [
    "idx_models = parse_models(models)\n",
    "print(idx_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_in_output = [f for f in os.listdir('output/') if os.path.isfile('output/'+f)]\n",
    "files_cv = {idx: [f for f in files_in_output \n",
    "                  if f.startswith('model-%02d-' % idx) and f.endswith('cv.csv')][0] \n",
    "            for idx in idx_models}\n",
    "files_test_one = {idx: [f for f in files_in_output \n",
    "                        if f.startswith('model-%02d-' % idx) and f.endswith('test-one.csv')][0]\n",
    "                  for idx in idx_models}\n",
    "files_test_kf = {idx: [f for f in files_in_output \n",
    "                       if f.startswith('model-%02d-' % idx) and f.endswith('test-kfold.csv')][0]\n",
    "                 for idx in idx_models}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1 model-01-lgb-cv.csv\n",
      " 1 model-01-lgb-test-kfold.csv\n",
      " 1 model-01-lgb-test-one.csv\n",
      " 2 model-02-keras-search-cv.csv\n",
      " 2 model-02-keras-search-test-kfold.csv\n",
      " 2 model-02-keras-search-test-one.csv\n",
      " 3 model-03-lgb-feats-selection-cv.csv\n",
      " 3 model-03-lgb-feats-selection-test-kfold.csv\n",
      " 3 model-03-lgb-feats-selection-test-one.csv\n",
      " 4 model-04-lgb-PCA-cv.csv\n",
      " 4 model-04-lgb-PCA-test-kfold.csv\n",
      " 4 model-04-lgb-PCA-test-one.csv\n",
      " 5 model-05-lgb-wo-per-area-cv.csv\n",
      " 5 model-05-lgb-wo-per-area-test-kfold.csv\n",
      " 5 model-05-lgb-wo-per-area-test-one.csv\n",
      " 6 model-06-lgb-lr0.001-cv.csv\n",
      " 6 model-06-lgb-lr0.001-test-kfold.csv\n",
      " 6 model-06-lgb-lr0.001-test-one.csv\n",
      " 7 model-07-keras-embedding-cv.csv\n",
      " 7 model-07-keras-embedding-test-kfold.csv\n",
      " 7 model-07-keras-embedding-test-one.csv\n",
      " 8 model-08-keras-search-long-cv.csv\n",
      " 8 model-08-keras-search-long-test-kfold.csv\n",
      " 8 model-08-keras-search-long-test-one.csv\n",
      " 9 model-09-lgb-feats-selection-75-cv.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-kfold.csv\n",
      " 9 model-09-lgb-feats-selection-75-test-one.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-kfold.csv\n",
      "10 model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "11 model-11-rf-cv.csv\n",
      "11 model-11-rf-test-kfold.csv\n",
      "11 model-11-rf-test-one.csv\n",
      "12 model-12-predict-keras-search-prelu-cv.csv\n",
      "12 model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "12 model-12-predict-keras-search-prelu-test-one.csv\n",
      "13 model-13-predict-keras-he_uni-cv.csv\n",
      "13 model-13-predict-keras-he_uni-test-kfold.csv\n",
      "13 model-13-predict-keras-he_uni-test-one.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-kfold.csv\n",
      "14 model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-kfold.csv\n",
      "15 model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-kfold.csv\n",
      "16 model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-kfold.csv\n",
      "17 model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-kfold.csv\n",
      "18 model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-kfold.csv\n",
      "19 model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-kfold.csv\n",
      "20 model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "21 model-21-lgb-wo-per-area-long-cv.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-kfold.csv\n",
      "21 model-21-lgb-wo-per-area-long-test-one.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-kfold.csv\n",
      "22 model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "23 model-23-lgb-binary-cv.csv\n",
      "23 model-23-lgb-binary-test-kfold.csv\n",
      "23 model-23-lgb-binary-test-one.csv\n",
      "24 model-24-lgb-binary-augment-cv.csv\n",
      "24 model-24-lgb-binary-augment-test-kfold.csv\n",
      "24 model-24-lgb-binary-augment-test-one.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-kfold.csv\n",
      "25 model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-kfold.csv\n",
      "26 model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "27 model-27-lgb-feat_rm_new-cv.csv\n",
      "27 model-27-lgb-feat_rm_new-test-kfold.csv\n",
      "27 model-27-lgb-feat_rm_new-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "for k in files_cv: \n",
    "    print('%2d'%k, files_cv[k])\n",
    "    print('%2d'%k, files_test_kf[k])\n",
    "    print('%2d'%k, files_test_one[k])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('dataset/train.csv')\n",
    "df_test = pd.read_csv('dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = df_train[['building_id', 'building_area', 'total_price']]\n",
    "test = df_test[['building_id', 'building_area']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV predictions:\n",
      "27\n",
      "model-01-lgb-cv.csv\n",
      "model-02-keras-search-cv.csv\n",
      "model-03-lgb-feats-selection-cv.csv\n",
      "model-04-lgb-PCA-cv.csv\n",
      "model-05-lgb-wo-per-area-cv.csv\n",
      "model-06-lgb-lr0.001-cv.csv\n",
      "model-07-keras-embedding-cv.csv\n",
      "model-08-keras-search-long-cv.csv\n",
      "model-09-lgb-feats-selection-75-cv.csv\n",
      "model-10-lgb-feats-selection-75-lr-0.001-cv.csv\n",
      "model-11-rf-cv.csv\n",
      "model-12-predict-keras-search-prelu-cv.csv\n",
      "model-13-predict-keras-he_uni-cv.csv\n",
      "model-14-lgb-feats-selection-75-lr-0.001-rand-cv.csv\n",
      "model-15-lgb-feats-selection-75-lr-0.001-rand323-cv.csv\n",
      "model-16-lgb-feats-selection-68-lr-0.001-mix5-cv.csv\n",
      "model-17-lgb-feats-selection-70-lr-0.001-mix5-cv.csv\n",
      "model-18-lgb-feats-selection-70-lr-0.001-p5-cv.csv\n",
      "model-19-lgb-search-bins-lr-0.0005-cv.csv\n",
      "model-20-lgb-lr-0.0008-mix5-cv.csv\n",
      "model-21-lgb-wo-per-area-long-cv.csv\n",
      "model-22-lgb-wo-per-area-long-2-cv.csv\n",
      "model-23-lgb-binary-cv.csv\n",
      "model-24-lgb-binary-augment-cv.csv\n",
      "model-25-lgb-search-bins-lr-0.0005-250-cv.csv\n",
      "model-26-lgb-search-bins-lr-0.0005-350-cv.csv\n",
      "model-27-lgb-feat_rm_new-cv.csv\n"
     ]
    }
   ],
   "source": [
    "print('CV predictions:')\n",
    "print(len(idx_models))\n",
    "for i, idx_model in enumerate(idx_models):\n",
    "    f = files_cv[idx_model]\n",
    "    print(f)\n",
    "#    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "    \n",
    "    cv = pd.merge(cv, df[['building_id', 'total_price_predict']], on='building_id')\n",
    "    \n",
    "    cv = cv.rename(columns = {'total_price_predict': 'pred_{}'.format(idx_model)})\n",
    "    cv[f'log_pred_{idx_model}'] = np.log1p(cv[f'pred_{idx_model}'])\n",
    "    cv[f'log_parea_pred_{idx_model}'] = np.log1p( cv[f'pred_{idx_model}'] / cv['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test predictions:\n",
      "No. 0 file: model-01-lgb-test-one.csv\n",
      "No. 1 file: model-02-keras-search-test-kfold.csv\n",
      "No. 2 file: model-03-lgb-feats-selection-test-one.csv\n",
      "No. 3 file: model-04-lgb-PCA-test-one.csv\n",
      "No. 4 file: model-05-lgb-wo-per-area-test-one.csv\n",
      "No. 5 file: model-06-lgb-lr0.001-test-one.csv\n",
      "No. 6 file: model-07-keras-embedding-test-kfold.csv\n",
      "No. 7 file: model-08-keras-search-long-test-kfold.csv\n",
      "No. 8 file: model-09-lgb-feats-selection-75-test-one.csv\n",
      "No. 9 file: model-10-lgb-feats-selection-75-lr-0.001-test-one.csv\n",
      "No. 10 file: model-11-rf-test-one.csv\n",
      "No. 11 file: model-12-predict-keras-search-prelu-test-kfold.csv\n",
      "No. 12 file: model-13-predict-keras-he_uni-test-kfold.csv\n",
      "No. 13 file: model-14-lgb-feats-selection-75-lr-0.001-rand-test-one.csv\n",
      "No. 14 file: model-15-lgb-feats-selection-75-lr-0.001-rand323-test-one.csv\n",
      "No. 15 file: model-16-lgb-feats-selection-68-lr-0.001-mix5-test-one.csv\n",
      "No. 16 file: model-17-lgb-feats-selection-70-lr-0.001-mix5-test-one.csv\n",
      "No. 17 file: model-18-lgb-feats-selection-70-lr-0.001-p5-test-one.csv\n",
      "No. 18 file: model-19-lgb-search-bins-lr-0.0005-test-one.csv\n",
      "No. 19 file: model-20-lgb-lr-0.0008-mix5-test-one.csv\n",
      "No. 20 file: model-21-lgb-wo-per-area-long-test-one.csv\n",
      "No. 21 file: model-22-lgb-wo-per-area-long-2-test-one.csv\n",
      "No. 22 file: model-23-lgb-binary-test-one.csv\n",
      "No. 23 file: model-24-lgb-binary-augment-test-one.csv\n",
      "No. 24 file: model-25-lgb-search-bins-lr-0.0005-250-test-one.csv\n",
      "No. 25 file: model-26-lgb-search-bins-lr-0.0005-350-test-one.csv\n",
      "No. 26 file: model-27-lgb-feat_rm_new-test-one.csv\n"
     ]
    }
   ],
   "source": [
    "cv['log_total_price'] = np.log1p(cv['total_price'])\n",
    "cv['log_parea_total_price'] = np.log1p( cv['total_price'] / cv['building_area'] )\n",
    "\n",
    "print('Test predictions:')\n",
    "for i, idx in enumerate(idx_models):\n",
    "    f = files_test_kf[idx] if idx in use_test_kfold else files_test_one[idx]\n",
    "    print('No. {} file: {}'.format(i, f))\n",
    "    df = pd.read_csv('output/'+f)\n",
    "\n",
    "    test = pd.merge(test, df[['building_id','total_price']], on='building_id')\n",
    "        \n",
    "    test = test.rename(columns = {'total_price': 'pred_{}'.format(idx)})\n",
    "    test[f'log_pred_{idx}'] = np.log1p(test[f'pred_{idx}'])\n",
    "    test[f'log_parea_pred_{idx}'] = np.log1p( test[f'pred_{idx}'] / test['building_area'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>total_price</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_pred_25</th>\n",
       "      <th>log_parea_pred_25</th>\n",
       "      <th>pred_26</th>\n",
       "      <th>log_pred_26</th>\n",
       "      <th>log_parea_pred_26</th>\n",
       "      <th>pred_27</th>\n",
       "      <th>log_pred_27</th>\n",
       "      <th>log_parea_pred_27</th>\n",
       "      <th>log_total_price</th>\n",
       "      <th>log_parea_total_price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e3mMIMR3JJqCaXz1</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>6.476038e+05</td>\n",
       "      <td>6.331552e+05</td>\n",
       "      <td>13.358472</td>\n",
       "      <td>12.129369</td>\n",
       "      <td>717209.94</td>\n",
       "      <td>13.483125</td>\n",
       "      <td>12.254022</td>\n",
       "      <td>6.656891e+05</td>\n",
       "      <td>...</td>\n",
       "      <td>13.368623</td>\n",
       "      <td>12.139520</td>\n",
       "      <td>6.452832e+05</td>\n",
       "      <td>13.377446</td>\n",
       "      <td>12.148343</td>\n",
       "      <td>6.477905e+05</td>\n",
       "      <td>13.381324</td>\n",
       "      <td>12.152221</td>\n",
       "      <td>13.381036</td>\n",
       "      <td>12.151933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LgwzgklNvy4QCtq5</td>\n",
       "      <td>4.041309</td>\n",
       "      <td>3.321452e+06</td>\n",
       "      <td>3.064324e+06</td>\n",
       "      <td>14.935338</td>\n",
       "      <td>13.538770</td>\n",
       "      <td>2899842.20</td>\n",
       "      <td>14.880167</td>\n",
       "      <td>13.483600</td>\n",
       "      <td>3.079196e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>14.964998</td>\n",
       "      <td>13.568430</td>\n",
       "      <td>3.164660e+06</td>\n",
       "      <td>14.967557</td>\n",
       "      <td>13.570989</td>\n",
       "      <td>3.127411e+06</td>\n",
       "      <td>14.955716</td>\n",
       "      <td>13.559149</td>\n",
       "      <td>15.015913</td>\n",
       "      <td>13.619345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ucIR2NLLsC3T650L</td>\n",
       "      <td>5.584279</td>\n",
       "      <td>9.570885e+06</td>\n",
       "      <td>9.827776e+06</td>\n",
       "      <td>16.100723</td>\n",
       "      <td>14.380769</td>\n",
       "      <td>9766813.00</td>\n",
       "      <td>16.094501</td>\n",
       "      <td>14.374546</td>\n",
       "      <td>9.814852e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>16.099372</td>\n",
       "      <td>14.379417</td>\n",
       "      <td>9.832843e+06</td>\n",
       "      <td>16.101239</td>\n",
       "      <td>14.381284</td>\n",
       "      <td>9.745913e+06</td>\n",
       "      <td>16.092359</td>\n",
       "      <td>14.372404</td>\n",
       "      <td>16.074236</td>\n",
       "      <td>14.354282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>jre1pJhcQj91Kdky</td>\n",
       "      <td>13.563031</td>\n",
       "      <td>1.421501e+07</td>\n",
       "      <td>1.255350e+07</td>\n",
       "      <td>16.345510</td>\n",
       "      <td>13.738164</td>\n",
       "      <td>12699800.00</td>\n",
       "      <td>16.357097</td>\n",
       "      <td>13.749750</td>\n",
       "      <td>1.255981e+07</td>\n",
       "      <td>...</td>\n",
       "      <td>16.360680</td>\n",
       "      <td>13.753334</td>\n",
       "      <td>1.274179e+07</td>\n",
       "      <td>16.360398</td>\n",
       "      <td>13.753051</td>\n",
       "      <td>1.259548e+07</td>\n",
       "      <td>16.348848</td>\n",
       "      <td>13.741502</td>\n",
       "      <td>16.469809</td>\n",
       "      <td>13.862462</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rQpYpY9nRG7X5mmr</td>\n",
       "      <td>4.688108</td>\n",
       "      <td>7.627120e+05</td>\n",
       "      <td>1.215194e+06</td>\n",
       "      <td>14.010415</td>\n",
       "      <td>12.465389</td>\n",
       "      <td>2012610.50</td>\n",
       "      <td>14.514944</td>\n",
       "      <td>12.969916</td>\n",
       "      <td>1.128419e+06</td>\n",
       "      <td>...</td>\n",
       "      <td>13.950262</td>\n",
       "      <td>12.405236</td>\n",
       "      <td>1.114412e+06</td>\n",
       "      <td>13.923838</td>\n",
       "      <td>12.378812</td>\n",
       "      <td>1.131428e+06</td>\n",
       "      <td>13.938992</td>\n",
       "      <td>12.393966</td>\n",
       "      <td>13.544637</td>\n",
       "      <td>11.999613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 86 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area   total_price        pred_1  log_pred_1  \\\n",
       "0  e3mMIMR3JJqCaXz1       3.418175  6.476038e+05  6.331552e+05   13.358472   \n",
       "1  LgwzgklNvy4QCtq5       4.041309  3.321452e+06  3.064324e+06   14.935338   \n",
       "2  ucIR2NLLsC3T650L       5.584279  9.570885e+06  9.827776e+06   16.100723   \n",
       "3  jre1pJhcQj91Kdky      13.563031  1.421501e+07  1.255350e+07   16.345510   \n",
       "4  rQpYpY9nRG7X5mmr       4.688108  7.627120e+05  1.215194e+06   14.010415   \n",
       "\n",
       "   log_parea_pred_1       pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         12.129369    717209.94   13.483125         12.254022  6.656891e+05   \n",
       "1         13.538770   2899842.20   14.880167         13.483600  3.079196e+06   \n",
       "2         14.380769   9766813.00   16.094501         14.374546  9.814852e+06   \n",
       "3         13.738164  12699800.00   16.357097         13.749750  1.255981e+07   \n",
       "4         12.465389   2012610.50   14.514944         12.969916  1.128419e+06   \n",
       "\n",
       "   ...  log_pred_25  log_parea_pred_25       pred_26  log_pred_26  \\\n",
       "0  ...    13.368623          12.139520  6.452832e+05    13.377446   \n",
       "1  ...    14.964998          13.568430  3.164660e+06    14.967557   \n",
       "2  ...    16.099372          14.379417  9.832843e+06    16.101239   \n",
       "3  ...    16.360680          13.753334  1.274179e+07    16.360398   \n",
       "4  ...    13.950262          12.405236  1.114412e+06    13.923838   \n",
       "\n",
       "   log_parea_pred_26       pred_27  log_pred_27  log_parea_pred_27  \\\n",
       "0          12.148343  6.477905e+05    13.381324          12.152221   \n",
       "1          13.570989  3.127411e+06    14.955716          13.559149   \n",
       "2          14.381284  9.745913e+06    16.092359          14.372404   \n",
       "3          13.753051  1.259548e+07    16.348848          13.741502   \n",
       "4          12.378812  1.131428e+06    13.938992          12.393966   \n",
       "\n",
       "   log_total_price  log_parea_total_price  \n",
       "0        13.381036              12.151933  \n",
       "1        15.015913              13.619345  \n",
       "2        16.074236              14.354282  \n",
       "3        16.469809              13.862462  \n",
       "4        13.544637              11.999613  \n",
       "\n",
       "[5 rows x 86 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>building_id</th>\n",
       "      <th>building_area</th>\n",
       "      <th>pred_1</th>\n",
       "      <th>log_pred_1</th>\n",
       "      <th>log_parea_pred_1</th>\n",
       "      <th>pred_2</th>\n",
       "      <th>log_pred_2</th>\n",
       "      <th>log_parea_pred_2</th>\n",
       "      <th>pred_3</th>\n",
       "      <th>log_pred_3</th>\n",
       "      <th>...</th>\n",
       "      <th>log_parea_pred_24</th>\n",
       "      <th>pred_25</th>\n",
       "      <th>log_pred_25</th>\n",
       "      <th>log_parea_pred_25</th>\n",
       "      <th>pred_26</th>\n",
       "      <th>log_pred_26</th>\n",
       "      <th>log_parea_pred_26</th>\n",
       "      <th>pred_27</th>\n",
       "      <th>log_pred_27</th>\n",
       "      <th>log_parea_pred_27</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>X5gsdTWGS3W7JJQB</td>\n",
       "      <td>3.418175</td>\n",
       "      <td>1.526912e+07</td>\n",
       "      <td>16.541343</td>\n",
       "      <td>15.312236</td>\n",
       "      <td>12470072.0</td>\n",
       "      <td>16.338842</td>\n",
       "      <td>15.109735</td>\n",
       "      <td>1.531685e+07</td>\n",
       "      <td>16.544464</td>\n",
       "      <td>...</td>\n",
       "      <td>15.189986</td>\n",
       "      <td>1.456214e+07</td>\n",
       "      <td>16.493936</td>\n",
       "      <td>15.264829</td>\n",
       "      <td>1.358120e+07</td>\n",
       "      <td>16.424197</td>\n",
       "      <td>15.195091</td>\n",
       "      <td>1.405424e+07</td>\n",
       "      <td>16.458435</td>\n",
       "      <td>15.229328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BTshNOJyKHnT2YIT</td>\n",
       "      <td>7.726227</td>\n",
       "      <td>3.924241e+06</td>\n",
       "      <td>15.182684</td>\n",
       "      <td>13.138065</td>\n",
       "      <td>3916552.2</td>\n",
       "      <td>15.180723</td>\n",
       "      <td>13.136104</td>\n",
       "      <td>3.977095e+06</td>\n",
       "      <td>15.196062</td>\n",
       "      <td>...</td>\n",
       "      <td>13.140432</td>\n",
       "      <td>3.903389e+06</td>\n",
       "      <td>15.177356</td>\n",
       "      <td>13.132737</td>\n",
       "      <td>3.915563e+06</td>\n",
       "      <td>15.180470</td>\n",
       "      <td>13.135851</td>\n",
       "      <td>3.932854e+06</td>\n",
       "      <td>15.184876</td>\n",
       "      <td>13.140257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>dhdymr0lV8N5kZOT</td>\n",
       "      <td>12.170581</td>\n",
       "      <td>1.096127e+07</td>\n",
       "      <td>16.209879</td>\n",
       "      <td>13.710858</td>\n",
       "      <td>11912735.0</td>\n",
       "      <td>16.293119</td>\n",
       "      <td>13.794098</td>\n",
       "      <td>1.084967e+07</td>\n",
       "      <td>16.199646</td>\n",
       "      <td>...</td>\n",
       "      <td>13.643765</td>\n",
       "      <td>1.064055e+07</td>\n",
       "      <td>16.180183</td>\n",
       "      <td>13.681162</td>\n",
       "      <td>1.076414e+07</td>\n",
       "      <td>16.191730</td>\n",
       "      <td>13.692710</td>\n",
       "      <td>1.040041e+07</td>\n",
       "      <td>16.157355</td>\n",
       "      <td>13.658335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>VEwyGGMcD56w5BOc</td>\n",
       "      <td>2.252256</td>\n",
       "      <td>6.155550e+06</td>\n",
       "      <td>15.632865</td>\n",
       "      <td>14.820933</td>\n",
       "      <td>5940670.0</td>\n",
       "      <td>15.597333</td>\n",
       "      <td>14.785400</td>\n",
       "      <td>6.015238e+06</td>\n",
       "      <td>15.609807</td>\n",
       "      <td>...</td>\n",
       "      <td>14.778239</td>\n",
       "      <td>6.006309e+06</td>\n",
       "      <td>15.608321</td>\n",
       "      <td>14.796389</td>\n",
       "      <td>6.034948e+06</td>\n",
       "      <td>15.613078</td>\n",
       "      <td>14.801146</td>\n",
       "      <td>5.905111e+06</td>\n",
       "      <td>15.591329</td>\n",
       "      <td>14.779397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wmUeMoJZfsqaSX9b</td>\n",
       "      <td>5.813985</td>\n",
       "      <td>1.062995e+06</td>\n",
       "      <td>13.876602</td>\n",
       "      <td>12.116340</td>\n",
       "      <td>1088488.1</td>\n",
       "      <td>13.900301</td>\n",
       "      <td>12.140039</td>\n",
       "      <td>1.027248e+06</td>\n",
       "      <td>13.842395</td>\n",
       "      <td>...</td>\n",
       "      <td>12.188114</td>\n",
       "      <td>1.091787e+06</td>\n",
       "      <td>13.903327</td>\n",
       "      <td>12.143065</td>\n",
       "      <td>1.096191e+06</td>\n",
       "      <td>13.907353</td>\n",
       "      <td>12.147091</td>\n",
       "      <td>1.048505e+06</td>\n",
       "      <td>13.862877</td>\n",
       "      <td>12.102615</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        building_id  building_area        pred_1  log_pred_1  \\\n",
       "0  X5gsdTWGS3W7JJQB       3.418175  1.526912e+07   16.541343   \n",
       "1  BTshNOJyKHnT2YIT       7.726227  3.924241e+06   15.182684   \n",
       "2  dhdymr0lV8N5kZOT      12.170581  1.096127e+07   16.209879   \n",
       "3  VEwyGGMcD56w5BOc       2.252256  6.155550e+06   15.632865   \n",
       "4  wmUeMoJZfsqaSX9b       5.813985  1.062995e+06   13.876602   \n",
       "\n",
       "   log_parea_pred_1      pred_2  log_pred_2  log_parea_pred_2        pred_3  \\\n",
       "0         15.312236  12470072.0   16.338842         15.109735  1.531685e+07   \n",
       "1         13.138065   3916552.2   15.180723         13.136104  3.977095e+06   \n",
       "2         13.710858  11912735.0   16.293119         13.794098  1.084967e+07   \n",
       "3         14.820933   5940670.0   15.597333         14.785400  6.015238e+06   \n",
       "4         12.116340   1088488.1   13.900301         12.140039  1.027248e+06   \n",
       "\n",
       "   log_pred_3  ...  log_parea_pred_24       pred_25  log_pred_25  \\\n",
       "0   16.544464  ...          15.189986  1.456214e+07    16.493936   \n",
       "1   15.196062  ...          13.140432  3.903389e+06    15.177356   \n",
       "2   16.199646  ...          13.643765  1.064055e+07    16.180183   \n",
       "3   15.609807  ...          14.778239  6.006309e+06    15.608321   \n",
       "4   13.842395  ...          12.188114  1.091787e+06    13.903327   \n",
       "\n",
       "   log_parea_pred_25       pred_26  log_pred_26  log_parea_pred_26  \\\n",
       "0          15.264829  1.358120e+07    16.424197          15.195091   \n",
       "1          13.132737  3.915563e+06    15.180470          13.135851   \n",
       "2          13.681162  1.076414e+07    16.191730          13.692710   \n",
       "3          14.796389  6.034948e+06    15.613078          14.801146   \n",
       "4          12.143065  1.096191e+06    13.907353          12.147091   \n",
       "\n",
       "        pred_27  log_pred_27  log_parea_pred_27  \n",
       "0  1.405424e+07    16.458435          15.229328  \n",
       "1  3.932854e+06    15.184876          13.140257  \n",
       "2  1.040041e+07    16.157355          13.658335  \n",
       "3  5.905111e+06    15.591329          14.779397  \n",
       "4  1.048505e+06    13.862877          12.102615  \n",
       "\n",
       "[5 rows x 83 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(cv.head())\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check models scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0 model-01 5870.873059\n",
      " 1 model-02 5400.852164\n",
      " 2 model-03 5877.873452\n",
      " 3 model-04 5713.867808\n",
      " 4 model-05 5724.869598\n",
      " 5 model-06 5886.873769\n",
      " 6 model-07 5171.836449\n",
      " 7 model-08 5514.858826\n",
      " 8 model-09 5872.873118\n",
      " 9 model-10 5897.873845\n",
      "10 model-11 5075.838018\n",
      "11 model-12 5486.856963\n",
      "12 model-13 5506.858055\n",
      "13 model-14 5908.873901\n",
      "14 model-15 5900.873836\n",
      "15 model-16 5907.874126\n",
      "16 model-17 5905.874165\n",
      "17 model-18 5908.874297\n",
      "18 model-19 5911.874156\n",
      "19 model-20 5908.874040\n",
      "20 model-21 5758.870702\n",
      "21 model-22 5752.870671\n",
      "22 model-23 5852.871357\n",
      "23 model-24 5866.873835\n",
      "24 model-25 5908.874238\n",
      "25 model-26 5918.873998\n",
      "26 model-27 5892.873194\n"
     ]
    }
   ],
   "source": [
    "for i, idx_model in enumerate(idx_models):\n",
    "    print('%2d'%i, 'model-%02d'%idx_model, '%.6f'%cal_score(cv['total_price'], cv[f'pred_{idx_model}']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv['constant_1'] = 1\n",
    "test['constant_1'] = 1\n",
    "\n",
    "if is_per_area:\n",
    "    cols_opt = [f'log_parea_pred_{idx}' for idx in idx_models]\n",
    "else:\n",
    "    cols_opt = [f'log_pred_{idx}' for idx in idx_models]\n",
    "\n",
    "if add_intercept:\n",
    "    cols_opt.append('constant_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define opt function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(x, metric):\n",
    "    cv_pred_final = cv.loc[:,cols_opt].dot(x)\n",
    "    \n",
    "    if is_per_area:\n",
    "        cv_pred_final = np.expm1(cv_pred_final) * cv['building_area']\n",
    "    else:\n",
    "        cv_pred_final = np.expm1(cv_pred_final)\n",
    "\n",
    "    global best_score\n",
    "    global best_coeffs\n",
    "    score = cal_score(cv['total_price'], cv_pred_final)\n",
    "    if score > best_score[metric]:\n",
    "        best_score[metric] = score\n",
    "        best_coeffs[metric] = x.copy()\n",
    "        print('find better score:')\n",
    "        print('score: ', score)\n",
    "        print('coeffs: ', x)\n",
    "        print()\n",
    "    \n",
    "    if metric == 'mape':\n",
    "        return cal_mape(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mse':\n",
    "        return mean_squared_error(cv['total_price'], cv_pred_final)\n",
    "    elif metric == 'mae':\n",
    "        return mean_absolute_error(cv['total_price'], cv_pred_final)\n",
    "    else:\n",
    "        raise Exception('metric unknown: {}'.format(metric))\n",
    "#    return 1 - (cal_score(cv['total_price'], cv_pred_final)/10000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571, 0.03571428571428571]\n",
      "\n",
      "find better score:\n",
      "score:  155.59830708423098\n",
      "coeffs:  [0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  155.5983072164571\n",
      "coeffs:  [0.0357143  0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  155.59830721645739\n",
      "coeffs:  [0.03571429 0.03571429 0.0357143  0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  155.5983072164622\n",
      "coeffs:  [0.03571429 0.03571429 0.03571429 0.0357143  0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  155.59830721646313\n",
      "coeffs:  [0.03571429 0.03571429 0.03571429 0.03571429 0.0357143  0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  155.59830721652034\n",
      "coeffs:  [0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.0357143  0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429 0.03571429\n",
      " 0.03571429 0.03571429 0.03571429 0.03571429]\n",
      "\n",
      "find better score:\n",
      "score:  2426.820647526468\n",
      "coeffs:  [0.03657047 0.03657028 0.03657048 0.03657051 0.03657051 0.03657047\n",
      " 0.03657019 0.03657051 0.03657047 0.03657047 0.03657088 0.03657047\n",
      " 0.03657042 0.03657048 0.03657048 0.03657048 0.03657048 0.03657048\n",
      " 0.03657047 0.03657048 0.03657051 0.03657051 0.03657046 0.03657048\n",
      " 0.03657047 0.03657047 0.03657047 0.03576963]\n",
      "\n",
      "find better score:\n",
      "score:  2426.8206476601467\n",
      "coeffs:  [0.03657049 0.03657028 0.03657048 0.03657051 0.03657051 0.03657047\n",
      " 0.03657019 0.03657051 0.03657047 0.03657047 0.03657088 0.03657047\n",
      " 0.03657042 0.03657048 0.03657048 0.03657048 0.03657048 0.03657048\n",
      " 0.03657047 0.03657048 0.03657051 0.03657051 0.03657046 0.03657048\n",
      " 0.03657047 0.03657047 0.03657047 0.03576963]\n",
      "\n",
      "find better score:\n",
      "score:  2426.8206476601504\n",
      "coeffs:  [0.03657047 0.03657028 0.03657049 0.03657051 0.03657051 0.03657047\n",
      " 0.03657019 0.03657051 0.03657047 0.03657047 0.03657088 0.03657047\n",
      " 0.03657042 0.03657048 0.03657048 0.03657048 0.03657048 0.03657048\n",
      " 0.03657047 0.03657048 0.03657051 0.03657051 0.03657046 0.03657048\n",
      " 0.03657047 0.03657047 0.03657047 0.03576963]\n",
      "\n",
      "find better score:\n",
      "score:  2426.820647660162\n",
      "coeffs:  [0.03657047 0.03657028 0.03657048 0.03657051 0.03657053 0.03657047\n",
      " 0.03657019 0.03657051 0.03657047 0.03657047 0.03657088 0.03657047\n",
      " 0.03657042 0.03657048 0.03657048 0.03657048 0.03657048 0.03657048\n",
      " 0.03657047 0.03657048 0.03657051 0.03657051 0.03657046 0.03657048\n",
      " 0.03657047 0.03657047 0.03657047 0.03576963]\n",
      "\n",
      "find better score:\n",
      "score:  2426.8206476601636\n",
      "coeffs:  [0.03657047 0.03657028 0.03657048 0.03657051 0.03657051 0.03657047\n",
      " 0.03657019 0.03657052 0.03657047 0.03657047 0.03657088 0.03657047\n",
      " 0.03657042 0.03657048 0.03657048 0.03657048 0.03657048 0.03657048\n",
      " 0.03657047 0.03657048 0.03657051 0.03657051 0.03657046 0.03657048\n",
      " 0.03657047 0.03657047 0.03657047 0.03576963]\n",
      "\n",
      "find better score:\n",
      "score:  4892.8427293975565\n",
      "coeffs:  [0.03713594 0.03713562 0.03713595 0.037136   0.03713601 0.03713594\n",
      " 0.03713547 0.037136   0.03713594 0.03713594 0.03713662 0.03713594\n",
      " 0.03713586 0.03713595 0.03713595 0.03713595 0.03713595 0.03713595\n",
      " 0.03713594 0.03713594 0.03713601 0.03713601 0.03713592 0.03713595\n",
      " 0.03713594 0.03713594 0.03713593 0.03580617]\n",
      "\n",
      "find better score:\n",
      "score:  5593.870303915963\n",
      "coeffs:  [0.03683551 0.03683526 0.03683551 0.03683555 0.03683556 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683549 0.03683551\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5593.870303973438\n",
      "coeffs:  [0.03683552 0.03683526 0.03683551 0.03683555 0.03683556 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683549 0.03683551\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5593.870303973444\n",
      "coeffs:  [0.03683551 0.03683526 0.03683553 0.03683555 0.03683556 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683549 0.03683551\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5593.8703039734555\n",
      "coeffs:  [0.03683551 0.03683526 0.03683551 0.03683555 0.03683557 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683549 0.03683551\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5593.870303973458\n",
      "coeffs:  [0.03683551 0.03683526 0.03683551 0.03683555 0.03683556 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5593.870303973463\n",
      "coeffs:  [0.03683551 0.03683526 0.03683551 0.03683555 0.03683556 0.03683551\n",
      " 0.03683514 0.03683555 0.03683551 0.03683551 0.03683604 0.0368355\n",
      " 0.03683544 0.03683551 0.03683551 0.03683551 0.03683551 0.03683551\n",
      " 0.03683551 0.03683551 0.03683556 0.03683556 0.03683549 0.03683553\n",
      " 0.03683551 0.03683551 0.0368355  0.03578676]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875303919049\n",
      "coeffs:  [0.03689683 0.03688996 0.03695286 0.03686698 0.03705449 0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712055 0.03716237\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875303930633\n",
      "coeffs:  [0.03689684 0.03688996 0.03695286 0.03686698 0.03705449 0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712055 0.03716237\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875303930638\n",
      "coeffs:  [0.03689683 0.03688996 0.03695287 0.03686698 0.03705449 0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712055 0.03716237\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n",
      "find better score:\n",
      "score:  5911.875303930651\n",
      "coeffs:  [0.03689683 0.03688996 0.03695286 0.03686698 0.0370545  0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712055 0.03716237\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5911.875303930653\n",
      "coeffs:  [0.03689683 0.03688996 0.03695286 0.03686698 0.03705449 0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712057 0.03716237\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n",
      "find better score:\n",
      "score:  5911.87530393066\n",
      "coeffs:  [0.03689683 0.03688996 0.03695286 0.03686698 0.03705449 0.03692522\n",
      " 0.03701904 0.03700132 0.03691354 0.03695015 0.03536449 0.03687575\n",
      " 0.03687875 0.03695892 0.03694532 0.03697034 0.03697183 0.03699447\n",
      " 0.03697725 0.03697401 0.03702937 0.03703686 0.03712055 0.03716239\n",
      " 0.03700843 0.03695272 0.03702193 0.03462485]\n",
      "\n",
      "find better score:\n",
      "score:  5940.875624674537\n",
      "coeffs:  [0.03684705 0.0366979  0.03729382 0.03640893 0.03827012 0.0370941\n",
      " 0.03680674 0.03762491 0.03695669 0.03723505 0.0243878  0.03676263\n",
      " 0.03649702 0.03730391 0.03720984 0.03741424 0.03746309 0.03762073\n",
      " 0.03751677 0.03743832 0.03825297 0.03828962 0.03851625 0.03904889\n",
      " 0.0377548  0.03731515 0.03767346 0.02770048]\n",
      "\n",
      "find better score:\n",
      "score:  5944.875809570951\n",
      "coeffs:  [0.03672445 0.03641271 0.03768932 0.03601565 0.03982178 0.03724287\n",
      " 0.03628934 0.03852008 0.03695928 0.03750265 0.01086858 0.03661158\n",
      " 0.03609649 0.03765582 0.03745668 0.03789586 0.03800516 0.03835527\n",
      " 0.03812712 0.03793702 0.03977385 0.03985216 0.0402405  0.04141044\n",
      " 0.0386163  0.0377193  0.03846891 0.01915093]\n",
      "\n",
      "find better score:\n",
      "score:  5953.876338357817\n",
      "coeffs:  [ 0.03623407  0.03527196  0.0392713   0.03444249  0.04602841  0.03783792\n",
      "  0.03421975  0.04210075  0.03696965  0.03857309 -0.04320832  0.03600737\n",
      "  0.03449439  0.03906348  0.03844402  0.03982235  0.04017342  0.04129343\n",
      "  0.0405685   0.03993183  0.04585734  0.0461023   0.04713751  0.05085665\n",
      "  0.04206233  0.03933592  0.04165071 -0.01504728]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876667020047\n",
      "coeffs:  [ 0.01939761  0.03297293  0.03503048  0.04469601  0.05753325  0.02751446\n",
      "  0.02473993  0.06720006  0.02325907  0.03139185 -0.10434511  0.03389533\n",
      "  0.03877658  0.03381553  0.03085974  0.03705598  0.03814456  0.04409468\n",
      "  0.04249136  0.03692394  0.05560419  0.05668741  0.067744    0.08402098\n",
      "  0.04574864  0.03975776  0.05915132 -0.07742878]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876667023433\n",
      "coeffs:  [ 0.01939763  0.03297293  0.03503048  0.04469601  0.05753325  0.02751446\n",
      "  0.02473993  0.06720006  0.02325907  0.03139185 -0.10434511  0.03389533\n",
      "  0.03877658  0.03381553  0.03085974  0.03705598  0.03814456  0.04409468\n",
      "  0.04249136  0.03692394  0.05560419  0.05668741  0.067744    0.08402098\n",
      "  0.04574864  0.03975776  0.05915132 -0.07742878]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876667023439\n",
      "coeffs:  [ 0.01939761  0.03297293  0.0350305   0.04469601  0.05753325  0.02751446\n",
      "  0.02473993  0.06720006  0.02325907  0.03139185 -0.10434511  0.03389533\n",
      "  0.03877658  0.03381553  0.03085974  0.03705598  0.03814456  0.04409468\n",
      "  0.04249136  0.03692394  0.05560419  0.05668741  0.067744    0.08402098\n",
      "  0.04574864  0.03975776  0.05915132 -0.07742878]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876667023447\n",
      "coeffs:  [ 0.01939761  0.03297293  0.03503048  0.04469603  0.05753325  0.02751446\n",
      "  0.02473993  0.06720006  0.02325907  0.03139185 -0.10434511  0.03389533\n",
      "  0.03877658  0.03381553  0.03085974  0.03705598  0.03814456  0.04409468\n",
      "  0.04249136  0.03692394  0.05560419  0.05668741  0.067744    0.08402098\n",
      "  0.04574864  0.03975776  0.05915132 -0.07742878]\n",
      "\n",
      "find better score:\n",
      "score:  5956.876667023454\n",
      "coeffs:  [ 0.01939761  0.03297293  0.03503048  0.04469601  0.05753325  0.02751446\n",
      "  0.02473993  0.06720006  0.02325907  0.03139185 -0.10434509  0.03389533\n",
      "  0.03877658  0.03381553  0.03085974  0.03705598  0.03814456  0.04409468\n",
      "  0.04249136  0.03692394  0.05560419  0.05668741  0.067744    0.08402098\n",
      "  0.04574864  0.03975776  0.05915132 -0.07742878]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709547649\n",
      "coeffs:  [ 0.00388353  0.0308957   0.02921081  0.05657357  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925065  0.10465579\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709550824\n",
      "coeffs:  [ 0.00388355  0.0308957   0.02921081  0.05657357  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925065  0.10465579\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709550828\n",
      "coeffs:  [ 0.00388353  0.0308957   0.02921082  0.05657357  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925065  0.10465579\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709550831\n",
      "coeffs:  [ 0.00388353  0.0308957   0.02921081  0.05657358  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925065  0.10465579\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709550832\n",
      "coeffs:  [ 0.00388353  0.0308957   0.02921081  0.05657357  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925067  0.10465579\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5958.876709550839\n",
      "coeffs:  [ 0.00388353  0.0308957   0.02921081  0.05657357  0.06090307  0.01702922\n",
      "  0.01772913  0.08581292  0.0101651   0.02335428 -0.0951186   0.03158797\n",
      "  0.04368242  0.02724038  0.02253441  0.03223803  0.03374718  0.04343846\n",
      "  0.04161894  0.03173724  0.05747723  0.05916153  0.07925065  0.10465581\n",
      "  0.04529472  0.03846191  0.07262237 -0.09353361]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876727667957\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703646  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876727668985\n",
      "coeffs:  [-0.00261643  0.02865785  0.02703646  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.8767276689905\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703647  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876727668991\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703646  0.06163864  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876727668993\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703646  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355963\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.876727669\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703646  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402012\n",
      "  0.04548669  0.03826397  0.07899458 -0.09966964]\n",
      "\n",
      "find better score:\n",
      "score:  5961.8767276690005\n",
      "coeffs:  [-0.00261645  0.02865785  0.02703646  0.06163862  0.06244426  0.01277193\n",
      "  0.01443194  0.09263309  0.00473895  0.02019856 -0.09197465  0.02944077\n",
      "  0.04461222  0.02474195  0.01924787  0.03051407  0.03220394  0.04355962\n",
      "  0.04162423  0.02979698  0.05841515  0.06037208  0.08437624  0.11402011\n",
      "  0.04548669  0.03826397  0.0789946  -0.09966964]\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "find better score:\n",
      "score:  5965.876760728317\n",
      "coeffs:  [-0.01115586  0.02040518  0.02498897  0.06880792  0.06356288  0.00758258\n",
      "  0.00999006  0.09623459 -0.00224866  0.01668348 -0.07987731  0.02189674\n",
      "  0.04111543  0.02226352  0.01553528  0.02912872  0.03105695  0.04485537\n",
      "  0.0426813   0.02772368  0.0588692   0.0612555   0.09089475  0.127514\n",
      "  0.04662598  0.03909933  0.08999011 -0.09573083]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876958194567\n",
      "coeffs:  [-0.12446793  0.02440947  0.14704839  0.06096884  0.07764397 -0.00041144\n",
      "  0.02082405  0.09885101 -0.08964934 -0.05764888 -0.10825227  0.00364872\n",
      "  0.02898592  0.01198022 -0.07268981  0.0551545   0.08312421  0.17911595\n",
      "  0.01708617 -0.17692777  0.04008628  0.0664916   0.0910588   0.24443207\n",
      "  0.01393358  0.00729984  0.36180794 -0.07174841]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876958194656\n",
      "coeffs:  [-0.12446791  0.02440947  0.14704839  0.06096884  0.07764397 -0.00041144\n",
      "  0.02082405  0.09885101 -0.08964934 -0.05764888 -0.10825227  0.00364872\n",
      "  0.02898592  0.01198022 -0.07268981  0.0551545   0.08312421  0.17911595\n",
      "  0.01708617 -0.17692777  0.04008628  0.0664916   0.0910588   0.24443207\n",
      "  0.01393358  0.00729984  0.36180794 -0.07174841]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876958194657\n",
      "coeffs:  [-0.12446793  0.02440947  0.14704839  0.06096884  0.07764397 -0.00041144\n",
      "  0.02082405  0.09885101 -0.08964934 -0.05764886 -0.10825227  0.00364872\n",
      "  0.02898592  0.01198022 -0.07268981  0.0551545   0.08312421  0.17911595\n",
      "  0.01708617 -0.17692777  0.04008628  0.0664916   0.0910588   0.24443207\n",
      "  0.01393358  0.00729984  0.36180794 -0.07174841]\n",
      "\n",
      "find better score:\n",
      "score:  5965.876958194658\n",
      "coeffs:  [-0.12446793  0.02440947  0.14704839  0.06096884  0.07764397 -0.00041144\n",
      "  0.02082405  0.09885101 -0.08964934 -0.05764888 -0.10825227  0.00364872\n",
      "  0.02898592  0.01198022 -0.07268981  0.05515451  0.08312421  0.17911595\n",
      "  0.01708617 -0.17692777  0.04008628  0.0664916   0.0910588   0.24443207\n",
      "  0.01393358  0.00729984  0.36180794 -0.07174841]\n",
      "\n",
      "find better score:\n",
      "score:  5966.8769623180815\n",
      "coeffs:  [-0.12893311  0.01748268  0.15705462  0.05650056  0.07757895  0.00376346\n",
      "  0.01821735  0.09913794 -0.09212872 -0.06135379 -0.10463274  0.00585625\n",
      "  0.02920516  0.0177638  -0.07945878  0.06377096  0.09713183  0.20107405\n",
      "  0.01725589 -0.20151799  0.03604288  0.06572246  0.08880421  0.23845299\n",
      "  0.01324528  0.00749634  0.3603118  -0.07060099]\n",
      "\n",
      "Optimizing with init x0: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "Optimizing with init x0: [0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1, 0.1]\n",
      "\n",
      "Optimizing with init x0: [0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2, 0.2]\n",
      "\n",
      "Optimizing with init x0: [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n",
      "/usr/local/lib/python3.7/site-packages/scipy/optimize/optimize.py:670: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  grad[k] = (f(*((xk + d,) + args)) - f0) / d[k]\n",
      "/usr/local/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: overflow encountered in expm1\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimizing with init x0: [0.34416808580055425, 0.7280331195157227, 0.8580406547525017, 0.05588302971722231, 0.7471218316687382, -2.1147372476584465, 1.795334523424792, -0.1122838607277405, -0.28454860413389704, 0.09036987956487025, -1.2862654697282074, -0.9887031769198399, -0.7775055103198899, -0.3566202987611873, 1.6020435736010978, -0.5873760516955561, 0.8161281082575919, 1.3274481865326864, 1.4142465547006995, 0.13523491900122164, 0.3341617193504456, -0.33467621971533756, 1.402320246138047, -0.33983022130451207, -0.040241500878293646, -0.3892305719187574, -0.8269655764989035, 0.36991774304990965]\n",
      "\n",
      "Optimizing with init x0: [-0.3343550832011317, 0.00029280744242966145, -0.06044434264776245, -2.633435172158633, -0.1384630358723084, -1.5770952674863343, -2.479562229244216, 0.3838913101534719, 1.1756154147826228, -0.8010439513107928, -0.15444442280811954, 0.010354188581224333, -2.2096577311203043, -0.34512239390860966, 1.798840138594349, -0.2130427024793206, 0.054424787948603004, -0.6946872479260904, 0.5796387668882377, 0.5835432843622804, 0.8445307364324199, 0.1544467241162038, 0.9767138244860428, 0.8245256813046936, -0.8429767076895349, -0.7502240804484047, -0.6917419209398621, 1.9390661676260526]\n",
      "\n",
      "Optimizing with init x0: [0.8041312025758488, -0.8107843856389928, -0.05472622703271994, -0.008558441754976269, 0.43907730715685234, 0.7159661858387044, -0.5339763932002428, 0.7527950978513848, -0.2102518299116361, 1.0437910205691832, 0.3029212795030239, 0.7860195506225016, 0.4807802331586901, -1.4872229471813885, -0.08837702147096181, -0.40876884210972714, 1.0063923594098165, -3.488576459189255, -0.4962137390238279, 0.31422953891308386, -0.8818257045525443, 0.6707976847751743, 0.35374598832626636, -0.5301547428898434, 1.932327872059035, -0.8684819066112506, 2.3182816213688273, -0.28380344145878444]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "best_score = {}\n",
    "best_coeffs = {}\n",
    "\n",
    "len_x = len(cols_opt)\n",
    "rev_len_x = 1/len_x\n",
    "x0s = [ [1/len_x for i in range(len_x)],\n",
    "       [0 for i in range(len_x)],\n",
    "       [0.1 for i in range(len_x)],\n",
    "       [0.2 for i in range(len_x)],\n",
    "       [0.5 for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)],\n",
    "       [np.random.randn()+1/len_x for i in range(len_x)] ]\n",
    "\n",
    "for metric in ['mape']:\n",
    "#for metric in ['mape', 'mae', 'mse']:\n",
    "    best_score[metric] = 0\n",
    "    best_coeffs[metric] = []\n",
    "    for x0 in x0s:\n",
    "        print('Optimizing with init x0: {}'.format(x0))\n",
    "        print()\n",
    "        minimize(objective, x0, args=(metric), tol=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'mape': 5966.8769623180815}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'mape': array([-0.12893311,  0.01748268,  0.15705462,  0.05650056,  0.07757895,\n",
       "         0.00376346,  0.01821735,  0.09913794, -0.09212872, -0.06135379,\n",
       "        -0.10463274,  0.00585625,  0.02920516,  0.0177638 , -0.07945878,\n",
       "         0.06377096,  0.09713183,  0.20107405,  0.01725589, -0.20151799,\n",
       "         0.03604288,  0.06572246,  0.08880421,  0.23845299,  0.01324528,\n",
       "         0.00749634,  0.3603118 , -0.07060099])}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(best_score)\n",
    "display(best_coeffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_final = pd.DataFrame({'building_id': test['building_id']})\n",
    "\n",
    "test_pred_final['total_price'] = test.loc[:,cols_opt].dot(best_coeffs['mape'])\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price']) * test['building_area'] \n",
    "else:\n",
    "    test_pred_final['total_price'] = np.expm1(test_pred_final['total_price'])\n",
    "    \n",
    "test_pred_final['total_price'] = np.clip(test_pred_final['total_price'], 0, None)\n",
    "\n",
    "if is_per_area:\n",
    "    test_pred_final.to_csv('output/stack_spopt-parea_{}_{}.csv'.format(stack_idx, models), index=False)\n",
    "else:\n",
    "    test_pred_final.to_csv('output/stack_spopt_{}_{}.csv'.format(stack_idx, models), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_parea_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price'] / test['building_area']), bins=100, label='test',\n",
    "         normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price/area + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(cv['log_total_price'], bins=100, label='train true', normed=True)\n",
    "plt.hist(np.log1p(test_pred_final['total_price']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(price + 1)'); plt.ylabel('ratio')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(np.log1p(cv['building_area']), bins=100, label='train', normed=True)\n",
    "plt.hist(np.log1p(test['building_area']), bins=100, label='test', normed=True, alpha=0.7)\n",
    "plt.xlabel('log(building_area + 1)'); plt.ylabel('ratio'); plt.yscale('log')\n",
    "plt.legend(); plt.grid(); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([1/17 if i in [3, 4, 7, 8, 12, 13, 15, 16, 17, 18, 19, 20, 21, 22, 23, 25, 26] else 0 \\\n",
    " for i in list(range(1,24)) + list(range(25,28))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
